{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data from output.txt\n",
    "with open('Unstructured_Corpora.txt', 'r') as f:    \n",
    "    text_data = [line.rstrip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regular expression pattern to match punctuation\n",
    "punct_pattern = r'[^\\w\\s]|_'\n",
    "\n",
    "# Define a list to store the tokenized documents\n",
    "tokens = []\n",
    "\n",
    "# Tokenize each document\n",
    "for doc in text_data:\n",
    "    # Remove punctuation using re.sub\n",
    "    doc = re.sub(punct_pattern, '', doc)\n",
    "    \n",
    "    # Tokenize the document using word_tokenize from NLTK\n",
    "    doc_tokens = word_tokenize(doc)\n",
    "    \n",
    "    # Append the tokens to the list\n",
    "    tokens.append(doc_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_docs = [[token for token in doc if token not in stop_words] for doc in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_docs = [[stemmer.stem(token) for token in doc] for doc in filtered_docs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(126747 unique tokens: ['15', '2', '2023', '2023a', '2023explor']...) from 6055 documents (total 3940529 corpus positions)\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary(126747 unique tokens: ['15', '2', '2023', '2023a', '2023explor']...) from 6055 documents (total 3940529 corpus positions)\", 'datetime': '2023-05-04T13:23:33.649981', 'gensim': '4.1.2', 'python': '3.9.15 (main, Nov 24 2022, 14:31:59) \\n[GCC 11.2.0]', 'platform': 'Linux-5.13.0-1025-aws-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Create a dictionary from the stemmed documents\n",
    "dictionary = gensim.corpora.Dictionary(stemmed_docs)\n",
    "\n",
    "# Create a gensim corpus from the stemmed documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in stemmed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.1\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.1\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (multi-pass) LDA training, 10 topics, 10 passes over the supplied corpus of 6055 documents, updating model once every 2000 documents, evaluating perplexity every 6055 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.011*\"use\" + 0.009*\"page\" + 0.008*\"set\" + 0.008*\"improv\" + 0.008*\"cooki\" + 0.008*\"agenc\" + 0.007*\"addit\" + 0.007*\"search\" + 0.007*\"help\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.012*\"govuk\" + 0.011*\"use\" + 0.010*\"page\" + 0.009*\"improv\" + 0.008*\"addit\" + 0.008*\"help\" + 0.007*\"search\" + 0.007*\"cooki\" + 0.006*\"govern\" + 0.006*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.012*\"cooki\" + 0.011*\"environ\" + 0.011*\"govuk\" + 0.010*\"help\" + 0.010*\"use\" + 0.010*\"addit\" + 0.009*\"page\" + 0.009*\"set\" + 0.009*\"improv\" + 0.008*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.013*\"use\" + 0.010*\"set\" + 0.010*\"govuk\" + 0.009*\"improv\" + 0.009*\"addit\" + 0.008*\"cooki\" + 0.007*\"environ\" + 0.007*\"govern\" + 0.007*\"help\" + 0.006*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.010*\"govuk\" + 0.009*\"govern\" + 0.009*\"cooki\" + 0.008*\"new\" + 0.007*\"use\" + 0.007*\"help\" + 0.007*\"search\" + 0.007*\"addit\" + 0.007*\"environ\" + 0.006*\"improv\"\n",
      "INFO:gensim.models.ldamodel:topic diff=7.627749, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.014*\"cooki\" + 0.013*\"govuk\" + 0.012*\"use\" + 0.011*\"addit\" + 0.011*\"page\" + 0.010*\"help\" + 0.010*\"environ\" + 0.010*\"set\" + 0.009*\"improv\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.014*\"flood\" + 0.011*\"cooki\" + 0.011*\"govuk\" + 0.010*\"use\" + 0.009*\"set\" + 0.009*\"live\" + 0.009*\"environ\" + 0.009*\"page\" + 0.009*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"flood\" + 0.012*\"use\" + 0.010*\"cooki\" + 0.009*\"govuk\" + 0.009*\"page\" + 0.008*\"new\" + 0.008*\"help\" + 0.008*\"search\" + 0.008*\"improv\" + 0.007*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"cooki\" + 0.010*\"govern\" + 0.009*\"use\" + 0.009*\"new\" + 0.009*\"govuk\" + 0.009*\"page\" + 0.008*\"set\" + 0.008*\"us\" + 0.007*\"help\" + 0.007*\"environ\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"cooki\" + 0.011*\"govuk\" + 0.011*\"govern\" + 0.010*\"use\" + 0.009*\"help\" + 0.009*\"set\" + 0.008*\"search\" + 0.008*\"page\" + 0.007*\"live\" + 0.007*\"share\"\n",
      "INFO:gensim.models.ldamodel:topic diff=1.040604, rho=0.707107\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"cooki\" + 0.012*\"govern\" + 0.011*\"govuk\" + 0.010*\"use\" + 0.009*\"set\" + 0.009*\"help\" + 0.008*\"search\" + 0.008*\"page\" + 0.008*\"new\" + 0.007*\"live\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.011*\"uk\" + 0.010*\"use\" + 0.010*\"govuk\" + 0.009*\"page\" + 0.008*\"govern\" + 0.008*\"help\" + 0.008*\"cooki\" + 0.008*\"improv\" + 0.008*\"new\" + 0.007*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.011*\"use\" + 0.009*\"improv\" + 0.009*\"set\" + 0.008*\"govuk\" + 0.008*\"help\" + 0.008*\"govern\" + 0.007*\"new\" + 0.007*\"addit\" + 0.007*\"cooki\" + 0.006*\"page\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"cooki\" + 0.010*\"govern\" + 0.009*\"new\" + 0.009*\"use\" + 0.009*\"page\" + 0.009*\"govuk\" + 0.008*\"set\" + 0.008*\"us\" + 0.007*\"help\" + 0.007*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.007*\"help\" + 0.007*\"busi\" + 0.007*\"govern\" + 0.006*\"support\" + 0.006*\"i\" + 0.006*\"work\" + 0.006*\"uk\" + 0.006*\"develop\" + 0.006*\"use\" + 0.005*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.804400, rho=0.577350\n",
      "INFO:gensim.models.ldamodel:-8.145 per-word bound, 283.0 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.013*\"uk\" + 0.011*\"govuk\" + 0.010*\"use\" + 0.009*\"page\" + 0.009*\"govern\" + 0.009*\"cooki\" + 0.008*\"help\" + 0.008*\"addit\" + 0.008*\"improv\" + 0.007*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.009*\"use\" + 0.009*\"natur\" + 0.008*\"improv\" + 0.008*\"help\" + 0.008*\"govuk\" + 0.008*\"set\" + 0.007*\"england\" + 0.007*\"cooki\" + 0.007*\"new\" + 0.007*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.015*\"flood\" + 0.011*\"cooki\" + 0.011*\"govuk\" + 0.010*\"use\" + 0.010*\"open\" + 0.009*\"page\" + 0.009*\"help\" + 0.009*\"set\" + 0.008*\"govern\" + 0.008*\"live\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"new\" + 0.010*\"cooki\" + 0.009*\"use\" + 0.009*\"govern\" + 0.008*\"govuk\" + 0.008*\"page\" + 0.008*\"set\" + 0.007*\"help\" + 0.007*\"us\" + 0.007*\"live\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.013*\"busi\" + 0.007*\"help\" + 0.007*\"innov\" + 0.007*\"support\" + 0.006*\"govern\" + 0.006*\"i\" + 0.005*\"develop\" + 0.005*\"school\" + 0.005*\"use\" + 0.005*\"uk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.537524, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"use\" + 0.006*\"i\" + 0.006*\"set\" + 0.006*\"water\" + 0.006*\"improv\" + 0.006*\"help\" + 0.005*\"govern\" + 0.005*\"environ\" + 0.005*\"us\" + 0.005*\"need\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.010*\"new\" + 0.009*\"cooki\" + 0.009*\"govern\" + 0.009*\"use\" + 0.008*\"govuk\" + 0.008*\"health\" + 0.008*\"page\" + 0.007*\"set\" + 0.007*\"help\" + 0.007*\"live\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"cooki\" + 0.012*\"govuk\" + 0.012*\"govern\" + 0.011*\"use\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"page\" + 0.009*\"search\" + 0.008*\"new\" + 0.008*\"live\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.007*\"govern\" + 0.006*\"new\" + 0.006*\"hs2\" + 0.005*\"rail\" + 0.004*\"help\" + 0.004*\"librari\" + 0.004*\"govuk\" + 0.004*\"support\" + 0.004*\"cooki\" + 0.004*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"use\" + 0.009*\"cooki\" + 0.009*\"new\" + 0.009*\"govuk\" + 0.009*\"page\" + 0.009*\"improv\" + 0.008*\"help\" + 0.008*\"flood\" + 0.007*\"addit\" + 0.007*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.406427, rho=0.445989\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"natur\" + 0.009*\"help\" + 0.009*\"use\" + 0.009*\"improv\" + 0.008*\"new\" + 0.007*\"england\" + 0.007*\"govuk\" + 0.007*\"set\" + 0.007*\"environ\" + 0.007*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.015*\"cooki\" + 0.015*\"govuk\" + 0.014*\"use\" + 0.012*\"page\" + 0.012*\"addit\" + 0.011*\"set\" + 0.011*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"water\" + 0.007*\"use\" + 0.007*\"i\" + 0.006*\"need\" + 0.006*\"set\" + 0.005*\"environ\" + 0.005*\"chang\" + 0.005*\"help\" + 0.005*\"improv\" + 0.005*\"work\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"govern\" + 0.012*\"cooki\" + 0.011*\"govuk\" + 0.011*\"use\" + 0.009*\"set\" + 0.009*\"help\" + 0.009*\"page\" + 0.009*\"new\" + 0.008*\"search\" + 0.008*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.011*\"busi\" + 0.007*\"i\" + 0.007*\"help\" + 0.007*\"support\" + 0.006*\"work\" + 0.006*\"school\" + 0.006*\"develop\" + 0.006*\"govern\" + 0.006*\"year\" + 0.005*\"innov\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.285578, rho=0.445989\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.011*\"use\" + 0.010*\"new\" + 0.009*\"project\" + 0.009*\"improv\" + 0.009*\"page\" + 0.009*\"cooki\" + 0.009*\"govuk\" + 0.008*\"help\" + 0.007*\"govern\" + 0.007*\"local\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.013*\"uk\" + 0.011*\"govuk\" + 0.010*\"use\" + 0.010*\"cooki\" + 0.009*\"govern\" + 0.009*\"page\" + 0.008*\"help\" + 0.008*\"addit\" + 0.008*\"set\" + 0.008*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"govern\" + 0.012*\"cooki\" + 0.012*\"use\" + 0.011*\"govuk\" + 0.010*\"new\" + 0.009*\"set\" + 0.009*\"help\" + 0.009*\"page\" + 0.008*\"search\" + 0.008*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"health\" + 0.010*\"new\" + 0.009*\"govern\" + 0.008*\"use\" + 0.008*\"cooki\" + 0.007*\"govuk\" + 0.007*\"help\" + 0.007*\"page\" + 0.007*\"set\" + 0.006*\"improv\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.012*\"page\" + 0.012*\"addit\" + 0.012*\"set\" + 0.011*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.259068, rho=0.445989\n",
      "INFO:gensim.models.ldamodel:-7.828 per-word bound, 227.3 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"cooki\" + 0.012*\"use\" + 0.012*\"govuk\" + 0.011*\"govern\" + 0.010*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"search\" + 0.008*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.007*\"use\" + 0.006*\"need\" + 0.005*\"set\" + 0.005*\"help\" + 0.005*\"chang\" + 0.005*\"us\" + 0.005*\"work\" + 0.005*\"govern\" + 0.005*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.024*\"flood\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.011*\"use\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"agenc\" + 0.008*\"addit\" + 0.008*\"set\" + 0.008*\"open\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"health\" + 0.011*\"new\" + 0.009*\"regul\" + 0.009*\"use\" + 0.008*\"medic\" + 0.008*\"cooki\" + 0.008*\"govern\" + 0.007*\"govuk\" + 0.007*\"help\" + 0.007*\"devic\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"natur\" + 0.009*\"england\" + 0.009*\"help\" + 0.008*\"use\" + 0.008*\"forest\" + 0.008*\"improv\" + 0.007*\"govuk\" + 0.007*\"new\" + 0.007*\"cooki\" + 0.006*\"woodland\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.294821, rho=0.445989\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.017*\"natur\" + 0.009*\"england\" + 0.009*\"help\" + 0.008*\"improv\" + 0.008*\"use\" + 0.007*\"new\" + 0.007*\"govuk\" + 0.007*\"cooki\" + 0.006*\"tree\" + 0.006*\"environ\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.014*\"busi\" + 0.008*\"support\" + 0.008*\"innov\" + 0.007*\"help\" + 0.007*\"school\" + 0.006*\"i\" + 0.006*\"govern\" + 0.006*\"year\" + 0.006*\"develop\" + 0.006*\"work\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"health\" + 0.010*\"new\" + 0.009*\"use\" + 0.008*\"regul\" + 0.008*\"cooki\" + 0.007*\"govern\" + 0.007*\"medic\" + 0.007*\"govuk\" + 0.007*\"help\" + 0.007*\"air\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.012*\"use\" + 0.012*\"cooki\" + 0.012*\"govuk\" + 0.012*\"govern\" + 0.010*\"new\" + 0.009*\"set\" + 0.009*\"page\" + 0.009*\"help\" + 0.009*\"search\" + 0.008*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.013*\"uk\" + 0.011*\"govuk\" + 0.011*\"use\" + 0.010*\"cooki\" + 0.010*\"govern\" + 0.009*\"page\" + 0.008*\"help\" + 0.008*\"support\" + 0.008*\"set\" + 0.008*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.256114, rho=0.407316\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.017*\"hs2\" + 0.015*\"rail\" + 0.012*\"librari\" + 0.008*\"phase\" + 0.008*\"railway\" + 0.006*\"ltd\" + 0.006*\"dementia\" + 0.006*\"speed\" + 0.005*\"billion\" + 0.003*\"hybrid\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.013*\"busi\" + 0.008*\"support\" + 0.007*\"innov\" + 0.007*\"school\" + 0.007*\"help\" + 0.007*\"work\" + 0.006*\"develop\" + 0.006*\"i\" + 0.006*\"year\" + 0.006*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.017*\"health\" + 0.010*\"new\" + 0.009*\"use\" + 0.008*\"regul\" + 0.008*\"air\" + 0.007*\"govern\" + 0.007*\"cooki\" + 0.007*\"help\" + 0.007*\"govuk\" + 0.007*\"medic\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"water\" + 0.008*\"i\" + 0.007*\"climat\" + 0.007*\"environ\" + 0.007*\"need\" + 0.006*\"use\" + 0.006*\"chang\" + 0.005*\"work\" + 0.005*\"govern\" + 0.005*\"also\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.012*\"page\" + 0.012*\"set\" + 0.012*\"addit\" + 0.011*\"search\" + 0.010*\"improv\" + 0.009*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.144842, rho=0.407316\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.012*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.011*\"govuk\" + 0.011*\"use\" + 0.011*\"agenc\" + 0.011*\"cooki\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"environ\" + 0.008*\"addit\" + 0.008*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"new\" + 0.011*\"use\" + 0.011*\"project\" + 0.010*\"improv\" + 0.009*\"local\" + 0.008*\"page\" + 0.008*\"govuk\" + 0.008*\"cooki\" + 0.008*\"help\" + 0.007*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.007*\"climat\" + 0.007*\"need\" + 0.006*\"water\" + 0.006*\"chang\" + 0.006*\"use\" + 0.006*\"environ\" + 0.005*\"work\" + 0.005*\"govern\" + 0.005*\"also\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.009*\"page\" + 0.008*\"set\" + 0.008*\"help\" + 0.008*\"support\" + 0.008*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.168848, rho=0.407316\n",
      "INFO:gensim.models.ldamodel:-7.658 per-word bound, 201.9 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"new\" + 0.011*\"use\" + 0.010*\"improv\" + 0.009*\"open\" + 0.009*\"local\" + 0.009*\"page\" + 0.008*\"govuk\" + 0.008*\"cooki\" + 0.008*\"project\" + 0.008*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.009*\"i\" + 0.007*\"need\" + 0.007*\"climat\" + 0.006*\"chang\" + 0.006*\"use\" + 0.005*\"environ\" + 0.005*\"water\" + 0.005*\"also\" + 0.005*\"work\" + 0.005*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.022*\"railway\" + 0.022*\"rail\" + 0.017*\"hs2\" + 0.016*\"speed\" + 0.007*\"phase\" + 0.006*\"line\" + 0.006*\"billion\" + 0.005*\"librari\" + 0.003*\"ltd\" + 0.003*\"construct\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.009*\"page\" + 0.009*\"help\" + 0.009*\"set\" + 0.008*\"support\" + 0.008*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.245162, rho=0.407316\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"new\" + 0.011*\"use\" + 0.010*\"improv\" + 0.009*\"local\" + 0.009*\"project\" + 0.008*\"open\" + 0.008*\"page\" + 0.008*\"govuk\" + 0.008*\"cooki\" + 0.008*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.012*\"govern\" + 0.010*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"search\" + 0.009*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.009*\"page\" + 0.009*\"help\" + 0.009*\"set\" + 0.008*\"support\" + 0.008*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.018*\"librari\" + 0.018*\"rail\" + 0.017*\"hs2\" + 0.015*\"railway\" + 0.011*\"speed\" + 0.007*\"phase\" + 0.007*\"billion\" + 0.005*\"dementia\" + 0.005*\"line\" + 0.005*\"ltd\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.008*\"climat\" + 0.008*\"water\" + 0.008*\"environ\" + 0.007*\"need\" + 0.006*\"chang\" + 0.006*\"use\" + 0.005*\"also\" + 0.005*\"work\" + 0.005*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.218794, rho=0.377224\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.008*\"water\" + 0.008*\"i\" + 0.007*\"environ\" + 0.007*\"need\" + 0.007*\"chang\" + 0.006*\"use\" + 0.005*\"work\" + 0.005*\"also\" + 0.005*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govuk\" + 0.012*\"govern\" + 0.012*\"cooki\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"us\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.019*\"health\" + 0.009*\"regul\" + 0.009*\"new\" + 0.008*\"use\" + 0.008*\"air\" + 0.008*\"medic\" + 0.007*\"help\" + 0.007*\"cooki\" + 0.006*\"govern\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"new\" + 0.010*\"project\" + 0.010*\"use\" + 0.010*\"improv\" + 0.010*\"local\" + 0.008*\"open\" + 0.008*\"page\" + 0.008*\"govuk\" + 0.008*\"cooki\" + 0.008*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.012*\"page\" + 0.012*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.009*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.115223, rho=0.377224\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.011*\"project\" + 0.010*\"use\" + 0.010*\"improv\" + 0.009*\"local\" + 0.008*\"page\" + 0.008*\"open\" + 0.008*\"govuk\" + 0.008*\"cooki\" + 0.008*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govern\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"search\" + 0.009*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.015*\"busi\" + 0.009*\"innov\" + 0.009*\"support\" + 0.008*\"school\" + 0.007*\"help\" + 0.007*\"work\" + 0.007*\"develop\" + 0.006*\"govern\" + 0.006*\"year\" + 0.006*\"programm\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.020*\"natur\" + 0.010*\"england\" + 0.009*\"help\" + 0.008*\"new\" + 0.008*\"tree\" + 0.008*\"improv\" + 0.008*\"wildlif\" + 0.007*\"use\" + 0.007*\"plant\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.008*\"help\" + 0.008*\"support\" + 0.008*\"addit\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.138024, rho=0.377224\n",
      "INFO:gensim.models.ldamodel:-7.531 per-word bound, 185.0 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"health\" + 0.011*\"regul\" + 0.010*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.008*\"devic\" + 0.007*\"air\" + 0.007*\"cooki\" + 0.007*\"govuk\" + 0.007*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"improv\" + 0.010*\"use\" + 0.010*\"open\" + 0.009*\"local\" + 0.008*\"page\" + 0.008*\"project\" + 0.008*\"govuk\" + 0.008*\"england\" + 0.008*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.024*\"railway\" + 0.023*\"rail\" + 0.019*\"hs2\" + 0.017*\"speed\" + 0.008*\"phase\" + 0.007*\"line\" + 0.007*\"billion\" + 0.007*\"librari\" + 0.004*\"freight\" + 0.004*\"erg\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.017*\"busi\" + 0.011*\"innov\" + 0.009*\"support\" + 0.008*\"school\" + 0.007*\"help\" + 0.007*\"programm\" + 0.006*\"govern\" + 0.006*\"develop\" + 0.006*\"the\" + 0.005*\"work\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"page\" + 0.010*\"agenc\" + 0.009*\"help\" + 0.008*\"addit\" + 0.008*\"environ\" + 0.008*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.224094, rho=0.377224\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.020*\"natur\" + 0.009*\"help\" + 0.009*\"england\" + 0.007*\"improv\" + 0.007*\"tree\" + 0.007*\"wildlif\" + 0.007*\"use\" + 0.007*\"govuk\" + 0.007*\"new\" + 0.007*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"new\" + 0.010*\"use\" + 0.010*\"improv\" + 0.010*\"local\" + 0.009*\"project\" + 0.009*\"open\" + 0.008*\"page\" + 0.008*\"govuk\" + 0.007*\"help\" + 0.007*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"us\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.020*\"librari\" + 0.019*\"rail\" + 0.018*\"hs2\" + 0.017*\"railway\" + 0.012*\"speed\" + 0.007*\"phase\" + 0.007*\"billion\" + 0.006*\"dementia\" + 0.005*\"line\" + 0.005*\"ltd\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.197202, rho=0.352947\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.012*\"page\" + 0.012*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.009*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"addit\" + 0.009*\"us\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.029*\"flood\" + 0.012*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"environ\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"water\" + 0.009*\"river\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.021*\"hs2\" + 0.020*\"rail\" + 0.016*\"librari\" + 0.012*\"railway\" + 0.010*\"phase\" + 0.009*\"speed\" + 0.008*\"dementia\" + 0.007*\"ltd\" + 0.006*\"billion\" + 0.006*\"freight\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.008*\"environ\" + 0.007*\"i\" + 0.007*\"water\" + 0.007*\"chang\" + 0.007*\"need\" + 0.006*\"work\" + 0.005*\"also\" + 0.005*\"govern\" + 0.005*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.104752, rho=0.352947\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.023*\"health\" + 0.009*\"regul\" + 0.009*\"new\" + 0.008*\"air\" + 0.008*\"medic\" + 0.008*\"use\" + 0.006*\"social\" + 0.006*\"help\" + 0.006*\"improv\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.011*\"innov\" + 0.010*\"support\" + 0.008*\"school\" + 0.007*\"help\" + 0.007*\"work\" + 0.007*\"develop\" + 0.006*\"programm\" + 0.006*\"govern\" + 0.006*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.021*\"natur\" + 0.010*\"england\" + 0.009*\"help\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.008*\"new\" + 0.007*\"improv\" + 0.007*\"plant\" + 0.007*\"use\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.121727, rho=0.352947\n",
      "INFO:gensim.models.ldamodel:-7.436 per-word bound, 173.2 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.008*\"climat\" + 0.007*\"need\" + 0.007*\"environ\" + 0.006*\"chang\" + 0.006*\"also\" + 0.006*\"work\" + 0.005*\"govern\" + 0.005*\"water\" + 0.005*\"use\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"improv\" + 0.010*\"open\" + 0.010*\"use\" + 0.009*\"local\" + 0.008*\"project\" + 0.008*\"england\" + 0.008*\"page\" + 0.007*\"govuk\" + 0.007*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"search\" + 0.012*\"addit\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"health\" + 0.011*\"regul\" + 0.010*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.008*\"devic\" + 0.007*\"air\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.024*\"railway\" + 0.023*\"rail\" + 0.019*\"hs2\" + 0.018*\"speed\" + 0.010*\"erg\" + 0.008*\"line\" + 0.008*\"phase\" + 0.008*\"billion\" + 0.007*\"librari\" + 0.006*\"suiss\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.211462, rho=0.352947\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.020*\"rail\" + 0.020*\"librari\" + 0.019*\"hs2\" + 0.018*\"railway\" + 0.013*\"speed\" + 0.008*\"phase\" + 0.007*\"billion\" + 0.007*\"erg\" + 0.006*\"line\" + 0.006*\"dementia\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.029*\"flood\" + 0.012*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"environ\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"river\" + 0.009*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.017*\"busi\" + 0.011*\"innov\" + 0.010*\"support\" + 0.008*\"school\" + 0.008*\"help\" + 0.007*\"programm\" + 0.006*\"develop\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"improv\" + 0.010*\"use\" + 0.010*\"local\" + 0.009*\"project\" + 0.009*\"open\" + 0.008*\"page\" + 0.007*\"help\" + 0.007*\"govuk\" + 0.007*\"england\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.179851, rho=0.332825\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.019*\"health\" + 0.010*\"regul\" + 0.009*\"new\" + 0.008*\"medic\" + 0.008*\"use\" + 0.008*\"air\" + 0.006*\"help\" + 0.006*\"devic\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.021*\"natur\" + 0.009*\"help\" + 0.008*\"england\" + 0.008*\"wildlif\" + 0.008*\"tree\" + 0.008*\"improv\" + 0.007*\"plant\" + 0.007*\"new\" + 0.007*\"govuk\" + 0.007*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.008*\"environ\" + 0.007*\"i\" + 0.007*\"chang\" + 0.007*\"water\" + 0.006*\"need\" + 0.006*\"work\" + 0.006*\"also\" + 0.006*\"govern\" + 0.005*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.011*\"innov\" + 0.010*\"support\" + 0.009*\"school\" + 0.008*\"help\" + 0.007*\"programm\" + 0.007*\"work\" + 0.007*\"develop\" + 0.006*\"govern\" + 0.006*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.098447, rho=0.332825\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.021*\"natur\" + 0.009*\"england\" + 0.009*\"help\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.008*\"plant\" + 0.008*\"new\" + 0.007*\"improv\" + 0.007*\"use\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.011*\"innov\" + 0.010*\"support\" + 0.008*\"school\" + 0.008*\"help\" + 0.007*\"work\" + 0.007*\"develop\" + 0.007*\"programm\" + 0.006*\"govern\" + 0.006*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.023*\"health\" + 0.010*\"regul\" + 0.009*\"new\" + 0.008*\"medic\" + 0.008*\"air\" + 0.008*\"use\" + 0.006*\"social\" + 0.006*\"help\" + 0.006*\"improv\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.109577, rho=0.332825\n",
      "INFO:gensim.models.ldamodel:-7.360 per-word bound, 164.2 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.018*\"natur\" + 0.009*\"help\" + 0.008*\"forest\" + 0.008*\"england\" + 0.007*\"tree\" + 0.007*\"wildlif\" + 0.007*\"woodland\" + 0.007*\"improv\" + 0.007*\"govuk\" + 0.007*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"help\" + 0.009*\"addit\" + 0.008*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.017*\"busi\" + 0.012*\"innov\" + 0.010*\"support\" + 0.008*\"school\" + 0.008*\"help\" + 0.007*\"programm\" + 0.007*\"govern\" + 0.006*\"develop\" + 0.006*\"the\" + 0.006*\"competit\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.008*\"devic\" + 0.007*\"air\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"also\" + 0.006*\"work\" + 0.005*\"govern\" + 0.005*\"water\" + 0.005*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.208773, rho=0.332825\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.020*\"natur\" + 0.009*\"help\" + 0.008*\"england\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.007*\"improv\" + 0.007*\"farm\" + 0.007*\"plant\" + 0.007*\"forest\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"environ\" + 0.008*\"climat\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"water\" + 0.006*\"also\" + 0.006*\"work\" + 0.006*\"govern\" + 0.005*\"year\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.010*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.020*\"rail\" + 0.019*\"librari\" + 0.019*\"hs2\" + 0.018*\"railway\" + 0.013*\"speed\" + 0.008*\"billion\" + 0.008*\"phase\" + 0.007*\"erg\" + 0.007*\"line\" + 0.006*\"dementia\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.016*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.007*\"air\" + 0.007*\"devic\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.168907, rho=0.315794\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.021*\"natur\" + 0.009*\"help\" + 0.008*\"england\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.007*\"plant\" + 0.007*\"improv\" + 0.007*\"new\" + 0.007*\"habitat\" + 0.007*\"farm\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.016*\"govuk\" + 0.015*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.012*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.021*\"hs2\" + 0.020*\"rail\" + 0.017*\"librari\" + 0.014*\"railway\" + 0.010*\"speed\" + 0.010*\"phase\" + 0.008*\"dementia\" + 0.007*\"freight\" + 0.007*\"billion\" + 0.006*\"ltd\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic diff=0.093474, rho=0.315794\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.030*\"hs2\" + 0.019*\"rail\" + 0.014*\"railway\" + 0.013*\"librari\" + 0.012*\"phase\" + 0.012*\"speed\" + 0.006*\"dementia\" + 0.006*\"freight\" + 0.005*\"ltd\" + 0.005*\"billion\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.021*\"natur\" + 0.009*\"england\" + 0.009*\"help\" + 0.009*\"tree\" + 0.008*\"wildlif\" + 0.008*\"plant\" + 0.007*\"new\" + 0.007*\"improv\" + 0.007*\"habitat\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"govern\" + 0.006*\"work\" + 0.005*\"also\" + 0.005*\"year\" + 0.005*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.011*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"environ\" + 0.009*\"water\" + 0.009*\"river\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.023*\"health\" + 0.010*\"regul\" + 0.009*\"new\" + 0.008*\"medic\" + 0.008*\"air\" + 0.007*\"use\" + 0.006*\"social\" + 0.006*\"help\" + 0.006*\"devic\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.102605, rho=0.315794\n",
      "INFO:gensim.models.ldamodel:-7.285 per-word bound, 155.9 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"i\" + 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"use\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.023*\"railway\" + 0.022*\"rail\" + 0.019*\"hs2\" + 0.017*\"speed\" + 0.010*\"erg\" + 0.010*\"line\" + 0.009*\"billion\" + 0.008*\"librari\" + 0.008*\"phase\" + 0.008*\"suiss\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.018*\"natur\" + 0.009*\"help\" + 0.008*\"forest\" + 0.008*\"england\" + 0.007*\"tree\" + 0.007*\"wildlif\" + 0.007*\"woodland\" + 0.007*\"improv\" + 0.007*\"govuk\" + 0.007*\"plant\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.008*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"search\" + 0.012*\"addit\" + 0.010*\"improv\" + 0.010*\"help\" + 0.010*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.204763, rho=0.315794\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"set\" + 0.013*\"page\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.009*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.008*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.016*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.007*\"air\" + 0.007*\"devic\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"improv\" + 0.010*\"local\" + 0.010*\"open\" + 0.009*\"project\" + 0.009*\"use\" + 0.008*\"england\" + 0.008*\"page\" + 0.007*\"help\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.160768, rho=0.301135\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.012*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"environ\" + 0.010*\"page\" + 0.009*\"water\" + 0.009*\"help\" + 0.009*\"river\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.022*\"natur\" + 0.009*\"help\" + 0.008*\"england\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.008*\"plant\" + 0.007*\"improv\" + 0.007*\"farm\" + 0.007*\"habitat\" + 0.007*\"new\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.012*\"innov\" + 0.011*\"support\" + 0.009*\"school\" + 0.008*\"programm\" + 0.008*\"help\" + 0.007*\"develop\" + 0.007*\"work\" + 0.006*\"govern\" + 0.006*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"project\" + 0.010*\"local\" + 0.010*\"improv\" + 0.009*\"open\" + 0.009*\"use\" + 0.008*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.090475, rho=0.301135\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.014*\"new\" + 0.011*\"project\" + 0.010*\"improv\" + 0.010*\"local\" + 0.009*\"open\" + 0.009*\"use\" + 0.008*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.012*\"govern\" + 0.012*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.029*\"hs2\" + 0.019*\"rail\" + 0.014*\"railway\" + 0.013*\"librari\" + 0.012*\"phase\" + 0.012*\"speed\" + 0.006*\"dementia\" + 0.006*\"freight\" + 0.005*\"line\" + 0.005*\"billion\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.095154, rho=0.301135\n",
      "INFO:gensim.models.ldamodel:-7.233 per-word bound, 150.4 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.008*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.007*\"devic\" + 0.007*\"air\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.017*\"busi\" + 0.012*\"innov\" + 0.011*\"support\" + 0.008*\"help\" + 0.008*\"school\" + 0.008*\"programm\" + 0.007*\"govern\" + 0.007*\"develop\" + 0.006*\"the\" + 0.006*\"competit\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.013*\"search\" + 0.012*\"addit\" + 0.010*\"improv\" + 0.010*\"help\" + 0.010*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.008*\"i\" + 0.007*\"environ\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"make\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.206370, rho=0.301135\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"environ\" + 0.008*\"climat\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"need\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.020*\"natur\" + 0.009*\"help\" + 0.008*\"england\" + 0.008*\"tree\" + 0.008*\"wildlif\" + 0.007*\"farm\" + 0.007*\"plant\" + 0.007*\"forest\" + 0.007*\"improv\" + 0.007*\"govuk\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.019*\"rail\" + 0.018*\"hs2\" + 0.018*\"librari\" + 0.017*\"railway\" + 0.013*\"speed\" + 0.009*\"billion\" + 0.009*\"line\" + 0.007*\"phase\" + 0.007*\"erg\" + 0.006*\"dementia\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.008*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"improv\" + 0.010*\"open\" + 0.010*\"local\" + 0.009*\"project\" + 0.009*\"use\" + 0.008*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.007*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.153717, rho=0.288345\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.020*\"hs2\" + 0.019*\"rail\" + 0.016*\"librari\" + 0.013*\"railway\" + 0.010*\"speed\" + 0.009*\"phase\" + 0.008*\"billion\" + 0.008*\"dementia\" + 0.007*\"line\" + 0.006*\"freight\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"environ\" + 0.008*\"climat\" + 0.007*\"chang\" + 0.007*\"i\" + 0.006*\"govern\" + 0.006*\"need\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.012*\"innov\" + 0.011*\"support\" + 0.009*\"school\" + 0.008*\"programm\" + 0.008*\"help\" + 0.007*\"develop\" + 0.007*\"work\" + 0.006*\"govern\" + 0.006*\"skill\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.089214, rho=0.288345\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.014*\"new\" + 0.011*\"project\" + 0.010*\"improv\" + 0.010*\"local\" + 0.009*\"open\" + 0.009*\"use\" + 0.008*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.012*\"addit\" + 0.012*\"search\" + 0.010*\"improv\" + 0.010*\"help\" + 0.010*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"govern\" + 0.006*\"need\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.022*\"health\" + 0.010*\"regul\" + 0.008*\"new\" + 0.008*\"medic\" + 0.008*\"air\" + 0.007*\"use\" + 0.006*\"social\" + 0.006*\"devic\" + 0.006*\"help\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.011*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"environ\" + 0.009*\"water\" + 0.009*\"river\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.090296, rho=0.288345\n",
      "INFO:gensim.models.ldamodel:-7.195 per-word bound, 146.5 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.011*\"govern\" + 0.011*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.009*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"cooki\" + 0.017*\"govuk\" + 0.016*\"use\" + 0.013*\"page\" + 0.013*\"set\" + 0.013*\"search\" + 0.013*\"addit\" + 0.011*\"improv\" + 0.010*\"help\" + 0.010*\"govern\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.021*\"railway\" + 0.020*\"rail\" + 0.018*\"hs2\" + 0.016*\"speed\" + 0.012*\"line\" + 0.011*\"billion\" + 0.009*\"erg\" + 0.008*\"librari\" + 0.007*\"phase\" + 0.007*\"suiss\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.007*\"devic\" + 0.007*\"air\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.027*\"flood\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.011*\"cooki\" + 0.010*\"agenc\" + 0.010*\"page\" + 0.010*\"help\" + 0.009*\"environ\" + 0.008*\"addit\" + 0.008*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.200508, rho=0.288345\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #2000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.018*\"rail\" + 0.018*\"hs2\" + 0.017*\"librari\" + 0.017*\"railway\" + 0.013*\"speed\" + 0.010*\"billion\" + 0.010*\"line\" + 0.007*\"phase\" + 0.007*\"erg\" + 0.006*\"dementia\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.028*\"flood\" + 0.012*\"agenc\" + 0.011*\"use\" + 0.011*\"govuk\" + 0.010*\"cooki\" + 0.010*\"environ\" + 0.010*\"page\" + 0.009*\"help\" + 0.009*\"water\" + 0.009*\"river\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.016*\"health\" + 0.011*\"regul\" + 0.009*\"new\" + 0.009*\"medic\" + 0.008*\"use\" + 0.007*\"devic\" + 0.007*\"air\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"cooki\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"environ\" + 0.008*\"climat\" + 0.007*\"i\" + 0.007*\"chang\" + 0.006*\"govern\" + 0.006*\"need\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"water\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.010*\"open\" + 0.010*\"improv\" + 0.010*\"local\" + 0.009*\"project\" + 0.009*\"use\" + 0.009*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.147335, rho=0.277057\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #4000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.016*\"busi\" + 0.012*\"innov\" + 0.011*\"support\" + 0.009*\"school\" + 0.009*\"programm\" + 0.008*\"help\" + 0.007*\"develop\" + 0.007*\"work\" + 0.006*\"govern\" + 0.006*\"fund\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.018*\"health\" + 0.010*\"regul\" + 0.009*\"new\" + 0.008*\"medic\" + 0.008*\"use\" + 0.007*\"air\" + 0.006*\"devic\" + 0.006*\"help\" + 0.006*\"govuk\" + 0.006*\"social\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*\"use\" + 0.013*\"govuk\" + 0.013*\"cooki\" + 0.012*\"govern\" + 0.011*\"new\" + 0.011*\"page\" + 0.010*\"set\" + 0.010*\"help\" + 0.009*\"addit\" + 0.009*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.009*\"support\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.020*\"hs2\" + 0.019*\"rail\" + 0.015*\"librari\" + 0.013*\"railway\" + 0.010*\"speed\" + 0.009*\"phase\" + 0.009*\"billion\" + 0.008*\"line\" + 0.007*\"dementia\" + 0.006*\"freight\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.086705, rho=0.277057\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #6000/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 2000 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.022*\"natur\" + 0.010*\"england\" + 0.009*\"help\" + 0.009*\"tree\" + 0.009*\"wildlif\" + 0.008*\"plant\" + 0.007*\"new\" + 0.007*\"habitat\" + 0.007*\"improv\" + 0.007*\"farm\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.027*\"hs2\" + 0.018*\"rail\" + 0.014*\"railway\" + 0.012*\"librari\" + 0.012*\"speed\" + 0.011*\"phase\" + 0.007*\"line\" + 0.007*\"billion\" + 0.006*\"dementia\" + 0.005*\"freight\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"climat\" + 0.007*\"environ\" + 0.007*\"chang\" + 0.007*\"i\" + 0.006*\"govern\" + 0.006*\"work\" + 0.006*\"need\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"the\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.014*\"new\" + 0.011*\"project\" + 0.010*\"improv\" + 0.010*\"local\" + 0.009*\"open\" + 0.009*\"use\" + 0.008*\"england\" + 0.007*\"page\" + 0.007*\"help\" + 0.006*\"work\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.015*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"search\" + 0.009*\"help\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.086338, rho=0.277057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:-7.157 per-word bound, 142.7 perplexity estimate based on a held-out corpus of 55 documents with 35581 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #6055/6055\n",
      "INFO:gensim.models.ldamodel:merging changes from 55 documents into a model of 6055 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*\"uk\" + 0.012*\"govuk\" + 0.012*\"cooki\" + 0.011*\"use\" + 0.010*\"govern\" + 0.010*\"page\" + 0.009*\"set\" + 0.009*\"addit\" + 0.009*\"help\" + 0.008*\"search\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.018*\"natur\" + 0.009*\"help\" + 0.009*\"forest\" + 0.008*\"england\" + 0.008*\"tree\" + 0.007*\"wildlif\" + 0.007*\"woodland\" + 0.007*\"plant\" + 0.007*\"govuk\" + 0.007*\"improv\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.007*\"climat\" + 0.007*\"i\" + 0.007*\"environ\" + 0.007*\"chang\" + 0.006*\"govern\" + 0.006*\"need\" + 0.006*\"work\" + 0.006*\"also\" + 0.005*\"year\" + 0.005*\"make\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.017*\"busi\" + 0.012*\"innov\" + 0.011*\"support\" + 0.008*\"programm\" + 0.008*\"school\" + 0.008*\"help\" + 0.007*\"develop\" + 0.007*\"govern\" + 0.006*\"uk\" + 0.006*\"competit\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"new\" + 0.011*\"open\" + 0.010*\"improv\" + 0.009*\"england\" + 0.009*\"local\" + 0.009*\"use\" + 0.008*\"project\" + 0.007*\"page\" + 0.007*\"help\" + 0.006*\"govuk\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.196557, rho=0.277057\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=126747, num_topics=10, decay=0.5, chunksize=2000) in 71.13s', 'datetime': '2023-05-04T13:24:47.103531', 'gensim': '4.1.2', 'python': '3.9.15 (main, Nov 24 2022, 14:31:59) \\n[GCC 11.2.0]', 'platform': 'Linux-5.13.0-1025-aws-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Train an LDA model on the corpus\n",
    "num_topics = 10\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ -8.32500848  -7.710724    -7.91949637 ...  -7.53473275  -8.19668896\n",
      "  -12.15087364]\n",
      " [ -5.88574248  -7.36145454  -6.20580701 ...  -6.47788808  -6.11558862\n",
      "  -12.14815904]\n",
      " [ -8.63291732  -7.96308229  -9.70172735 ...  -9.28670046 -14.35622578\n",
      "  -12.15100739]\n",
      " ...\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]\n",
      " [-15.992385   -15.23053983 -15.1318475  ... -14.66308252 -14.35909161\n",
      "  -12.1510877 ]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-a71bf3659da34eaa80371f56fc37f26d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.13998542  0.47429906  0.26552669 ...  0.65029031 -0.01166589\n",
      "  -3.96585057]\n",
      " [ 0.3375322  -1.13817986  0.01746767 ... -0.25461341  0.10768606\n",
      "  -5.92488436]\n",
      " [ 0.27563538  0.94547041 -0.79317464 ... -0.37814775 -5.44767307\n",
      "  -3.24245469]\n",
      " ...\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]\n",
      " [-0.77324685 -0.01140168  0.08729064 ...  0.55605563  0.86004653\n",
      "   3.06805044]] loaded from the file /dev/shm/joblib_memmapping_folder_239603_fab7c8c200b5417fbf897377e717fec7_fb43acfc161643aeb405c0a1d68b7d4e/239603-140125521122736-296f52a52d414001b4a9fd56d10482ed.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Convert the gensim LDA model to a format that pyLDAvis can use\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2396031401248621688645856133644\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2396031401248621688645856133644_data = {\"mdsDat\": {\"x\": [-0.11615917126445201, -0.020007005545110573, -0.0731886643862738, -0.10010706179820829, -0.11197496772321952, -0.04047058496482611, 0.0016119300945559934, -0.026220792845162676, -0.006633981804825139, 0.49315030023752204], \"y\": [0.09222553351410605, -0.13669002651835951, 0.06606936118106656, 0.04426592447723881, 0.005563716721147563, 0.013547305142572264, -0.21778601258234875, 0.04611317362660455, 0.0455702950652506, 0.04112072937272188], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [30.1812130053633, 16.7257250046819, 14.79527391489751, 12.18326682268433, 10.656661511714434, 5.384222599604409, 4.564649054534831, 4.327543663514763, 1.06854207597942, 0.1129023470250993]}, \"tinfo\": {\"Term\": [\"flood\", \"new\", \"regul\", \"uk\", \"busi\", \"natur\", \"govuk\", \"cooki\", \"page\", \"open\", \"use\", \"help\", \"improv\", \"england\", \"addit\", \"support\", \"billion\", \"river\", \"share\", \"water\", \"health\", \"search\", \"innov\", \"live\", \"govern\", \"project\", \"local\", \"climat\", \"public\", \"set\", \"angler\", \"rod\", \"guilti\", \"mmo\", \"ifca\", \"magistr\", \"aardman\", \"inhomeenvironmentwast\", \"topicwast\", \"plead\", \"angl\", \"surcharg\", \"crimestopp\", \"byelaw\", \"inhomeenvironmentcommerci\", \"555\", \"recyclingwast\", \"vmd\", \"flytip\", \"inventor\", \"psc\", \"tracey\", \"reinspect\", \"coars\", \"unlicens\", \"inshor\", \"db\", \"recyclingi\", \"bailiff\", \"flout\", \"fish\", \"inspector\", \"inspect\", \"hotlin\", \"fisheri\", \"permit\", \"salmon\", \"caught\", \"prosecut\", \"enforc\", \"trout\", \"wallac\", \"wast\", \"fine\", \"illeg\", \"regist\", \"0800\", \"offenc\", \"court\", \"cooki\", \"govuk\", \"licenc\", \"search\", \"set\", \"site\", \"addit\", \"page\", \"use\", \"menu\", \"report\", \"regul\", \"share\", \"improv\", \"inform\", \"agenc\", \"live\", \"content\", \"tab\", \"open\", \"you\", \"us\", \"help\", \"govern\", \"justic\", \"like\", \"paper\", \"environ\", \"new\", \"local\", \"chang\", \"death\", \"support\", \"droplet\", \"pierc\", \"eufor\", \"althea\", \"ohr\", \"rhetor\", \"daytoday\", \"shouldnt\", \"fossil\", \"briefli\", \"murder\", \"truth\", \"depress\", \"inabl\", \"reluct\", \"exponenti\", \"who\", \"quantum\", \"irregular\", \"updates7\", \"nationalist\", \"q3\", \"bonn\", \"y\", \"totem\", \"handwash\", \"hardwon\", \"med\", \"moral\", \"zhang\", \"shift\", \"compromis\", \"ofwat\", \"cotton\", \"co2\", \"zero\", \"singleus\", \"straw\", \"5p\", \"ocean\", \"emiss\", \"ive\", \"stirrer\", \"cloud\", \"climat\", \"decad\", \"pari\", \"plastic\", \"and\", \"genuin\", \"planet\", \"cleaner\", \"net\", \"divis\", \"ago\", \"green\", \"but\", \"that\", \"adapt\", \"i\", \"achiev\", \"power\", \"billion\", \"thing\", \"carbon\", \"im\", \"need\", \"want\", \"believ\", \"we\", \"ambit\", \"global\", \"much\", \"resourc\", \"polici\", \"ambiti\", \"action\", \"strategi\", \"tackl\", \"commit\", \"countri\", \"time\", \"environment\", \"year\", \"peopl\", \"develop\", \"invest\", \"increas\", \"reduc\", \"environ\", \"chang\", \"work\", \"also\", \"protect\", \"make\", \"water\", \"the\", \"ensur\", \"govern\", \"plan\", \"build\", \"impact\", \"help\", \"us\", \"use\", \"uk\", \"set\", \"inhomeenvironmentriv\", \"topicriv\", \"erosioni\", \"embank\", \"beck\", \"floodlin\", \"warden\", \"988\", \"reservoir\", \"culvert\", \"floodhit\", \"wilton\", \"sluic\", \"floodsth\", \"desmond\", \"supporti\", \"eventswint\", \"calderdal\", \"blockag\", \"1188\", \"erosiontop\", \"floodingfromenviron\", \"floodingth\", \"flood\", \"stockton\", \"eva\", \"foss\", \"gravel\", \"mytholmroyd\", \"3million\", \"tidal\", \"weir\", \"wall\", \"repair\", \"eros\", \"thame\", \"swim\", \"rainfal\", \"river\", \"warn\", \"0345\", \"pump\", \"easter\", \"catchment\", \"coastal\", \"storm\", \"bridg\", \"mainten\", \"bath\", \"allevi\", \"brook\", \"gate\", \"lake\", \"risk\", \"properti\", \"water\", \"scheme\", \"cumbria\", \"weather\", \"winter\", \"defenc\", \"agenc\", \"affect\", \"barrier\", \"work\", \"environ\", \"park\", \"page\", \"commun\", \"help\", \"use\", \"govuk\", \"cooki\", \"local\", \"open\", \"protect\", \"addit\", \"new\", \"improv\", \"share\", \"search\", \"set\", \"govern\", \"live\", \"us\", \"like\", \"tab\", \"menu\", \"support\", \"inform\", \"slaveri\", \"missil\", \"pork\", \"swine\", \"dstl\", \"munit\", \"dasa\", \"carolin\", \"mod\", \"fever\", \"fusion\", \"noke\", \"autonom\", \"15million\", \"battlefield\", \"nigerian\", \"allergen\", \"allergi\", \"kimbl\", \"chisholm\", \"bari\", \"ukaea\", \"pig\", \"simul\", \"fallon\", \"avers\", \"topicmilitari\", \"soldier\", \"suppress\", \"ballist\", \"radar\", \"fraud\", \"format\", \"traffick\", \"laboratori\", \"raf\", \"michael\", \"logist\", \"anim\", \"food\", \"queen\", \"african\", \"welfar\", \"exercis\", \"hon\", \"secretari\", \"rt\", \"technolog\", \"product\", \"minist\", \"lord\", \"chemic\", \"scienc\", \"defenc\", \"new\", \"govern\", \"use\", \"uk\", \"govuk\", \"cooki\", \"page\", \"us\", \"search\", \"set\", \"addit\", \"help\", \"live\", \"share\", \"open\", \"improv\", \"support\", \"state\", \"like\", \"menu\", \"content\", \"tab\", \"inform\", \"job\", \"travel\", \"justic\", \"chang\", \"report\", \"ambassador\", \"orbit\", \"herzegovina\", \"osc\", \"isf\", \"bilater\", \"lgbt\", \"turkey\", \"poland\", \"drc\", \"nato\", \"spaceflight\", \"balkan\", \"macedonia\", \"astroscal\", \"bih\", \"greek\", \"osman\", \"inhomeinternationalforeign\", \"rampl\", \"jec\", \"outer\", \"lgbti\", \"arab\", \"unoosa\", \"somalia\", \"numerica\", \"kosovo\", \"medal\", \"topicforeign\", \"bosnia\", \"satellit\", \"republ\", \"embassi\", \"kingdom\", \"space\", \"un\", \"stabil\", \"mission\", \"peac\", \"foreign\", \"maritim\", \"gender\", \"uk\", \"intern\", \"commonwealth\", \"british\", \"trade\", \"women\", \"media\", \"financ\", \"unit\", \"support\", \"govuk\", \"cooki\", \"govern\", \"right\", \"page\", \"use\", \"addit\", \"set\", \"search\", \"share\", \"help\", \"secur\", \"live\", \"open\", \"improv\", \"us\", \"new\", \"like\", \"menu\", \"chang\", \"tab\", \"credit\", \"includ\", \"content\", \"nation\", \"also\", \"inform\", \"job\", \"report\", \"woodland\", \"forestri\", \"pest\", \"grassland\", \"beetl\", \"stewardship\", \"spruce\", \"bark\", \"butterfli\", \"eighttooth\", \"nnr\", \"typographu\", \"wildflow\", \"transylvania\", \"meadow\", \"peatland\", \"mosaic\", \"romania\", \"pollin\", \"\\u015fi\", \"bee\", \"sssi\", \"topicforest\", \"countrysideforest\", \"woodlandi\", \"wyre\", \"honey\", \"harmoni\", \"scrub\", \"junip\", \"tree\", \"forest\", \"nativ\", \"wild\", \"speci\", \"treasur\", \"wildlif\", \"landscap\", \"reserv\", \"habitat\", \"bird\", \"hectar\", \"natur\", \"plant\", \"biodivers\", \"farm\", \"landown\", \"creation\", \"england\", \"farmer\", \"land\", \"conserv\", \"restor\", \"countrysid\", \"manag\", \"rural\", \"help\", \"protect\", \"commiss\", \"improv\", \"new\", \"govuk\", \"cooki\", \"page\", \"use\", \"live\", \"addit\", \"open\", \"set\", \"us\", \"local\", \"govern\", \"search\", \"share\", \"pupil\", \"gromit\", \"talent\", \"parent\", \"startup\", \"ipo\", \"techbas\", \"cohen\", \"wigtown\", \"turkmenabad\", \"getbizzi\", \"teacher\", \"fsb\", \"prize\", \"cofound\", \"mentor\", \"apprentic\", \"teach\", \"graduat\", \"bafta\", \"5g\", \"curriculum\", \"studio\", \"music\", \"creator\", \"preschool\", \"inhomeeduc\", \"multiacademi\", \"consumerfriendli\", \"schumpeterian\", \"tech\", \"student\", \"fintech\", \"founder\", \"entrepreneurship\", \"entrepreneur\", \"femal\", \"school\", \"hub\", \"young\", \"winner\", \"apprenticeship\", \"skill\", \"lab\", \"idea\", \"educ\", \"children\", \"innov\", \"primari\", \"competit\", \"cma\", \"youth\", \"market\", \"busi\", \"win\", \"programm\", \"award\", \"grow\", \"learn\", \"brazilian\", \"consum\", \"famili\", \"network\", \"develop\", \"fund\", \"support\", \"futur\", \"partnership\", \"social\", \"digit\", \"offer\", \"uk\", \"help\", \"the\", \"creat\", \"work\", \"govern\", \"new\", \"servic\", \"project\", \"make\", \"junction\", \"coventri\", \"a46\", \"binley\", \"redcar\", \"tunnel\", \"longest\", \"nda\", \"scarborough\", \"a3\", \"hindhead\", \"octobersaturday\", \"saltburn\", \"officershar\", \"enquiriesmemb\", \"5000media\", \"enquiriesjournalist\", \"693\", \"1448\", \"filey\", \"staith\", \"novembersaturday\", \"inhometransportroad\", \"0844\", \"cleveland\", \"infrastructureroad\", \"roundabout\", \"newport\", \"caith\", \"longdist\", \"highway\", \"sellafield\", \"heritag\", \"path\", \"traffic\", \"coastlin\", \"rout\", \"trail\", \"coast\", \"nuclear\", \"middlesbrough\", \"contract\", \"walker\", \"borough\", \"decommiss\", \"stretch\", \"england\", \"road\", \"mile\", \"project\", \"council\", \"north\", \"million\", \"new\", \"open\", \"local\", \"enjoy\", \"design\", \"fund\", \"improv\", \"citi\", \"use\", \"work\", \"page\", \"commun\", \"nation\", \"help\", \"plan\", \"govuk\", \"live\", \"addit\", \"share\", \"cooki\", \"govern\", \"us\", \"set\", \"search\", \"gp\", \"mhra\", \"statham\", \"ahwb\", \"rsh\", \"j\", \"zinc\", \"endnot\", \"aerosol\", \"n\", \"si\", \"respiratori\", \"cvmp\", \"mcp\", \"explanatori\", \"inhomehealth\", \"mdr\", \"ivdr\", \"vitro\", \"exhal\", \"vol\", \"ivd\", \"ukca\", \"marpol\", \"ema\", \"indoor\", \"s\", \"inhometransportmaritim\", \"inhomecoronaviru\", \"symptom\", \"patient\", \"sulphur\", \"medic\", \"oxid\", \"infect\", \"devic\", \"watson\", \"clinic\", \"referr\", \"viru\", \"m\", \"medicin\", \"nh\", \"coronaviru\", \"ship\", \"draft\", \"jonathan\", \"health\", \"veterinari\", \"healthcar\", \"air\", \"amend\", \"regul\", \"social\", \"regulatori\", \"new\", \"spread\", \"standard\", \"use\", \"public\", \"pollut\", \"safeti\", \"help\", \"govuk\", \"cooki\", \"improv\", \"uk\", \"govern\", \"page\", \"live\", \"set\", \"addit\", \"like\", \"search\", \"the\", \"us\", \"share\", \"hs2\", \"erg\", \"suiss\", \"503km\", \"eur21\", \"ninefigur\", \"0207\", \"ifc\", \"inhomeexport\", \"honor\", \"nationsit\", \"communicationsukexportfinancegovuk\", \"izmir\", \"ukt\\u00fcrkiy\", \"englisht\\u00fcrk\\u00e7eth\", \"electricpow\", \"britishmad\", \"7817\", \"830831\", \"alignmentcontactmedia\", \"citiestreasuri\", \"collaborationturkey\", \"commitmentsuk\", \"cop26intern\", \"dedeoglu\", \"fasten\", \"financepublished17\", \"ichikawa\", \"i\\u0307zmir\", \"nebati\", \"dementia\", \"railway\", \"rail\", \"0\", \"librari\", \"freight\", \"speed\", \"line\", \"billion\", \"electrif\", \"phase\", \"construct\", \"17\", \"biggest\", \"ltd\", \"map\", \"supplier\", \"updat\"], \"Freq\": [15778.0, 28953.0, 9287.0, 13645.0, 8003.0, 5532.0, 41852.0, 41766.0, 34502.0, 24484.0, 42976.0, 33180.0, 30022.0, 5499.0, 31236.0, 20620.0, 1638.0, 5416.0, 23523.0, 8190.0, 2775.0, 30062.0, 3364.0, 26170.0, 33456.0, 5735.0, 17943.0, 5714.0, 10180.0, 33503.0, 764.6277709894509, 560.3907881873888, 350.3901933752596, 273.0698749884461, 265.7603176580677, 255.90362906382236, 235.6672814891195, 220.84528173214318, 215.01876028551905, 210.58785916170012, 542.8596675307342, 163.30073077282682, 152.35253316779284, 211.7796598326945, 139.6502266377961, 136.98208773145123, 128.39867921048648, 127.65468642695116, 127.21044369600676, 177.0252161340117, 121.70383447352486, 117.9205544145431, 115.17986630378361, 182.92549824600204, 101.21145327999808, 168.31879240670654, 79.50990425740675, 76.04726329913817, 74.21682368093336, 74.18298930721423, 5220.749296577381, 594.3234286962748, 1734.1126197223227, 235.130188929529, 1956.7953415863124, 1285.161528483027, 615.1368816551403, 251.93410419012017, 493.22223566945553, 1403.0199262974616, 348.1700700353941, 504.6115262069598, 4649.026121904042, 993.4701833683342, 1986.2681789743917, 1116.9200618982013, 490.23214236193576, 580.3672946945628, 1291.514014355072, 20837.0663403757, 20623.640980066626, 4880.545032269836, 14969.00202861071, 15955.02325010631, 5420.1455237091195, 14920.509254282826, 15983.86017433432, 19105.53946290843, 9014.49506288034, 7578.390207221569, 5032.6945591953145, 10467.359338569611, 12588.595066859072, 7569.820540129112, 8014.184417168664, 11100.355023762222, 7138.784118083741, 7444.9760969781255, 10219.952152437014, 6049.870402785146, 11013.616081061255, 11863.52170361773, 11729.284630643293, 5915.008077507015, 8259.530319798732, 5816.129603807814, 7681.48650336979, 9371.722361121447, 6558.57933222254, 6611.912966060259, 5673.748744185157, 6022.608516246871, 543.373287462706, 137.48956254514536, 135.4857345202486, 134.6723201775524, 134.6723201775524, 141.09299067283425, 107.58762035152265, 100.30010457530355, 91.9139600888758, 86.91807624973028, 86.77798188338907, 84.4628234534946, 83.01125898734769, 76.21462017497416, 75.95562734491476, 72.72736669365285, 72.85812910829624, 71.93672116219057, 71.20691074852813, 74.24446582162008, 68.66321541109882, 70.83710458864698, 67.85300443106146, 67.70247036336048, 67.36419910294738, 65.59365548413676, 70.61186215737956, 62.55581268385988, 63.011812317439144, 61.980828268406924, 182.18471022463063, 130.1548786924105, 111.710300138944, 100.56795940265873, 84.32525149547459, 1054.5610283831752, 182.47197704606225, 103.52070209254022, 88.34386036010768, 861.2138077465959, 1431.315684689453, 213.20110612363302, 86.1732272952023, 158.5249038080422, 4916.706381851919, 450.9346376703026, 248.603480956984, 1423.3843889278648, 1336.9776902039061, 221.27641893218362, 397.4635327142498, 331.4160643231392, 1158.0939396992626, 274.57016885144714, 276.2547539737606, 1701.2202037828022, 753.6972176461256, 785.7870085812186, 860.9260805616684, 4732.274330494881, 1370.3724581953318, 1422.962695965635, 1235.0979442015384, 720.4973368679578, 1231.703070328391, 395.51005694671534, 3935.8681938813556, 1734.031844679441, 473.8433994069809, 2553.506642617215, 697.0294636655284, 2025.1651056584892, 1316.4417953795128, 1076.4959678715602, 1403.7279418351084, 600.009084543964, 2129.3584084094223, 1313.0085578817084, 1516.3236456584175, 2267.8986643157673, 2360.3209328404423, 2194.693809563274, 2446.125169202787, 3427.256148356733, 2995.7123280420615, 2720.0202725329573, 1987.8778108548659, 1728.5417030820272, 2056.1923776450817, 4593.78962511704, 4352.624524890238, 3904.7598979194872, 3763.9494361604397, 2711.4783813213285, 3110.98458523044, 2556.9543048378905, 3053.5968994695295, 2078.986201962288, 4154.399062469524, 2174.069371493172, 1873.4114966932814, 1825.2453521184234, 2938.118706343992, 2657.1554888070164, 2875.378527670937, 2276.290937391234, 2037.489803715797, 702.9113056835653, 692.5259423870245, 614.1520990231659, 291.1564410547643, 258.06974528356125, 213.22506921115507, 197.78785770646635, 197.45459148990696, 385.58044377764656, 168.71259037859417, 157.55936244358395, 153.0356226680104, 152.73803991224344, 139.68333995308484, 135.84093708972736, 118.18063579693857, 116.22476473555741, 112.2908880076578, 112.32528190923948, 111.31064484469533, 109.66343656756305, 101.15676591042802, 97.80318234342772, 15663.344535595157, 94.49279900998786, 90.92735443896737, 90.14443928707755, 89.74677146545977, 84.71855952021423, 82.44296261398662, 488.4769862582897, 340.38135950477835, 582.185147876126, 868.2239732029935, 1114.8469461522534, 601.7047984201591, 183.94625514259522, 427.26300189008145, 4764.89739297298, 1456.4752754780668, 197.8612268384048, 551.5748130188045, 323.324393759839, 517.1276322802509, 2844.8178438718232, 643.8227524450685, 1155.467721933472, 1745.7867984672282, 441.1455140231255, 495.7154857228917, 277.7125147964531, 347.7958159301115, 678.657479662224, 3934.9093933412873, 1248.1023255083514, 4908.828490062652, 2814.820253254224, 539.1837779203092, 783.766260968924, 543.5118779893032, 2368.6748466848367, 6010.39005786798, 1111.3746382984416, 755.9061486789268, 4684.767712936367, 5051.57699348452, 886.0888477934733, 5735.421826879328, 2169.145422296356, 5534.865234643709, 6404.64984597787, 6267.661192706626, 6123.259338633489, 3695.560416670694, 4285.207972213332, 2385.812681366598, 4798.297248017785, 4611.84056044953, 4648.792540276139, 3940.251154821475, 4391.774973501251, 4537.189199426371, 4495.984389065753, 3964.975126982444, 3945.1007119123774, 3246.7329984290777, 2887.590758232723, 2614.6749625353, 2622.4685154328276, 2415.524940040932, 402.481152439542, 359.59290076443045, 312.5989674687567, 295.16858540357396, 272.8893341577709, 266.633089339354, 249.50006613209854, 237.6777810279164, 318.46597147032656, 302.91142889918467, 203.01383095979898, 184.85069865562156, 229.95089391872392, 150.75205457532869, 148.17649540051795, 131.51850303866306, 131.12794882398467, 117.49012874746141, 116.81133959808783, 113.3844331545819, 109.98683364672593, 108.4766916147907, 388.04570865454957, 89.30721013935171, 87.85343942178109, 87.08558373543458, 86.3012337284517, 89.43748104020152, 79.61261554951592, 78.38184301691479, 145.22255189944417, 280.6642580940264, 358.9010195536962, 250.84537673620892, 233.91090015855352, 138.8702753438533, 571.4197150059813, 301.819045183816, 1804.6081730561602, 3105.060708190853, 376.71091770284767, 308.649691968655, 571.06101767487, 565.6650763805721, 1042.7591859401257, 1470.7172941751019, 920.035292585894, 1799.0025911122832, 1572.0550468087968, 1803.9034093688256, 561.1170870818524, 432.8098557129714, 733.6289859776674, 1718.05536775375, 5409.13697436403, 5481.210434860321, 6336.4088095538955, 3084.0673572557707, 6138.935030369583, 6108.731574948915, 5178.390748196883, 4379.883765713875, 4444.617847350469, 4713.715290190813, 4486.830788983229, 4487.40667201529, 3913.450701963214, 3590.5533541548043, 3559.59740561072, 3857.672763971981, 3085.9644626168247, 1885.2018408963684, 2846.7599544162736, 2612.6221438238917, 2327.539028588131, 2332.5511782693497, 2308.7445850689487, 2075.5094979561727, 2022.3404710612738, 2015.8850368866586, 1884.3015765446169, 1864.9787558723765, 1845.7959823390415, 399.8587022624078, 421.9541183086069, 334.054618234957, 317.72067956067013, 306.4192768549391, 292.48361943855355, 250.94571656664027, 248.40253675602293, 246.2340204096484, 240.15473416755836, 221.84161521122533, 187.96271789891358, 185.79836909694492, 183.60423640724272, 166.89945961005927, 166.6487347611246, 159.1235917055631, 158.79434347596037, 158.3858752380323, 158.38127993980177, 198.4912549942654, 149.06753926338283, 145.14715101738156, 144.25654311138268, 141.88725134125488, 135.75557136641402, 132.7334783737175, 130.0532095730685, 129.31290213951408, 510.5557701746523, 621.5232762763791, 322.59338225726066, 779.3964580017226, 633.8431241739904, 2369.441557295677, 646.2219287701764, 470.0748103388379, 685.349035529433, 445.344528505092, 428.1888625121129, 707.8314832361762, 327.9177441065311, 6012.844096014676, 1961.5110670328793, 347.8593829809993, 1418.918393065627, 1385.033348319778, 744.3728547900315, 756.1892242144909, 745.760243766442, 854.1338506754856, 3509.9630954330783, 4940.087172120017, 4926.756114180931, 4216.33630477333, 1024.166435949583, 4091.8064603502976, 4487.1413359355, 3644.186085953457, 3737.90553123608, 3519.228389933471, 3088.761970514311, 3603.0227732165595, 1191.0577926800495, 2953.3473311676817, 2854.99621635789, 3063.5926421549434, 2941.555209274311, 2699.5933985206702, 2342.59797602355, 2111.021148181708, 1978.833972549759, 1850.2016023021888, 1678.837456036567, 1665.0327890628273, 1696.431581921351, 1500.863902103196, 1586.5226076556432, 1550.1067268524027, 1520.3979282473856, 1523.4670008315666, 1510.3091356897946, 917.1853817441963, 442.92028259510465, 386.9583659859744, 360.9444613452197, 334.2888397017281, 319.0690492637382, 251.36799192316008, 212.55306681647227, 210.33544935087352, 204.81336351819309, 176.8538073068065, 170.88347544180755, 140.24439692404695, 205.5585960114218, 138.00366075191027, 120.56102890982505, 497.1834929626267, 109.47612781382209, 105.18718786000073, 102.82713470965034, 98.0687874501917, 95.9253857254795, 94.59656643874155, 94.2424068731747, 398.5051472232798, 91.71679933153473, 151.12230408827534, 84.49240113421772, 80.7381924167133, 1670.0744151462688, 1813.8658539597361, 262.7705776382771, 604.1619483385422, 1074.3169070173894, 161.0472685427893, 1589.4507912341242, 1026.7273460027586, 582.5961964532577, 1078.1665668475175, 317.7082318099918, 372.3270898863167, 3874.8339279942943, 1508.714834119699, 1038.940148524033, 1342.0923882274521, 469.0258963783544, 511.2404569208104, 1746.3803736177294, 747.1973856886411, 904.9943147589833, 636.4717732947049, 561.1330461779717, 434.7843256547445, 1066.2851324532867, 626.6008759861434, 1892.166541854276, 1037.0754371257567, 589.6008681405733, 1409.653350158326, 1321.9755568153807, 1415.8974756792788, 1398.6405468234173, 1280.8617035786467, 1323.7441378655315, 1115.0419905523, 1113.9942389162545, 1056.9601922914283, 1109.629644477256, 1061.3572912366274, 955.0372250075866, 1020.080619075216, 994.7559532228594, 939.8439865028533, 361.55985715517824, 289.466526320623, 272.052839539358, 199.16729408926804, 188.8657190968621, 189.3851931058539, 184.81353704574755, 154.00020372897174, 154.00020372897174, 153.92165862224294, 153.9179732213407, 146.62649129538778, 125.35523675837942, 146.07725139217715, 111.28996703434778, 111.84486067757888, 107.38315939098173, 106.30703279741915, 102.06974311007889, 94.59104910022597, 320.50490989988026, 89.38187103347829, 76.69688341127701, 79.8618261349573, 69.5264229314289, 66.43205772900414, 66.09028390982236, 63.54330020532374, 61.590236655030836, 61.590236655030836, 774.6714371672115, 367.7573613269484, 124.7756027676143, 161.70825112565498, 139.90932465662516, 816.9202030374981, 803.7383616013315, 1475.9682175532291, 634.0050453121788, 1000.7416343483206, 193.84446537822, 142.91697823895822, 1071.9558923688044, 238.66260481047524, 754.8891264742603, 763.2098403612727, 795.8144146250888, 2195.925020298357, 347.4764954630811, 1113.0668744696386, 376.4931434905746, 359.5887121067088, 938.6855975698812, 3102.819093298921, 262.4316188691929, 1493.8048878471366, 743.4531599564141, 697.6114632428978, 550.1696712268916, 344.5244055812825, 473.1153091630427, 475.0099821427909, 573.8141564267141, 1205.4161528324155, 1047.53282434883, 1939.903905021261, 875.9076410101616, 694.1573212472816, 559.2285122832429, 988.3650530092915, 586.0057557681847, 1129.2815495710074, 1473.3060179560355, 1097.3313852446713, 719.5883464140163, 1016.2878279814914, 1186.9641881060581, 1088.3791276575948, 813.8729628051328, 760.2129393548673, 734.2868140805625, 249.31729842266344, 205.4479019734255, 186.42124640832787, 185.19944981084728, 161.63839926591473, 365.7021344351687, 181.17503505349475, 163.80005314367028, 137.37950821412318, 127.11871963719561, 123.8903139491286, 123.44685806490533, 107.18442672646776, 101.06003852077508, 100.42765033956225, 100.42764041351954, 99.81798287011831, 99.81798287011831, 99.81798287011831, 94.73734783377225, 93.46987158772879, 92.5751281715821, 89.01070608561183, 101.49998058587813, 235.51332949117034, 83.2531645664874, 79.68325834191849, 67.62870480828845, 66.53177782813101, 65.35383945037557, 633.1959625687757, 291.4404458816636, 448.00050302709883, 1061.9917566766003, 435.3807308432914, 389.60078954483856, 759.2082262248099, 326.5918982769474, 907.1902766664517, 511.8450479788693, 320.7642391921019, 431.45438538793826, 224.16804133956137, 353.4102789984112, 177.62542262325152, 263.3305281866213, 1606.0152881458496, 799.5796653700804, 336.78999396810286, 1423.7173992886324, 921.9318794446522, 774.8566722652236, 924.1326816348658, 2292.770390503541, 1809.0346249529807, 1548.0211527688216, 377.3254113389837, 571.5399512184263, 805.6147787476169, 1683.1269817871362, 472.35944858943236, 1449.9235813997605, 1015.9264217980779, 1260.0290141254777, 728.4804537289459, 837.4543474356217, 1129.862939819291, 676.53429588081, 1065.275450422576, 950.8008614780042, 987.0492607055307, 925.0844700184812, 1007.530577830144, 957.3840512299536, 869.0569616319938, 772.8520880873505, 721.9268038801089, 114.90614627175911, 106.56226892079283, 104.03010269735107, 72.30147336726887, 61.97684889118409, 54.90624070260978, 64.89584130064792, 51.660562390673334, 42.88070842389036, 43.84371274093667, 34.46062021152666, 33.9440113034085, 31.12723629820392, 30.995483049252588, 34.0147664523933, 25.893146884188383, 20.777590542684948, 20.777583189972802, 20.777203299845237, 20.67397122130979, 20.67397122130979, 20.67327761546398, 20.67327761546398, 20.6723193119809, 20.62724963742752, 68.43368698243368, 15.126555782791645, 14.10440992559578, 13.26296064575375, 39.22000627485041, 227.75649383461737, 33.687683503464775, 373.5677362652134, 77.47802780873883, 78.67549541070952, 308.7472259514094, 63.952880476912696, 58.042858686182726, 35.09127458684357, 145.95263018336317, 33.87353800838931, 141.92886336305426, 123.1676830503019, 193.52597184790417, 244.34499672618972, 168.62645332685184, 90.97089183243416, 556.6731307435223, 134.8629167939808, 79.17508279020876, 276.04665630811894, 105.96349345443866, 461.16155681965495, 197.57490455098616, 132.8120983221071, 388.34390345247647, 125.35710504794332, 161.17004833195597, 329.32821232401176, 228.48253004280141, 155.74872700494046, 127.7387171374754, 258.41314675183554, 254.96605804697683, 253.72850836019208, 235.09920629249754, 191.20308341938133, 214.8826399411031, 212.75929431661734, 200.51661684098235, 204.77219016622675, 198.97350804462565, 181.23331553690608, 180.12662451909483, 169.446212105862, 176.5705784238427, 158.4579857513323, 78.9350427844614, 39.72042254777725, 30.34952463534948, 19.855624521931777, 19.855624521931777, 19.855624521931777, 11.210466162972285, 11.170278219054092, 10.328075771274136, 10.186416816755063, 10.052574400236525, 9.991364879034629, 9.985345543980149, 9.985345543980149, 9.95791722305302, 9.944770191473008, 9.909057127512714, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 9.79547079376656, 16.8046182193775, 90.05190419572178, 87.52131814545638, 11.738949486000122, 36.156052215682514, 22.899535239367626, 68.6427277263323, 56.350033598430905, 50.94023105851348, 11.442178969088543, 32.961930550919156, 20.39989422703331, 14.590263234581329, 14.283470851097373, 13.686661704712371, 10.989583187865248, 10.559156707766709, 10.510926410146403], \"Total\": [15778.0, 28953.0, 9287.0, 13645.0, 8003.0, 5532.0, 41852.0, 41766.0, 34502.0, 24484.0, 42976.0, 33180.0, 30022.0, 5499.0, 31236.0, 20620.0, 1638.0, 5416.0, 23523.0, 8190.0, 2775.0, 30062.0, 3364.0, 26170.0, 33456.0, 5735.0, 17943.0, 5714.0, 10180.0, 33503.0, 765.5841370454414, 561.1251686362868, 351.1255851471352, 273.8067732599868, 266.49412138997945, 256.63744372995967, 236.40557962053933, 221.5792168830444, 215.75273954889667, 211.32169164246253, 544.9781549236028, 164.03453136273387, 153.08631352738604, 212.86850872186614, 140.38404995713213, 137.71598951538078, 129.13251904530316, 128.3885733340228, 127.9443227760613, 178.07001069659285, 122.43964700204052, 118.65439333120794, 115.91407569187555, 184.13886417855838, 101.94566756512788, 169.56634569060256, 80.24369867743034, 76.78116378162102, 74.95060845600374, 74.91694415639343, 5320.034962620006, 606.8492980655861, 1790.6388969952027, 238.39791529071323, 2027.5421794262613, 1329.1775634797539, 636.2572842009737, 256.4125082102002, 509.1158549618742, 1494.6833657849252, 357.9107864863415, 527.6629730361916, 5221.095003196888, 1063.4713301232623, 2195.5023104593597, 1215.9301273051267, 524.889702525835, 631.364889673996, 1538.9813004296632, 41766.42688130038, 41852.94480975737, 7866.3614243955935, 30062.0224936446, 33503.771232310064, 9428.455591629998, 31236.426951845027, 34502.36339211704, 42976.38574248663, 18052.670183302245, 15367.820284861233, 9287.822812806115, 23523.140866026708, 30022.98969826164, 15821.46504253202, 17067.970869459463, 26170.07125825722, 14977.66056337554, 15894.70326277196, 24484.786779197784, 12187.902098581273, 27637.58822296382, 33180.70737588321, 33456.55040198806, 12506.07124399018, 20632.255268677665, 12237.837483503576, 19676.816569971787, 28953.97716064518, 17943.04360529034, 18706.18434912037, 12146.058897245528, 20620.86407250793, 544.0875509490565, 138.1981258616395, 136.1942994683907, 135.38090274713394, 135.38090274713394, 141.93142674696168, 108.30059003098269, 101.0088018970284, 92.63184884202691, 87.6276585006341, 87.48654063664898, 85.17219484476003, 83.71983592074098, 76.92319023881116, 76.66418428601536, 73.43871386290914, 73.5754710988431, 72.6453949581622, 71.91553737906828, 75.00136621226673, 69.37187267790272, 71.57562323788113, 68.56156942571812, 68.41470537319628, 68.07302655870585, 66.30646345040846, 71.41737016858184, 63.26965026451494, 63.736664473984256, 62.69495602897423, 184.30958465754404, 131.9496355689541, 113.1576254787466, 101.80490884656854, 85.33932349545363, 1105.3884680808435, 186.39544084674506, 105.1859045618206, 89.52944002677538, 915.1265735196109, 1548.7160782746776, 221.03557231644967, 87.39374321464464, 163.91021040792145, 5714.675873724202, 483.4852612874899, 260.73377699293434, 1612.7840565009817, 1520.576570978462, 233.51931834567677, 436.84628050253343, 360.6593662141627, 1373.6567978156834, 297.7073402049136, 302.14284245768204, 2151.1555706864638, 889.7272233299325, 932.3732087683376, 1039.5422064266259, 6728.851315467714, 1758.5202676096117, 1887.3562048879362, 1638.4404598217222, 896.5005365496934, 1654.6179823587045, 458.5546845794719, 6444.71707070648, 2541.435255411188, 565.6865829391136, 4069.414217809341, 887.9655275374138, 3128.0208917374734, 1888.8172967154069, 1492.9465825638222, 2085.4090015334114, 755.363380926217, 3718.9383224535377, 2042.8795261807802, 2459.2363835993992, 4161.960446153617, 4541.712621537308, 4134.702198189125, 5075.608557188781, 8951.957747915303, 7732.0193687230085, 6684.851390684701, 4138.073215338433, 3282.1922103076645, 4477.108612939579, 19676.816569971787, 18706.18434912037, 15811.876921887335, 15532.670637442674, 8159.932719308494, 12577.466729562964, 8190.17071167813, 13321.267881520987, 5263.533105705589, 33456.55040198806, 6260.489158313974, 4195.881477212567, 3824.20901178163, 33180.70737588321, 27637.58822296382, 42976.38574248663, 13645.197943660398, 33503.771232310064, 703.623824669984, 693.2385480693897, 614.864688048071, 291.8700515899706, 258.83219131491495, 213.93739533001252, 198.50041165624143, 198.1669543741144, 387.1769806147907, 169.42932641005274, 158.2717270807086, 153.74804273367047, 153.45050700983452, 140.39572318394806, 136.55428525827722, 118.8929834583707, 116.93709081939359, 113.00323851289512, 113.03878252672818, 112.0229943492368, 110.37576489671467, 101.86907361215802, 98.51564229818477, 15778.999834175394, 95.2051845058165, 91.63974516597342, 90.8567522888716, 90.48224944250913, 85.43089279732672, 83.15543123435376, 493.0788359636509, 343.84368633301057, 593.3611121529239, 899.2231280311594, 1161.3469519687267, 625.7547155565708, 187.75538489545085, 447.8574123500136, 5416.990208526981, 1619.2361541540379, 203.07535800037428, 593.1965857394127, 341.65105241526794, 561.3756218893444, 3443.9113877929112, 710.6795975240511, 1336.4337399288731, 2089.1987542028187, 480.7561405608334, 550.6307703920412, 293.6773026811679, 377.721469727794, 806.4228171063052, 5958.077868689428, 1647.5698383996546, 8190.17071167813, 4482.204049255556, 634.2978848944886, 1012.4541718945366, 651.6840079646237, 4416.00555289883, 17067.970869459463, 1770.294406773093, 1041.6379649411701, 15811.876921887335, 19676.816569971787, 1391.740480750629, 34502.36339211704, 6498.78301068316, 33180.70737588321, 42976.38574248663, 41852.94480975737, 41766.42688130038, 17943.04360529034, 24484.786779197784, 8159.932719308494, 31236.426951845027, 28953.97716064518, 30022.98969826164, 23523.140866026708, 30062.0224936446, 33503.771232310064, 33456.55040198806, 26170.07125825722, 27637.58822296382, 20632.255268677665, 15894.70326277196, 18052.670183302245, 20620.86407250793, 15821.46504253202, 403.2684193204594, 360.3754265281149, 313.38077963572294, 295.9568097380287, 273.6716101568782, 267.4150291139739, 250.2818947767922, 238.47820198990794, 319.58335938109474, 303.98630409910896, 203.79857932999286, 185.6324763189804, 230.93530643844193, 151.53909388604785, 148.9588077964543, 132.30065162534325, 131.9097280247534, 118.27190398527283, 117.59314915078296, 114.16677029612971, 110.768604492601, 109.26033352203898, 391.3713557390596, 90.09536822876281, 88.63525920049895, 87.8674080621001, 87.08307483059617, 90.27752480628648, 80.39583558687686, 79.16362742027614, 146.94913265853984, 285.968414476819, 371.62681952580004, 258.9404796187077, 245.7967626652742, 143.34078234589236, 636.8997112198729, 328.71197624690046, 2345.7619152525385, 4305.854381180536, 428.03097957215454, 348.1721184963388, 695.7657976557448, 716.4097324036439, 1480.4253050611358, 2373.3877252951465, 1387.228759605661, 3191.3021935369293, 2914.155998793773, 3809.922980943426, 790.6426396409196, 565.9895963434725, 1235.699080175298, 4416.00555289883, 28953.97716064518, 33456.55040198806, 42976.38574248663, 13645.197943660398, 41852.94480975737, 41766.42688130038, 34502.36339211704, 27637.58822296382, 30062.0224936446, 33503.771232310064, 31236.426951845027, 33180.70737588321, 26170.07125825722, 23523.140866026708, 24484.786779197784, 30022.98969826164, 20620.86407250793, 8347.939210307697, 20632.255268677665, 18052.670183302245, 14977.66056337554, 15894.70326277196, 15821.46504253202, 13066.773124267096, 12535.595764402835, 12506.07124399018, 18706.18434912037, 15367.820284861233, 1846.6131718794345, 400.67375606313846, 422.8563789301714, 334.8696840413119, 318.535727378141, 307.2351616120215, 293.298676557295, 251.7621966225553, 249.21765394419012, 247.04906662436844, 240.9790394507837, 222.6567023190072, 188.7777918487028, 186.61342793404225, 184.41927533829548, 167.71450647573477, 167.46381309714246, 159.93867609761142, 159.60942326364798, 159.20091331303138, 159.19632453676377, 199.53334206957265, 149.8825817761422, 145.9622553166874, 145.07158302913928, 142.70230910029437, 136.57061002839336, 133.54873344524495, 130.86916487011138, 130.12836322908723, 513.97311498792, 641.1587225123047, 329.38712052712503, 817.0066136914269, 703.1254483103397, 2986.175637309488, 741.1867236830155, 530.1657177906168, 820.8676456032622, 505.8407112356803, 490.5184207803755, 875.9806135914295, 365.8223678694274, 13645.197943660398, 3633.971509848227, 412.44178367266227, 2582.7450632381115, 2518.8568625440384, 1146.2122414389626, 1336.5233200375894, 1340.531477063592, 1673.2519076928052, 20620.86407250793, 41852.94480975737, 41766.42688130038, 33456.55040198806, 2750.6384624676434, 34502.36339211704, 42976.38574248663, 31236.426951845027, 33503.771232310064, 30062.0224936446, 23523.140866026708, 33180.70737588321, 3696.2082872112865, 26170.07125825722, 24484.786779197784, 30022.98969826164, 27637.58822296382, 28953.97716064518, 20632.255268677665, 18052.670183302245, 18706.18434912037, 15894.70326277196, 12247.532781254105, 12826.081964619594, 14977.66056337554, 11260.512042320273, 15532.670637442674, 15821.46504253202, 13066.773124267096, 15367.820284861233, 1511.0957127203394, 917.9713913470868, 443.78379563661946, 387.74405876919303, 361.73010890299634, 335.07510909987025, 319.85470030981304, 252.15364323292573, 213.3387109795811, 211.1210947934913, 205.5990101795327, 177.63975659121132, 171.66917910827968, 141.03005146075427, 206.7224678980235, 138.7893591086699, 121.34672052142686, 500.45595120281365, 110.26183265102974, 105.97282961037996, 103.61283346122492, 98.85705817691122, 96.71106999350879, 95.38226665208262, 95.02808264498277, 401.8824587013925, 92.50245771813434, 152.4552403850281, 85.27807968399752, 81.52385199780454, 1707.1490070634247, 1862.4828978841583, 265.43619699764156, 628.7767145758128, 1147.5043170940562, 166.81162221833006, 1884.0103537933517, 1185.6733478110284, 656.9173942917005, 1281.831690847579, 346.58034839045916, 418.2108209408171, 5532.927362854159, 2085.084453464025, 1398.4947303311621, 2254.972159121559, 623.6218900738655, 773.8110493865706, 5499.780023383851, 1506.14948862145, 2131.437700963015, 1249.4130958786213, 1114.544647007631, 693.8139422282649, 6316.412109088593, 1799.25809514268, 33180.70737588321, 8159.932719308494, 1737.5342569711877, 30022.98969826164, 28953.97716064518, 41852.94480975737, 41766.42688130038, 34502.36339211704, 42976.38574248663, 26170.07125825722, 31236.426951845027, 24484.786779197784, 33503.771232310064, 27637.58822296382, 17943.04360529034, 33456.55040198806, 30062.0224936446, 23523.140866026708, 362.3558048763671, 290.2622438262986, 272.86428163585794, 199.97829125870015, 189.66625327749935, 190.1942722025759, 185.6092493092654, 154.79592327516497, 154.79592327516497, 154.7179679561968, 154.71497788190268, 147.43679850842315, 126.1509851654481, 147.08991117844533, 112.08838166581432, 112.64934241995016, 108.17946789838051, 107.1036673626887, 102.87474622804665, 95.38676701230996, 323.24498114122497, 90.17787324056792, 77.49264598584752, 80.69972345737202, 70.32234676283866, 67.22784750026132, 66.89257306681499, 64.33914466249897, 62.38595927696114, 62.38595927696114, 794.8538318957794, 374.7202101240945, 126.75837836900875, 164.82779472765296, 142.56977816359782, 850.8895632309838, 837.0390154128244, 1556.6855782305017, 675.1982809253585, 1103.4492285609704, 200.11407840026303, 146.5136048770094, 1266.5879834333286, 253.01136041928405, 894.0644736017578, 952.1754059030461, 1010.9280636137956, 3364.4973014078964, 420.8001192709876, 1869.5768435310422, 482.3042618341071, 459.1906432596542, 1653.3869376598964, 8003.979405064508, 312.5817855031159, 3285.6883022187017, 1296.171000440677, 1381.0573594866303, 1071.3737183620153, 512.2599029267116, 888.3071831824607, 973.4384064475215, 1419.5351282525485, 6684.851390684701, 5110.0509909962175, 20620.86407250793, 4112.920587499471, 2335.1562662511387, 1407.1346781038362, 6930.215555463699, 1696.7972037805375, 13645.197943660398, 33180.70737588321, 13321.267881520987, 3419.8761001542002, 15811.876921887335, 33456.55040198806, 28953.97716064518, 10274.92278447054, 5735.3437429443, 12577.466729562964, 250.11565497208758, 206.24454716232097, 187.21680813714684, 185.99501161251632, 162.43529408711555, 367.6445716749841, 182.15406727630196, 164.73291745052782, 138.18929193392518, 127.91428795591871, 124.68588430650655, 124.2424300675107, 107.98010902898778, 101.85562876193366, 101.22322417773364, 101.22321449914682, 100.61355535694692, 100.61355594166545, 100.61355646631931, 95.53291127732845, 94.26545103488478, 93.37070107622293, 89.80627981719229, 102.42273301557991, 237.75859203124782, 84.048735233183, 80.47883865420634, 68.43074988824604, 67.32904225561482, 66.14949806061801, 651.8697197610446, 308.8340941606066, 491.45808962913793, 1230.7252361387796, 481.49031132042813, 453.59537965167624, 969.5678491309769, 381.32848969605783, 1291.5574011666847, 715.4830693854988, 413.6637273879887, 636.0334692354621, 283.53783592171976, 515.6671919669469, 212.0809909009316, 377.1155138628435, 5499.780023383851, 2037.5496357926818, 568.3646319510387, 5735.3437429443, 3128.8572614692953, 2472.9262497222403, 4703.190906884909, 28953.97716064518, 24484.786779197784, 17943.04360529034, 870.6644609763625, 2234.343496145692, 5110.0509909962175, 30022.98969826164, 1470.997214402186, 42976.38574248663, 15811.876921887335, 34502.36339211704, 6498.78301068316, 11260.512042320273, 33180.70737588321, 6260.489158313974, 41852.94480975737, 26170.07125825722, 31236.426951845027, 23523.140866026708, 41766.42688130038, 33456.55040198806, 27637.58822296382, 33503.771232310064, 30062.0224936446, 115.75089129575267, 107.4065744185422, 105.13001467417772, 73.14639196714818, 62.82118485892, 55.750953468613616, 65.90158587433696, 52.504731422697795, 43.725178110132326, 44.82792044790588, 35.30485060100808, 34.788239497274645, 31.971471904362698, 31.839660783633178, 34.94696589020869, 26.738761091681358, 21.621764815386104, 21.621757648614338, 21.621380212923576, 21.518139897421726, 21.518139897421726, 21.517446710002957, 21.517446710002957, 21.516489603945626, 21.471514628617523, 71.71531884408668, 15.971014373939818, 14.950736163233346, 14.107230775249263, 41.76948176828371, 254.92656464792518, 36.39808425435956, 455.4278965877827, 87.93642641404551, 91.69169882855343, 421.8938679352521, 77.68859143753451, 71.21085812052746, 40.08159202827233, 269.9978493315149, 40.588132001716495, 271.32974005246047, 236.40907283230212, 455.4118978118005, 696.00785625755, 414.07751431957297, 165.36809455870997, 2775.390221651387, 354.1469245684522, 148.5785653330288, 1642.1732022608242, 289.9681987481024, 9287.822812806115, 1407.1346781038362, 807.8013757816909, 28953.97716064518, 857.4129557297881, 2135.9275729709984, 42976.38574248663, 10180.29467632518, 2213.784714630773, 1050.7108188684651, 33180.70737588321, 41852.94480975737, 41766.42688130038, 30022.98969826164, 13645.197943660398, 33456.55040198806, 34502.36339211704, 26170.07125825722, 33503.771232310064, 31236.426951845027, 20632.255268677665, 30062.0224936446, 13321.267881520987, 27637.58822296382, 23523.140866026708, 79.78021556848941, 40.57033737679737, 31.263393543890036, 20.700841286149437, 20.700841286149437, 20.700841286149437, 12.055711479206686, 12.01613453252943, 11.174470597064497, 11.033071108492775, 10.898429693304843, 10.836839394254032, 10.83086285561257, 10.83086285561257, 10.803491103354897, 10.790345254253998, 10.754743909984214, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 10.640898100768014, 19.520658559550007, 173.79807484416563, 181.5955244792557, 13.441975935982859, 78.86970642459482, 39.482088439122, 308.5746960537631, 874.2403367886694, 1638.4404598217222, 17.91677795831643, 1028.0119042959377, 1223.2740573024107, 570.7901855369273, 503.3677556605725, 805.6241892070187, 419.0956387831737, 309.1021409608802, 1874.9799471194913], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.3495, -7.6602, -8.1298, -8.3791, -8.4063, -8.4441, -8.5265, -8.5914, -8.6181, -8.639, -7.692, -8.8933, -8.9627, -8.6333, -9.0497, -9.069, -9.1337, -9.1395, -9.143, -8.8126, -9.1873, -9.2189, -9.2424, -8.7798, -9.3717, -8.863, -9.613, -9.6575, -9.6819, -9.6823, -5.4285, -7.6015, -6.5306, -8.5287, -6.4098, -6.8302, -7.567, -8.4597, -7.7879, -6.7425, -8.1362, -7.7651, -5.5445, -7.0877, -6.3949, -6.9705, -7.794, -7.6252, -6.8253, -4.0444, -4.0547, -5.4959, -4.3751, -4.3113, -5.391, -4.3784, -4.3095, -4.1311, -4.8823, -5.0558, -5.4652, -4.7329, -4.5483, -5.057, -4.9999, -4.6741, -5.1156, -5.0736, -4.7568, -5.2811, -4.682, -4.6077, -4.619, -5.3036, -4.9698, -5.3205, -5.0423, -4.8434, -5.2003, -5.1922, -5.3453, -5.2856, -7.1008, -8.4751, -8.4897, -8.4958, -8.4958, -8.4492, -8.7203, -8.7904, -8.8778, -8.9336, -8.9353, -8.9623, -8.9796, -9.0651, -9.0685, -9.1119, -9.1101, -9.1228, -9.133, -9.0912, -9.1694, -9.1382, -9.1813, -9.1835, -9.1885, -9.2151, -9.1414, -9.2625, -9.2553, -9.2718, -8.1936, -8.5299, -8.6827, -8.7878, -8.9639, -6.4377, -8.192, -8.7588, -8.9174, -6.6403, -6.1323, -8.0364, -8.9422, -8.3327, -4.8982, -7.2873, -7.8827, -6.1378, -6.2004, -7.9992, -7.4135, -7.5952, -6.3441, -7.7834, -7.7773, -5.9595, -6.7736, -6.7319, -6.6406, -4.9364, -6.1758, -6.1381, -6.2797, -6.8187, -6.2825, -7.4184, -5.1207, -5.9404, -7.2377, -5.5534, -6.8518, -5.7852, -6.2159, -6.4171, -6.1517, -7.0017, -5.735, -6.2185, -6.0746, -5.672, -5.6321, -5.7048, -5.5963, -5.2591, -5.3937, -5.4902, -5.8038, -5.9436, -5.77, -4.9661, -5.0201, -5.1287, -5.1654, -5.4934, -5.3559, -5.552, -5.3745, -5.759, -5.0667, -5.7142, -5.8631, -5.8891, -5.4131, -5.5136, -5.4347, -5.6683, -5.7791, -6.7207, -6.7356, -6.8557, -7.6021, -7.7227, -7.9136, -7.9888, -7.9905, -7.3212, -8.1478, -8.2162, -8.2453, -8.2472, -8.3366, -8.3645, -8.5037, -8.5204, -8.5549, -8.5546, -8.5636, -8.5785, -8.6593, -8.693, -3.6169, -8.7274, -8.7659, -8.7745, -8.779, -8.8366, -8.8639, -7.0847, -7.4459, -6.9092, -6.5095, -6.2595, -6.8762, -8.0613, -7.2186, -4.8069, -5.9922, -7.9884, -6.9632, -7.4973, -7.0277, -5.3227, -6.8085, -6.2237, -5.811, -7.1866, -7.07, -7.6494, -7.4243, -6.7558, -4.9983, -6.1466, -4.7772, -5.3333, -6.9859, -6.6119, -6.9779, -5.5059, -4.5747, -6.2626, -6.648, -4.8239, -4.7485, -6.4891, -4.6215, -5.5939, -4.6571, -4.5112, -4.5328, -4.5561, -5.0611, -4.913, -5.4987, -4.7999, -4.8396, -4.8316, -4.997, -4.8885, -4.8559, -4.865, -4.9907, -4.9957, -5.1906, -5.3078, -5.4071, -5.4041, -5.4863, -7.0841, -7.1967, -7.3368, -7.3942, -7.4727, -7.4958, -7.5623, -7.6108, -7.3182, -7.3683, -7.7684, -7.8622, -7.6439, -8.0661, -8.0833, -8.2026, -8.2055, -8.3154, -8.3212, -8.3509, -8.3814, -8.3952, -7.1206, -8.5896, -8.606, -8.6148, -8.6239, -8.5882, -8.7045, -8.7201, -8.1035, -7.4446, -7.1987, -7.5569, -7.6268, -8.1482, -6.7336, -7.3719, -5.5836, -5.0409, -7.1502, -7.3495, -6.7342, -6.7437, -6.1321, -5.7882, -6.2573, -5.5867, -5.7216, -5.584, -6.7518, -7.0114, -6.4837, -5.6328, -4.4859, -4.4726, -4.3277, -5.0477, -4.3593, -4.3642, -4.5295, -4.6969, -4.6823, -4.6235, -4.6728, -4.6727, -4.8095, -4.8957, -4.9043, -4.8239, -5.0471, -5.5399, -5.1278, -5.2136, -5.3292, -5.327, -5.3373, -5.4438, -5.4697, -5.4729, -5.5404, -5.5507, -5.4272, -6.9567, -6.9029, -7.1365, -7.1867, -7.2229, -7.2694, -7.4226, -7.4328, -7.4416, -7.4666, -7.5459, -7.7116, -7.7232, -7.7351, -7.8304, -7.832, -7.8782, -7.8802, -7.8828, -7.8828, -7.6571, -7.9434, -7.9701, -7.9762, -7.9928, -8.037, -8.0595, -8.0799, -8.0856, -6.7123, -6.5157, -7.1714, -6.2893, -6.496, -5.1774, -6.4767, -6.7949, -6.4179, -6.849, -6.8883, -6.3856, -7.1551, -4.2462, -5.3664, -7.096, -5.6902, -5.7144, -6.3353, -6.3195, -6.3334, -6.1978, -4.7845, -4.4427, -4.4454, -4.6011, -6.0162, -4.6311, -4.5389, -4.747, -4.7216, -4.7818, -4.9123, -4.7583, -5.8652, -4.9571, -4.991, -4.9205, -4.9611, -5.047, -5.1888, -5.2929, -5.3576, -5.4248, -5.522, -5.5302, -5.5116, -5.634, -5.5785, -5.6018, -5.6211, -5.6191, -4.9451, -5.4438, -6.1717, -6.3068, -6.3764, -6.4531, -6.4997, -6.7382, -6.9059, -6.9164, -6.943, -7.0898, -7.1241, -7.3217, -6.9394, -7.3378, -7.473, -6.0562, -7.5694, -7.6094, -7.6321, -7.6795, -7.7016, -7.7155, -7.7193, -6.2774, -7.7464, -7.247, -7.8285, -7.8739, -4.8445, -4.7619, -6.6938, -5.8613, -5.2857, -7.1834, -4.894, -5.331, -5.8976, -5.2821, -6.504, -6.3454, -4.0029, -4.9461, -5.3192, -5.0631, -6.1145, -6.0283, -4.7998, -5.6488, -5.4572, -5.8092, -5.9352, -6.1903, -5.2932, -5.8248, -4.7197, -5.321, -5.8857, -5.014, -5.0782, -5.0096, -5.0219, -5.1098, -5.0769, -5.2485, -5.2494, -5.302, -5.2533, -5.2978, -5.4034, -5.3375, -5.3626, -5.4194, -6.2096, -6.432, -6.494, -6.8059, -6.859, -6.8562, -6.8806, -7.063, -7.063, -7.0636, -7.0636, -7.1121, -7.2688, -7.1159, -7.3879, -7.3829, -7.4236, -7.4337, -7.4743, -7.5504, -6.3301, -7.6071, -7.7601, -7.7197, -7.8583, -7.9038, -7.909, -7.9483, -7.9795, -7.9795, -5.4476, -6.1926, -7.2735, -7.0142, -7.159, -5.3945, -5.4107, -4.8029, -5.6479, -5.1915, -6.8329, -7.1377, -5.1228, -6.6249, -5.4734, -5.4625, -5.4206, -4.4056, -6.2493, -5.0851, -6.1691, -6.215, -5.2555, -4.0599, -6.53, -4.7909, -5.4887, -5.5523, -5.7898, -6.2578, -5.9407, -5.9367, -5.7477, -5.0054, -5.1458, -4.5296, -5.3247, -5.5573, -5.7734, -5.2039, -5.7267, -5.0707, -4.8047, -5.0994, -5.5213, -5.1761, -5.0208, -5.1076, -5.3982, -5.4664, -5.5011, -6.5279, -6.7215, -6.8186, -6.8252, -6.9613, -6.1448, -6.8472, -6.948, -7.1239, -7.2015, -7.2273, -7.2308, -7.3721, -7.4309, -7.4372, -7.4372, -7.4433, -7.4433, -7.4433, -7.4955, -7.509, -7.5186, -7.5579, -7.4266, -6.5849, -7.6248, -7.6686, -7.8326, -7.849, -7.8668, -5.5959, -6.3718, -5.9419, -5.0788, -5.9704, -6.0815, -5.4144, -6.2579, -5.2363, -5.8086, -6.2759, -5.9795, -6.6343, -6.179, -6.867, -6.4732, -4.6651, -5.3626, -6.2272, -4.7856, -5.2202, -5.394, -5.2178, -4.3091, -4.5461, -4.7019, -6.1135, -5.6983, -5.355, -4.6182, -5.8889, -4.7674, -5.1231, -4.9078, -5.4557, -5.3163, -5.0168, -5.5297, -5.0757, -5.1894, -5.1519, -5.2168, -5.1314, -5.1825, -5.2792, -5.3966, -5.4647, -5.9038, -5.9792, -6.0033, -6.3671, -6.5212, -6.6423, -6.4752, -6.7033, -6.8895, -6.8673, -7.1081, -7.1232, -7.2099, -7.2141, -7.1212, -7.394, -7.6141, -7.6141, -7.6141, -7.6191, -7.6191, -7.6191, -7.6191, -7.6192, -7.6213, -6.4221, -7.9315, -8.0015, -8.063, -6.9788, -5.2197, -7.1308, -4.7249, -6.298, -6.2826, -4.9154, -6.4898, -6.5868, -7.09, -5.6647, -7.1253, -5.6926, -5.8344, -5.3825, -5.1494, -5.5203, -6.1374, -4.326, -5.7437, -6.2763, -5.0274, -5.9849, -4.5142, -5.3618, -5.759, -4.6861, -5.8168, -5.5655, -4.8509, -5.2165, -5.5997, -5.798, -5.0934, -5.1068, -5.1117, -5.1879, -5.3946, -5.2779, -5.2878, -5.3471, -5.3261, -5.3548, -5.4482, -5.4543, -5.5154, -5.4742, -5.5825, -4.0318, -4.7186, -4.9876, -5.4119, -5.4119, -5.4119, -5.9836, -5.9872, -6.0656, -6.0794, -6.0926, -6.0987, -6.0993, -6.0993, -6.1021, -6.1034, -6.107, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -6.1185, -5.5788, -3.9, -3.9285, -5.9375, -4.8126, -5.2693, -4.1715, -4.3688, -4.4698, -5.9631, -4.9051, -5.3849, -5.7201, -5.7413, -5.784, -6.0035, -6.0434, -6.048], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1967, 1.1966, 1.1959, 1.1953, 1.1952, 1.1951, 1.1948, 1.1946, 1.1945, 1.1945, 1.1941, 1.1935, 1.1931, 1.1928, 1.1927, 1.1926, 1.1923, 1.1922, 1.1922, 1.1921, 1.1919, 1.1917, 1.1916, 1.1913, 1.1907, 1.1906, 1.1888, 1.1883, 1.1881, 1.1881, 1.1791, 1.1771, 1.1659, 1.1841, 1.1624, 1.1643, 1.1642, 1.1803, 1.1662, 1.1347, 1.1704, 1.1533, 1.0819, 1.1299, 1.0978, 1.113, 1.1296, 1.1137, 1.0226, 0.5026, 0.4902, 0.7206, 0.5007, 0.4561, 0.6443, 0.4591, 0.4285, 0.3873, 0.5035, 0.491, 0.5852, 0.3882, 0.3288, 0.4608, 0.442, 0.3403, 0.4569, 0.4395, 0.3242, 0.4975, 0.2779, 0.1695, 0.1498, 0.4492, 0.2825, 0.4541, 0.2573, 0.0699, 0.1915, 0.158, 0.4368, -0.0328, 1.7869, 1.7831, 1.783, 1.783, 1.783, 1.7823, 1.7816, 1.7812, 1.7804, 1.7801, 1.7801, 1.7799, 1.7797, 1.779, 1.7789, 1.7785, 1.7784, 1.7784, 1.7783, 1.7781, 1.778, 1.7779, 1.7778, 1.7778, 1.7778, 1.7774, 1.7769, 1.7769, 1.7768, 1.7768, 1.7766, 1.7745, 1.7753, 1.776, 1.7763, 1.7411, 1.7669, 1.7723, 1.7749, 1.7275, 1.7094, 1.7521, 1.7742, 1.7548, 1.6378, 1.7185, 1.7406, 1.6633, 1.6595, 1.7344, 1.6937, 1.7037, 1.6175, 1.7073, 1.6986, 1.5536, 1.6223, 1.6172, 1.5997, 1.4362, 1.5388, 1.5058, 1.5056, 1.5697, 1.493, 1.6403, 1.2951, 1.4059, 1.6111, 1.3222, 1.5461, 1.3535, 1.4272, 1.4612, 1.3924, 1.558, 1.2306, 1.3462, 1.3047, 1.1811, 1.1337, 1.1548, 1.0583, 0.8281, 0.84, 0.889, 1.0551, 1.147, 1.0101, 0.3335, 0.3301, 0.3897, 0.3707, 0.6865, 0.3913, 0.6241, 0.3152, 0.8593, -0.2979, 0.7306, 0.9819, 1.0486, -0.636, -0.5537, -0.9162, -0.0026, -1.0117, 1.9098, 1.9098, 1.9097, 1.9084, 1.9079, 1.9075, 1.9073, 1.9073, 1.9067, 1.9066, 1.9064, 1.9062, 1.9062, 1.9058, 1.9056, 1.9049, 1.9048, 1.9045, 1.9045, 1.9045, 1.9044, 1.9038, 1.9036, 1.9035, 1.9034, 1.9031, 1.903, 1.9027, 1.9025, 1.9023, 1.9015, 1.9007, 1.8918, 1.8758, 1.87, 1.8717, 1.8904, 1.8638, 1.7826, 1.8049, 1.8849, 1.8381, 1.8557, 1.8288, 1.7198, 1.8121, 1.7654, 1.7313, 1.8249, 1.8058, 1.855, 1.8283, 1.7384, 1.496, 1.6332, 1.399, 1.4456, 1.7484, 1.6548, 1.7294, 1.288, 0.8671, 1.4453, 1.5902, 0.6944, 0.5511, 1.4594, 0.1165, 0.8136, 0.12, 0.0072, 0.0121, -0.0091, 0.3308, 0.168, 0.6812, 0.0375, 0.0738, 0.0455, 0.1241, -0.0127, -0.0885, -0.0962, 0.0237, -0.0358, 0.0617, 0.2053, -0.0213, -0.1513, 0.0314, 2.1032, 2.1029, 2.1026, 2.1024, 2.1022, 2.1022, 2.102, 2.1017, 2.1016, 2.1016, 2.1012, 2.1009, 2.1008, 2.0999, 2.0998, 2.0992, 2.0992, 2.0985, 2.0984, 2.0982, 2.098, 2.0979, 2.0966, 2.0963, 2.0962, 2.0962, 2.0961, 2.0958, 2.0953, 2.0952, 2.0933, 2.0864, 2.0703, 2.0733, 2.0555, 2.0734, 1.9966, 2.0198, 1.8428, 1.7782, 1.9774, 1.9846, 1.9076, 1.8689, 1.7546, 1.6265, 1.6945, 1.5319, 1.4879, 1.3575, 1.7622, 1.8368, 1.5837, 1.1611, 0.4275, 0.2962, 0.1908, 0.618, 0.1856, 0.1827, 0.2086, 0.263, 0.1935, 0.1439, 0.1647, 0.1044, 0.2049, 0.2254, 0.1767, 0.0532, 0.2057, 0.6171, 0.1244, 0.1722, 0.2434, 0.1861, 0.1804, 0.2652, 0.2808, 0.28, -0.1902, -0.0039, 2.2385, 2.2369, 2.2368, 2.2365, 2.2364, 2.2363, 2.2362, 2.2357, 2.2357, 2.2357, 2.2356, 2.2353, 2.2347, 2.2346, 2.2346, 2.2341, 2.2341, 2.2339, 2.2339, 2.2339, 2.2339, 2.2337, 2.2335, 2.2334, 2.2334, 2.2333, 2.233, 2.2329, 2.2327, 2.2327, 2.2323, 2.2079, 2.2181, 2.1919, 2.1353, 2.0076, 2.1019, 2.1187, 2.0586, 2.1116, 2.1031, 2.0258, 2.1296, 1.4195, 1.6224, 2.0687, 1.64, 1.6409, 1.8073, 1.6694, 1.6526, 1.5665, 0.4683, 0.1022, 0.1016, 0.1677, 1.251, 0.1069, -0.0205, 0.0905, 0.0459, 0.094, 0.2088, 0.0188, 1.1065, 0.0573, 0.09, -0.0434, -0.0013, -0.1336, 0.0634, 0.0929, -0.0074, 0.0883, 0.2518, 0.1973, 0.061, 0.2237, -0.0424, -0.0841, 0.0879, -0.0723, 2.9212, 2.9208, 2.9197, 2.9197, 2.9195, 2.9193, 2.9192, 2.9186, 2.918, 2.918, 2.9179, 2.9173, 2.9171, 2.9161, 2.9161, 2.916, 2.9152, 2.9151, 2.9145, 2.9143, 2.9141, 2.9137, 2.9135, 2.9134, 2.9134, 2.9133, 2.9132, 2.9129, 2.9124, 2.912, 2.8997, 2.8952, 2.9116, 2.8818, 2.8558, 2.8865, 2.7517, 2.7778, 2.8016, 2.7487, 2.8347, 2.8055, 2.5655, 2.5981, 2.6245, 2.4028, 2.6368, 2.5072, 1.7745, 2.2207, 2.0651, 2.2472, 2.2355, 2.4543, 1.1427, 1.8669, 0.0575, 0.8589, 1.8409, -0.1369, -0.1649, -0.4647, -0.4749, -0.3718, -0.5585, -0.234, -0.4119, -0.221, -0.4859, -0.3379, -0.0115, -0.5687, -0.4868, -0.2983, 3.0846, 3.0841, 3.0839, 3.0828, 3.0826, 3.0826, 3.0825, 3.0817, 3.0817, 3.0817, 3.0817, 3.0813, 3.0805, 3.0799, 3.0797, 3.0797, 3.0794, 3.0794, 3.079, 3.0785, 3.0783, 3.078, 3.0765, 3.0764, 3.0754, 3.0749, 3.0748, 3.0744, 3.074, 3.074, 3.0611, 3.0681, 3.0711, 3.0677, 3.068, 3.0461, 3.0462, 3.0336, 3.0239, 2.9891, 3.055, 3.062, 2.92, 3.0284, 2.9176, 2.8656, 2.8476, 2.6602, 2.8954, 2.5682, 2.8392, 2.8423, 2.5207, 2.1392, 2.912, 2.2986, 2.531, 2.4039, 2.4204, 2.6902, 2.4569, 2.3693, 2.181, 1.3738, 1.5021, 0.7232, 1.5402, 1.8737, 2.1641, 1.1392, 2.0237, 0.595, -0.0276, 0.5903, 1.5281, 0.3422, -0.252, -0.1942, 0.5512, 1.066, 0.2461, 3.137, 3.1363, 3.1359, 3.1359, 3.1353, 3.1349, 3.1348, 3.1345, 3.1343, 3.1339, 3.1338, 3.1337, 3.1328, 3.1323, 3.1323, 3.1323, 3.1322, 3.1322, 3.1322, 3.1318, 3.1317, 3.1316, 3.1313, 3.1311, 3.1307, 3.1307, 3.1302, 3.1284, 3.1283, 3.1281, 3.1111, 3.0822, 3.0476, 2.9927, 3.0395, 2.9881, 2.8956, 2.9852, 2.7869, 2.8052, 2.8858, 2.7521, 2.9052, 2.7623, 2.9629, 2.781, 1.9092, 2.2048, 2.6169, 1.7468, 1.9182, 1.9797, 1.513, 0.6042, 0.5349, 0.6899, 2.304, 1.7768, 1.2928, 0.2589, 2.0042, -0.249, 0.3952, -0.1697, 0.9518, 0.5415, -0.2397, 0.9151, -0.5308, -0.1749, -0.3145, -0.0957, -0.5844, -0.4136, -0.3194, -0.6292, -0.5889, 4.5316, 4.531, 4.5284, 4.5273, 4.5253, 4.5236, 4.5235, 4.5227, 4.5194, 4.5167, 4.5147, 4.5143, 4.5121, 4.512, 4.5118, 4.5067, 4.499, 4.499, 4.499, 4.4989, 4.4989, 4.4989, 4.4989, 4.4989, 4.4988, 4.492, 4.4846, 4.4806, 4.4772, 4.4759, 4.4262, 4.4615, 4.3407, 4.4123, 4.3858, 4.2266, 4.3443, 4.3344, 4.4059, 3.9237, 4.358, 3.8909, 3.8869, 3.6831, 3.4921, 3.6405, 3.9412, 2.9323, 3.5734, 3.9094, 2.7557, 3.5322, 1.5362, 2.5757, 2.7335, 0.2273, 2.6161, 1.9547, -0.3325, 0.7421, 1.8847, 2.4316, -0.3163, -0.5619, -0.5647, -0.3108, 0.2711, -0.509, -0.5497, -0.3326, -0.5586, -0.5173, -0.196, -0.5785, 0.1743, -0.5143, -0.4614, 6.7758, 6.7652, 6.7567, 6.7447, 6.7447, 6.7447, 6.7137, 6.7134, 6.7076, 6.7066, 6.7056, 6.7052, 6.7051, 6.7051, 6.7049, 6.7048, 6.7045, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.7036, 6.6366, 6.1289, 6.0565, 6.6509, 6.0064, 6.2417, 5.2834, 4.0446, 3.3156, 6.338, 3.3464, 2.6926, 3.1197, 3.2242, 2.7112, 3.1453, 3.4097, 1.6025]}, \"token.table\": {\"Topic\": [5, 10, 10, 1, 3, 1, 3, 8, 3, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 10, 3, 8, 10, 1, 5, 7, 2, 4, 8, 10, 10, 3, 8, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 9, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 1, 2, 3, 4, 5, 6, 9, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 7, 9, 1, 2, 3, 4, 5, 6, 8, 9, 10, 4, 4, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 2, 4, 5, 6, 7, 8, 9, 2, 4, 5, 6, 7, 8, 9, 1, 2, 4, 9, 1, 2, 4, 6, 7, 8, 1, 2, 1, 1, 2, 4, 6, 9, 7, 1, 4, 7, 5, 5, 4, 4, 1, 4, 5, 6, 7, 8, 7, 1, 5, 4, 4, 6, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 3, 6, 6, 1, 2, 3, 5, 7, 2, 3, 4, 5, 6, 7, 8, 10, 5, 5, 2, 3, 4, 5, 6, 7, 8, 10, 8, 1, 2, 4, 5, 6, 9, 1, 3, 6, 3, 2, 1, 3, 8, 2, 5, 5, 7, 2, 3, 5, 7, 8, 2, 1, 2, 3, 4, 5, 7, 8, 10, 1, 3, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 8, 6, 1, 2, 8, 3, 2, 5, 6, 7, 8, 4, 2, 3, 6, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 1, 2, 3, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 3, 4, 6, 3, 8, 2, 3, 5, 6, 2, 4, 9, 2, 4, 7, 10, 1, 4, 7, 2, 1, 6, 2, 3, 4, 6, 8, 1, 2, 3, 6, 8, 9, 2, 3, 6, 8, 7, 7, 10, 1, 2, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 2, 3, 1, 2, 4, 5, 6, 8, 1, 2, 3, 5, 7, 8, 10, 1, 2, 4, 7, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 7, 9, 2, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 6, 7, 8, 6, 1, 2, 4, 5, 9, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 3, 6, 8, 7, 9, 4, 2, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 6, 7, 8, 1, 5, 8, 10, 2, 3, 4, 5, 9, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 5, 1, 2, 3, 5, 9, 5, 2, 4, 3, 7, 1, 2, 3, 4, 5, 7, 8, 6, 10, 5, 7, 10, 9, 3, 5, 6, 2, 4, 5, 8, 9, 9, 1, 2, 4, 7, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 7, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 3, 6, 3, 3, 2, 10, 3, 3, 1, 2, 3, 4, 9, 9, 2, 4, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 6, 10, 5, 7, 4, 8, 1, 2, 5, 6, 7, 8, 10, 1, 2, 6, 5, 7, 1, 2, 3, 6, 1, 2, 2, 3, 6, 9, 3, 3, 3, 3, 3, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 5, 9, 1, 5, 6, 9, 6, 1, 2, 4, 8, 3, 2, 5, 7, 1, 4, 3, 8, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 8, 1, 5, 7, 1, 2, 5, 7, 7, 2, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 7, 6, 3, 5, 1, 2, 3, 5, 6, 7, 8, 7, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 2, 3, 6, 2, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 5, 7, 9, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 7, 8, 5, 3, 8, 8, 2, 3, 4, 5, 6, 7, 8, 6, 10, 1, 3, 10, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 1, 2, 4, 5, 6, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 9, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 9, 7, 1, 3, 1, 10, 9, 5, 9, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 8, 1, 2, 3, 4, 7, 1, 2, 1, 2, 3, 4, 5, 6, 7, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 7, 2, 5, 9, 9, 2, 3, 7, 10, 10, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 8, 9, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 2, 4, 5, 6, 5, 1, 5, 7, 1, 2, 4, 1, 2, 3, 6, 1, 2, 3, 4, 6, 7, 8, 9, 1, 3, 6, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 5, 5, 1, 2, 3, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 8, 8, 2, 4, 5, 6, 7, 8, 1, 4, 5, 6, 8, 10, 2, 9, 5, 1, 1, 2, 3, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 4, 5, 9, 1, 2, 3, 4, 5, 7, 9, 9, 9, 9, 3, 6, 2, 5, 1, 2, 3, 4, 5, 7, 8, 9, 2, 3, 4, 9, 1, 3, 4, 6, 7, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 1, 2, 3, 4, 5, 6, 3, 8, 1, 3, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 4, 2, 4, 5, 7, 8, 1, 4, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 4, 2, 7, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 10, 2, 6, 5, 1, 2, 3, 4, 5, 6, 8, 9, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 2, 4, 7, 9, 4, 10, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 2, 4, 5, 8, 5, 1, 2, 5, 6, 8, 1, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 2, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 5, 5, 5, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 2, 4, 5, 1, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 5, 6, 7, 8, 9, 5, 9, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 8, 9, 10, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 6, 1, 2, 3, 4, 6, 8, 1, 2, 1, 5, 1, 2, 4, 5, 6, 7, 9, 6, 1, 2, 3, 5, 6, 9, 4, 1, 2, 3, 4, 5, 7, 8, 9, 7, 1, 2, 3, 4, 5, 7, 7, 1, 2, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 7, 8, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 8, 9, 7, 2, 2, 1, 2, 3, 4, 5, 6, 7, 8, 3, 4, 2, 4, 2, 3, 4, 8, 10, 2, 3, 5, 8, 10, 2, 3, 5, 1, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 9, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 7, 9, 1, 2, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 1, 2, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 7, 9, 9, 1, 2, 3, 6, 8, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 6, 1, 2, 3, 7, 8, 1, 5, 6, 8, 2, 3, 5, 7, 8, 9, 9, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 8, 2, 3, 5, 8, 1, 2, 3, 4, 6, 7, 8, 1, 3, 5, 6, 7, 8, 7, 1, 2, 4, 5, 7, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 7, 1, 2, 4, 5, 9, 2, 9, 4, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 4, 5, 7, 8, 4, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 5, 2, 3, 5, 6, 7, 8, 9, 5, 1, 2, 6, 2, 3, 4, 5, 8, 10, 1, 2, 3, 4, 6, 9, 6, 6, 2, 3, 5, 9, 8, 1, 2, 3, 4, 5, 6, 8, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 6, 2, 4, 3, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 8, 5, 7, 7, 10, 2, 9, 1, 2, 4, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 4, 1, 1, 3, 4, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 7, 7, 7, 5, 7, 7, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 8, 2, 3, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 7, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 6, 4, 3, 1, 2, 1, 1, 2, 3, 4, 5, 7, 2, 3, 8, 4, 5, 6, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 6, 7, 3, 6, 1, 3, 6, 2, 3, 8, 5, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 9, 10, 2, 5, 1, 2, 3, 4, 5, 6, 1, 5, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 4, 9, 4, 9, 9, 1, 9, 1, 3, 4, 8, 2, 3, 7, 8, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 1, 2, 3, 1, 2, 4, 6, 1, 2, 3, 4, 6, 9, 1, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 8, 1, 3, 1, 2, 4, 5, 9, 2, 7, 3, 4, 6, 6, 1, 2, 3, 6, 8, 3, 1, 2, 4, 6, 7, 8, 7, 8, 1, 2, 3, 6, 9, 2, 4, 5, 7, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 6, 7, 4, 5, 7, 2, 4, 6, 8, 9, 2, 9, 6], \"Freq\": [0.074393824595616, 0.892725895147392, 0.9124305951558692, 0.024621401873834367, 0.9750075142038409, 0.9335294589359605, 0.0647755134771891, 0.9861092066800884, 0.9908679967431725, 0.9939018509247837, 0.9964425425002658, 0.2890729451572277, 0.1454124512003024, 0.1454124512003024, 0.024527401407279926, 0.24527401407279925, 0.0017519572433771374, 0.0017519572433771374, 0.12088504979302249, 0.026279358650657062, 0.9861051621379071, 0.9879156722576012, 0.9661443089939366, 0.994800970331039, 0.00618725770447834, 0.9930548615687737, 0.9829169039109596, 0.011169510271715451, 0.993901856107529, 0.9397702999597602, 0.9397702999597602, 0.9941112564514095, 0.9928523390894863, 0.9935005400997144, 0.9982843906595169, 0.019334437382525486, 0.7790640945311741, 0.01137319846030911, 0.030138975919819143, 0.04719877361028281, 0.025589696535695497, 0.05970929191662283, 0.02160907707458731, 0.0062552591531700105, 0.17989004979212267, 0.5724752107734367, 0.09868407813708373, 0.052165425500256796, 0.053778789175522465, 0.04006519793576424, 0.002957833404653736, 0.8282491991928296, 0.030782780922381587, 0.0779189142097784, 0.03655455234532813, 0.004809809519122123, 0.0019239238076488492, 0.020201199980312917, 0.4776794741281595, 0.02247376119817492, 0.15360271542570264, 0.14364639102024337, 0.11665866923952906, 0.035663489992545386, 0.012325353363671429, 0.03159772407777585, 0.0063707670633002976, 0.9834150907674798, 0.01751121162750949, 0.11805945903708011, 0.6275792296181627, 0.0954643472596485, 0.07004484651003796, 0.06496094636011585, 0.0067785335332294794, 0.8874920867715871, 0.04595428281017927, 0.06031499618836029, 0.0028721426756362044, 0.4695344315556475, 0.04306311544714262, 0.352121529030377, 0.05067972090037873, 0.06327641453457691, 0.01054606908909615, 0.0002929463635860042, 0.0066791770897608954, 0.0037497134539008535, 0.9134752217029811, 0.0761229351419151, 0.006619385664514356, 0.9843274297430412, 0.007307389977792401, 0.43783444950272804, 0.07611864560200418, 0.25210495423383783, 0.006089491648160334, 0.050542780679730774, 0.002435796659264134, 0.16806996948922523, 0.9397702999597602, 0.9931034045905797, 0.9892459329526715, 0.027241485232146062, 0.9007851116762965, 0.0018160990154764043, 0.07082786160357976, 0.29112830018421804, 0.24232793496094573, 0.1426670307846588, 0.10062661061210366, 0.10217174090941045, 0.04094595287862952, 0.030065660368427647, 0.04249108317593629, 0.007532510199370524, 0.997186436643539, 0.9996679478470251, 0.7849403815629908, 0.018018717510771668, 0.1193740035088623, 0.038289774710389794, 0.010135528599809063, 0.003378509533269688, 0.024775736577311046, 0.7943196812960241, 0.0052954645419734945, 0.1151763537879235, 0.04765918087776145, 0.0026477322709867472, 0.0052954645419734945, 0.03044892111634759, 0.4069411766857493, 0.2000219343031649, 0.02414057827796818, 0.3655573282092324, 0.00263058110741906, 0.8792717351548208, 0.036170490227012075, 0.055242203255800267, 0.001972935830564295, 0.024332875243626307, 0.9963702124466253, 0.0036698718690483436, 0.99923700476907, 0.03111995276474638, 0.0034104057824379595, 0.7694728046625646, 0.18458821297445455, 0.011510119515728114, 0.9890971186927222, 0.013650609454861865, 0.006825304727430932, 0.9760185760226233, 0.9934075058336168, 0.9977265102168612, 0.9959499201189003, 0.9901282161243785, 0.014658559706659314, 0.00694352828210178, 0.21679238303006668, 0.031631628840685884, 0.5732268348446248, 0.15584363477606217, 0.995945276012342, 0.9873168680603608, 0.9958798551403432, 0.9853009840731717, 0.9930611702104423, 0.9954248401167852, 0.13632375621794843, 0.7257799978927396, 0.005760158713434441, 0.09504261877166828, 0.025920714210454984, 0.011520317426868883, 0.004160113270039296, 0.07696209549572698, 0.9173049760436648, 0.9935632688617886, 0.996784822974734, 0.9940853517778349, 0.9979816197628378, 0.07778158670723828, 0.8379198204370669, 0.0035355266685108307, 0.07071053337021661, 0.010606580005532492, 0.7350490686763335, 0.033772524777020724, 0.015892952836245047, 0.11721052716730722, 0.015892952836245047, 0.003973238209061262, 0.0516520967177964, 0.027812667463428833, 0.9957397455309679, 0.9959797517786025, 0.7537655656613726, 0.08117475322507091, 0.020751440674078275, 0.02014110418366421, 0.000610336490414067, 0.02258245014532048, 0.0701886963976177, 0.031127161011117413, 0.9946503317272335, 0.05505919924472399, 0.13943563445092438, 0.0464785448169748, 0.0021451636069372984, 0.742941662535951, 0.013586036177269556, 0.0028853338183889034, 0.0779040130965004, 0.9175361542476713, 0.9908103882268675, 0.9918092682180133, 0.03878470515782193, 0.2753714066205357, 0.6845500460355571, 0.0058368811763053205, 0.9942154270306729, 0.32600638669135207, 0.6734862479551884, 0.018706501679110955, 0.8642403775749261, 0.003741300335822191, 0.0022447802014933147, 0.11074248994033686, 0.9928372101757169, 0.026715761064505295, 0.05923929627346826, 0.001935924714819224, 0.16184330615888715, 0.5494154340656958, 0.19978743056934392, 0.0007743698859276896, 0.929822233211565, 0.02724078410882586, 0.9466172477816986, 0.010215294040809697, 0.010215294040809697, 0.006810196027206465, 0.005004907815925927, 0.44639011139186957, 0.08579841970158732, 0.12655266905984128, 0.09318661695366845, 0.023594565417936513, 0.15872707644793654, 0.0562456306932628, 0.004528249928694886, 0.18265914066132172, 0.10007522002032743, 0.19527786378498346, 0.05034995464193752, 0.05897066647889456, 0.3876821569576479, 0.023863129867518772, 0.000999502821676179, 0.10227853842599013, 0.8474507469582039, 0.007867579878922318, 0.0033718199481095647, 0.0382139594119084, 0.9984123323046913, 0.9959199755422681, 0.004697735733689944, 0.9951129223795341, 0.9911220375088574, 0.7445827454647563, 0.00302184555789268, 0.24114327551983586, 0.000604369111578536, 0.010274274896835113, 0.997994776940124, 0.0035626769706687228, 0.9209519969178649, 0.07481621638404318, 0.9827913691067561, 0.015599863001694542, 0.3534659915992392, 0.2327037902951434, 0.1099101752462244, 0.10071535513807722, 0.10579388950013527, 0.049823095004611455, 0.0241631319121077, 0.015395977855502252, 0.00807219672285014, 0.09717493105054016, 0.13781172039894787, 0.7650317299069799, 0.06034059414864933, 0.08902710612095803, 0.008902710612095804, 0.05440545374058547, 0.7873952941364732, 0.9897801234711002, 0.0020394328219167984, 0.32223038586285413, 0.26036759026471124, 0.0006798109406389328, 0.07138014876708794, 0.0020394328219167984, 0.020394328219167986, 0.32087076398157627, 0.9397702999597602, 0.9177634937766993, 0.008318098130906641, 0.058226686916346485, 0.01109079750787552, 0.008411893689785758, 0.9926034553947195, 0.8604162525836546, 0.01854873353139463, 0.06527054346424714, 0.05564620059418389, 0.16851362722928406, 0.014042802269107004, 0.8144825316082063, 0.970043291411185, 0.024403604815375724, 0.006100901203843931, 0.006100901203843931, 0.21355813777865348, 0.004146759956867058, 0.7795908718910068, 0.9843059044694094, 0.9938151884251114, 0.005430684089754707, 0.022453512305224552, 0.20517864692705196, 0.06503775978065043, 0.005419813315054202, 0.7022529538220231, 0.00029036751745255176, 0.04442623017024042, 0.8260955871525099, 0.0005807350349051035, 0.12572913505695493, 0.0031940426919780697, 0.09259353574600457, 0.0440921598790498, 0.0022046079939524897, 0.859797117641471, 0.9902899689545053, 0.9948582413649865, 0.9397702999597602, 0.31999369092681995, 0.13985335772521088, 0.07884736628952219, 0.11740775710264617, 0.33956165044392767, 0.002877641105457014, 0.0017265846632742083, 0.08601715576870869, 0.5449355007917075, 0.01705926832284446, 0.06319137420997314, 0.2210496740424916, 0.004084613542089518, 0.029793651718770606, 0.03387826526086012, 0.9397702999597602, 0.1454750764234389, 0.00969833842822926, 0.8437554432559456, 0.0638581099442455, 0.16633883578248046, 0.3337547963110084, 0.018311120682807745, 0.13310184361872857, 0.08093823091728466, 0.0818614806996111, 0.1120209735889415, 0.009847997678148705, 0.9227782784436442, 0.0005348803947054215, 0.02460449815644939, 0.36906747234674087, 0.01016272749940301, 0.5953218793071342, 0.9852243959557185, 0.007578649199659373, 0.3161484390574802, 0.16727854117218574, 0.0016007515901644569, 0.002401127385246685, 0.5090390056722972, 0.002401127385246685, 0.06785069911727984, 0.09237504819581471, 0.41936636924294646, 0.02207191417068139, 0.04414382834136278, 0.3368010606785457, 0.016349566052356587, 0.11032219693293929, 0.11482514374652865, 0.2330274976032493, 0.5324734607069417, 0.007880156923781377, 0.9938133631119195, 0.47664319603134814, 0.02670644045560152, 0.14187796492038307, 0.15543148345160085, 0.11323530753175044, 0.03618722681734006, 0.01495560665513685, 0.028242060781798608, 0.006743376215039384, 0.037733863327741174, 0.13049627734177158, 0.11320158998322354, 0.018866931663870587, 0.0062889772212901965, 0.6776372955940186, 0.01572244305322549, 0.49889352659298514, 0.017286611613962437, 0.14660100126356232, 0.14626580380844392, 0.11796556152630598, 0.03349580283647292, 0.009289758041852388, 0.02413421676852373, 0.006081439542862131, 0.9397702999597602, 0.013174886358545483, 0.1888400378058186, 0.11198653404763662, 0.204210738557455, 0.05709117422036376, 0.4259879922596373, 0.9920936145841295, 0.04794082550431232, 0.058807412618623114, 0.34325631061087625, 0.09811888953215922, 0.15628709114405817, 0.0012784220134483286, 0.29467627409983976, 0.06935709637510636, 0.5196277696674635, 0.0325868262333833, 0.06869655260010533, 0.16799830010859093, 0.07420108405844711, 0.03478863881672001, 0.03280700749171697, 0.007206542987507448, 0.17295703170017876, 0.626969239913148, 0.017295703170017877, 0.17583964889518175, 0.9959922670586454, 0.8395163733563824, 0.013645389969414884, 0.051332657503989326, 0.09031948598803186, 0.005198243797872337, 0.9939656724047038, 0.05760442607587959, 0.2546875894014778, 0.06257536639714838, 0.05438793527976448, 0.0687159397351863, 0.1739829112444079, 0.21053394301844316, 0.11754811818529744, 0.1421535658959654, 0.011630746300578986, 0.003876915433526329, 0.0012923051445087764, 0.006461525722543882, 0.6603679288439847, 0.03101532346821063, 0.1421535658959654, 0.9954161546410593, 0.4561735085576893, 0.02800564049316045, 0.15121412884353688, 0.14198778080934701, 0.13708883495048513, 0.03829342679677041, 0.010532733596553056, 0.030781709813182186, 0.00604203322592966, 0.9929039147762109, 0.9974660442843662, 0.8497584696970245, 0.012612370607748044, 0.13558298403329147, 0.9869383342250077, 0.9696144141480664, 0.9988736908954458, 0.9972244839026574, 0.9969630178886696, 0.46714741365915363, 0.038037029451979024, 0.15223044904049612, 0.14803155617891403, 0.11584004424011793, 0.034002799055557004, 0.00913876681638457, 0.028074950309794042, 0.007574473397363788, 0.9328102345850549, 0.035161361392341314, 0.014478207632140541, 0.00827326150408031, 0.0020683153760200773, 0.00827326150408031, 0.037721438239304544, 0.12259467427773976, 0.8393020008245261, 0.9397702999597602, 0.0036231838498248735, 0.5364576587646953, 0.3890393658749458, 0.06838759516544449, 0.0024909388967546005, 0.10245555978036144, 0.8708722581330722, 0.9914018474496001, 0.05415460971364902, 0.2815144587593821, 0.17768082691172446, 0.06981916624239047, 0.03267178933137503, 0.1100994544591542, 0.008503616401316789, 0.2560036095554317, 0.009846292675208913, 0.9959409164111631, 0.025281040687830467, 0.406890122313011, 0.03530370178892302, 0.10905253645815627, 0.18429729069471676, 0.034705333961992116, 0.1802583078629332, 0.018848586548323307, 0.005385310442378087, 0.026072907989476077, 0.239396700630644, 0.7324116880680098, 0.3655008967221825, 0.03809405319173161, 0.13419496010723636, 0.13304059485900208, 0.12091975975254202, 0.02611751374130084, 0.14256410815693496, 0.029580609486003714, 0.009812104609991476, 0.9237259646024045, 0.030231031568805966, 0.043667045599386396, 0.2608207310591822, 0.2777257784426477, 0.009660027076266007, 0.043470121843197033, 0.4081361439722388, 0.9957536102495642, 0.99800114715516, 0.9975459268263405, 0.9454090590869948, 0.05268533456212355, 0.03150679991734076, 0.0031506799917340764, 0.009452039975202229, 0.0010502266639113586, 0.15228286626714702, 0.8013229445643667, 0.0010502266639113586, 0.9946898021034426, 0.9267544053845348, 0.055813606795067194, 0.27906803397533597, 0.6139496747457391, 0.9780399922048777, 0.99701904465624, 0.9534806535779384, 0.04528727109420247, 0.9239911821630875, 0.0006456961440692435, 0.003874176864415461, 0.0032284807203462177, 0.06779809512727057, 0.99038693449102, 0.938660342462045, 0.025423444770889318, 0.034789977054901174, 0.000669038020286561, 0.2041899849130787, 0.038001519899228356, 0.11964114877364718, 0.022000879941658523, 0.3174672427945106, 0.00036365090812658714, 0.29201167922564947, 0.006363890892215275, 0.9256267168021842, 0.13667722220630607, 0.02182241362957828, 0.03560499065878561, 0.009188384686138223, 0.0677643370602694, 0.2032930111808082, 0.0930323949471495, 0.4330026283342638, 0.993901861883618, 0.9879155777967926, 0.11323192768635675, 0.39498184171130146, 0.14495966581323858, 0.14590959809248655, 0.11057211730446245, 0.01652882165891449, 0.025268198627995717, 0.02260838824610143, 0.02583815799554449, 0.038782941319309344, 0.9601716078144161, 0.014028218502977637, 0.9819752952084346, 0.39035785960020325, 0.23347272581738496, 0.25674884867858705, 0.039945485958307485, 0.026122111682659092, 0.039183167523988635, 0.0025410614477294835, 0.00924946366973532, 0.0024394189898203043, 0.4354157683948837, 0.4819126558795862, 0.006698704129152057, 0.0015761656774475428, 0.025218650839160684, 0.03231139638767463, 0.015564636064794485, 0.0013791449677666, 0.9859420105014076, 0.960092070771651, 0.03960917960134166, 0.9985936937591651, 0.9965955851172013, 0.9912309144138012, 0.9661443089939366, 0.9930189115561731, 0.9919863679451295, 0.01675019120655788, 0.05304227215409995, 0.13958492672131567, 0.7900506852426467, 0.9759207859093895, 0.9729027723555822, 0.9940261227378232, 0.9928328838181434, 0.024654872707956844, 0.10478320900881659, 0.17669325440702405, 0.06574632722121825, 0.03698230906193527, 0.07807376357519667, 0.48796102234497923, 0.024654872707956844, 0.07006738391907688, 0.036364085325090535, 0.015077791476257051, 0.28337378686259573, 0.5951292988569695, 0.0004434644551840309, 0.0013278894393348444, 0.37048115357442163, 0.022574120468692355, 0.10888693402545725, 0.4959667055915644, 0.9397702999597602, 0.03942468557899243, 0.9605287031972701, 0.9967554324461032, 0.9944216995985663, 0.0037298639275165713, 0.4311722700209156, 0.5564956979854724, 0.0007459727855033142, 0.007459727855033143, 0.0007459727855033142, 0.9397702999597602, 0.9337346215858078, 0.02726918834439922, 0.038552990417943724, 0.007889024874465345, 0.9861281093081682, 0.9813845278619685, 0.014661557780738086, 0.0035714051004362003, 0.0005639060684899264, 0.9652080335777662, 0.03452455919797835, 0.00025350149198534667, 0.9926484672416211, 0.006400912672630003, 0.0006337537299633667, 0.998283160955399, 0.9914687197856848, 0.994765884014398, 0.9956183661647066, 0.99718137294375, 0.9877605237811188, 0.9926192678536105, 0.000928967783370166, 0.1203013279464365, 0.003715871133480664, 0.7211112418410913, 0.007431742266961328, 0.13632602220957185, 0.0006967258375276244, 0.009521919779544202, 0.07950771744301494, 0.02446391305938921, 0.8725462324515485, 0.022425253637773444, 0.0005369176818407475, 0.020402871909948408, 0.973968674859116, 0.005369176818407475, 0.9989418065135328, 0.010763485813817324, 0.018836100174180317, 0.9660228517901049, 0.005381742906908662, 0.9905702959076984, 0.9931789244204284, 0.012133875863015854, 0.9828439449042842, 0.017484448445635268, 0.982626002644702, 0.050655881668565446, 0.35459117167995813, 0.5825426391885027, 0.9908761301868664, 0.08610481593535349, 0.036985932299504115, 0.10606547781127634, 0.18532104702449945, 0.0831694244830119, 0.13952894036797053, 0.20508601613693286, 0.15772836737248844, 0.9960815265120185, 0.029176347426867363, 0.39290814534848045, 0.07123891496726781, 0.057866422396620265, 0.09044667702328882, 0.11816420707881281, 0.21298733621613175, 0.020180306970249924, 0.006807814399602385, 0.0026474534283705206, 0.060891428852521974, 0.9213137930729411, 0.013237267141852603, 0.0026474534283705206, 0.01640140277628287, 0.8966100184367969, 0.0874741481401753, 0.02141150477579992, 0.9463885110903565, 0.02997610668611989, 0.004282300955159984, 0.995378741659722, 0.6473741928479271, 0.03516600553741826, 0.23561223710070237, 0.017902693728140205, 0.052749008306127394, 0.010869492620656554, 0.35057409861666544, 0.12416103722854704, 0.13438325069319873, 0.16382442105191775, 0.12601418703792833, 0.030487303315627823, 0.035478851995735514, 0.02860426399319199, 0.006426245306725473, 0.4927729719795447, 0.018206604181944003, 0.14976246064622703, 0.14668024025322077, 0.11803231582520127, 0.03383274477904555, 0.009174981634995402, 0.025446238128307562, 0.006092761241989134, 0.9935128681313211, 0.9914969780230849, 0.9980810569437095, 0.9946702315041853, 0.9972303682296222, 0.007437862801756442, 0.7907377891117318, 0.013016259903073774, 0.03765418043389199, 0.09018408647129686, 0.0032540649757684436, 0.057643436713612425, 0.9956513675025059, 0.2273620265248945, 0.002896331548087828, 0.08906219510370071, 0.07385645447623962, 0.09340669242583245, 0.505409855141326, 0.001448165774043914, 0.00724082887021957, 0.9967943516657621, 0.0624106897740233, 0.0015602672443505827, 0.09439616828321025, 0.840984044704964, 0.9953780757642479, 0.9941559011820705, 0.9904546384804296, 0.006559302241592249, 0.11601972129468933, 0.2057368349666696, 0.0021618581607706086, 0.20069249925820484, 0.01333145865808542, 0.23276006197630222, 0.002522167854232377, 0.026302607622709074, 0.20069249925820484, 0.02692178371109097, 0.13460891855545484, 0.24229605339981872, 0.06057401334995468, 0.5317052282940467, 0.10760123303066842, 0.8895035263868588, 0.3575571751861785, 0.08854542993062985, 0.1668138034942261, 0.13522918451284416, 0.10858719674610598, 0.057021086939670416, 0.044393266946159894, 0.03405593458870379, 0.007775602764500511, 0.08139046002922576, 0.004069523001461288, 0.9115731523273285, 0.9979747758982895, 0.027612879467078553, 0.9710529279255958, 0.9944991022013326, 0.15130787026823328, 0.05201208040470519, 0.7045272709364612, 0.06552171167865459, 0.00472837094588229, 0.01891348378352916, 0.0033774078184873497, 0.9945681689921647, 0.9063659521148593, 0.9857468749818149, 0.012584002659342319, 0.9902204379503134, 0.008886278548839026, 0.050355578443421145, 0.9389834333273238, 0.012483557157357291, 0.7032403865311274, 0.005201482148898871, 0.10715053226731674, 0.06360669599224905, 0.04740779444282114, 0.060634420478592556, 0.00029722755136564976, 0.9397702999597602, 0.0033554627083150234, 0.0190142886804518, 0.017895801111013458, 0.1006638812494507, 0.0022369751388766823, 0.013421850833260094, 0.8444581149259476, 0.9154358225785002, 0.9981458450662918, 0.9045765930369137, 0.042814803497215455, 0.04964695299145196, 0.0013664298988473017, 0.0009109532658982011, 0.8635829341993548, 0.026169179824222875, 0.015265354897463343, 0.0021807649853519064, 0.05233835964844575, 0.019626884868167157, 0.021807649853519063, 0.1257776440874791, 0.47722286997848096, 0.1974264475801387, 0.07557118324590739, 0.03974678149957759, 0.002353427851948673, 0.05491331654546904, 0.0015689519012991155, 0.025887706371435407, 0.41931200478441744, 0.06721515812653542, 0.15484800303779145, 0.12850152628948147, 0.10205512611481889, 0.046964010385735847, 0.017253444950220687, 0.05605704218382512, 0.007827335064289308, 0.9879985445748535, 0.2897221466579184, 0.14010513927456386, 0.15554243341833884, 0.1267729306958491, 0.12981360984538054, 0.06588138157318112, 0.03383730130504214, 0.04880679865658152, 0.00943390197675138, 0.011882302284893984, 0.5267820679636334, 0.13588479023237737, 0.07982469740108267, 0.09505841827915187, 0.03412353476687503, 0.08530883691718759, 0.024373953404910737, 0.006702837186350453, 0.04183206668190622, 0.9481935114565411, 0.13087335225883193, 0.8615829023706436, 0.4784639083454006, 0.03962970548646845, 0.15270393693031545, 0.14594097283613341, 0.09796817145777688, 0.034320462646176025, 0.015927728520877274, 0.025345314035205502, 0.009733611873869445, 0.9875222960788951, 0.9215132443149744, 0.9866566193241894, 0.9972642906565995, 0.9991134116723854, 0.9973859602394473, 0.8948969808580438, 0.972371154776083, 0.9961817839373975, 0.9364087391514951, 0.9910220107231528, 0.0005944424443922385, 0.04161097110745669, 0.008322194221491339, 0.17981883942865215, 0.04488040455161401, 0.04428596210722177, 0.6526978039426778, 0.0014861061109805963, 0.026155467553258493, 0.9907626381625244, 0.005897396655729312, 0.9683694478600648, 0.0050261390027339006, 0.021221475789320914, 0.0005584598891926557, 0.0050261390027339006, 0.9788262125266602, 0.01977426691973051, 0.0030269912601652224, 0.2517906366410162, 0.009356154804147051, 0.12961026213980179, 0.5399051684040151, 0.00357735330746799, 0.04100197252405619, 0.021739300868459325, 0.993991067376213, 0.007008092532656706, 0.48041682603177693, 0.12662898231421083, 0.08288881857590517, 0.11986254814474918, 0.021507594324360235, 0.06162288261474, 0.10004656236275436, 0.9937207772413679, 0.9872692687500552, 0.9983181560745146, 0.9759522253278123, 0.9712438896634203, 0.9636457958678913, 0.022620793330232192, 0.009048317332092876, 0.9232874733353293, 0.9397702999597602, 0.986530212993821, 0.9924852251442056, 0.4203026981313752, 0.051504682418502465, 0.13905498953108317, 0.15887625661338947, 0.11632558287685549, 0.03198953529113526, 0.03145382536999185, 0.0450761633647815, 0.005433629200168908, 0.10884808250366296, 0.32654424751098887, 0.006047115694647942, 0.5502875282129627, 0.9955394436537286, 0.9935742487018566, 0.4729702785630992, 0.033583688418681604, 0.14249079229069192, 0.1612017044096717, 0.11482422992673043, 0.03110489236873129, 0.0111945628062272, 0.0269469118978469, 0.0055972814031136, 0.9949559208587704, 0.015644434469601093, 0.022755541046692498, 0.9016883139751902, 0.059733295247567805, 0.995891137032236, 0.023714350178019483, 0.03161913357069264, 0.9446216154244427, 0.03254721467139253, 0.016273607335696265, 0.9520060291382315, 0.10664380790785985, 0.03596128406195274, 0.8419900647608934, 0.014880531335980444, 0.20643343213888052, 0.27633929893136505, 0.04504002155757393, 0.007037503368370926, 0.42459603655837924, 0.0009383337824494569, 0.03518751684185463, 0.004222502021022556, 0.16356064728247194, 0.08338385939890726, 0.7520582703478366, 0.8661744838036811, 0.04723054634177813, 0.08687046916434192, 0.1540078846177621, 0.15867479021223974, 0.07840401398722434, 0.00466690559447764, 0.06813682167937353, 0.015867479021223974, 0.5133596153925403, 0.005600286713373167, 0.995572170415023, 0.9941115120537464, 0.038037418116526375, 0.17750795121045643, 0.13947053309393004, 0.16482881183828096, 0.45644901739831656, 0.6204901779446307, 0.03050965841153685, 0.11136025320210949, 0.10030050202792738, 0.08720677362630949, 0.02428060315251474, 0.003559460148012632, 0.01856004220035158, 0.003813707301442106, 0.40034401922797597, 0.09611164529407704, 0.15737494315172373, 0.1379878235765191, 0.11356005291176123, 0.03174640830439761, 0.02723890300316253, 0.02694809620953446, 0.008772671607780103, 0.2996887571699101, 0.3671759200440502, 0.08922031702004958, 0.05261711003746514, 0.032027806109761386, 0.07206256374696313, 0.02058930392770375, 0.06405561221952277, 0.4241486349219516, 0.054489725531414686, 0.15150894932121964, 0.14952194670717087, 0.1128388215247318, 0.0426059214358537, 0.020825315858780506, 0.03633922088385369, 0.007680529335073178, 0.3655455643024877, 0.0702779320910866, 0.205985120546119, 0.09981584169320863, 0.0802539430699165, 0.05322396918872934, 0.03388499818507585, 0.08627298880016022, 0.0047929438222311235, 0.9187374413555389, 0.07909660091140401, 0.9826227243695086, 0.9936643342992094, 0.012647939155598321, 0.7095493866290659, 0.029090260057876138, 0.14292171245826102, 0.05438613836907278, 0.051856550537953114, 0.6293256915473746, 0.08937169584104727, 0.06702877188078546, 0.047168395027219395, 0.14895282640174545, 0.017377829746870303, 0.14782646315790676, 0.8376832912281383, 0.9967128414025005, 0.9975161702022313, 0.0009573048021288647, 0.05360906891921642, 0.8357270922584988, 0.021060705646835022, 0.08902934659798442, 0.3541253652876699, 0.24734710628871603, 0.10216683753809068, 0.06948935097921498, 0.08213100636330557, 0.048022389006230945, 0.058358333659889926, 0.02830458689771228, 0.010097422853959157, 0.2651821906284213, 0.195839026750661, 0.24729228761886216, 0.04480391638677208, 0.023747658862246685, 0.16876669564769978, 0.0022164481604763572, 0.05002840133646635, 0.002058130434728046, 0.11214623978541627, 0.2266785697790329, 0.37938834310385505, 0.03340526291480485, 0.12169060061821765, 0.05010789437220727, 0.04056353353940589, 0.011930451041001731, 0.02624699229020381, 0.0022831555504410172, 0.1061667330955073, 0.80823706485612, 0.08333517759109713, 0.017539753907240153, 0.03689396511522929, 0.001209638200499321, 0.31087701752832547, 0.05261926172172046, 0.5679251351344312, 0.013306020205492531, 0.9759956380686321, 0.9736284632760661, 0.9712435677339505, 0.00483740354963884, 0.996505131225601, 0.9957380787883671, 0.9933585205424514, 0.11971358643820748, 0.021698087541925107, 0.07631741135435727, 0.0703317320324469, 0.5656466959205303, 0.09577086915056598, 0.03741049576193984, 0.013467778474298342, 0.06148064317048937, 0.024153109816977967, 0.09441670201182295, 0.8212057337772508, 0.13267988976453357, 0.014742209973837062, 0.17690651968604473, 0.14373654724491136, 0.0036855524934592656, 0.5233484540712157, 0.994235719392578, 0.49931671650089016, 0.01772590961618425, 0.1448539176447557, 0.14474313070965453, 0.11693560999926549, 0.033180687062794895, 0.008253626665035792, 0.029026176996501712, 0.005982494495462185, 0.9962146226081295, 0.014130953180622477, 0.06908465999415433, 0.014130953180622477, 0.8965304740150483, 0.0015701059089580532, 0.0031402118179161063, 0.22240286955039257, 0.7759926209312611, 0.003518867796425954, 0.2867877254087152, 0.0914905627070748, 0.024632074574981677, 0.5929292236977732, 0.03508256485154786, 0.2787469243659348, 0.19795071440479428, 0.10184574887206924, 0.021049538910928714, 0.022537890147054988, 0.14585842114037473, 0.196462363168668, 0.0006378648154826884, 0.0005249449949523004, 0.13149872123555126, 0.05354438948513464, 0.473500385446975, 0.284782659761623, 0.020997799798092017, 0.016273294843521312, 0.018898019818282815, 0.9989582349392361, 0.0012182231878137822, 0.0073093391268826925, 0.8344828836524407, 0.08283917677133719, 0.07187516808101314, 0.997053494147054, 0.995045551232201, 0.9884420610952281, 0.9971427285390408, 0.006882613804207843, 0.6967322897182708, 0.14135829890180723, 0.001058863662185822, 0.034413069021039216, 0.058766933251313117, 0.009000341128579486, 0.0481782966294549, 0.003706022817650377, 0.9947287974641565, 0.998447996302418, 0.994438680131728, 0.9913292954747034, 0.9949562414342438, 0.9815311430993547, 0.2502550496291055, 0.15434466864988833, 0.15088123822563884, 0.11802305214942554, 0.133297668379449, 0.07930367612448233, 0.0362328105921487, 0.0743305452588933, 0.003374624515935418, 0.9946394314648339, 0.9175633812771422, 0.007534767385240116, 0.9908219111590753, 0.9959372422887276, 0.024399380499070984, 0.19176105710751343, 0.013374475236527798, 0.001445889214759762, 0.0025303061258295833, 0.7003525883992597, 0.06452280620865437, 0.0016266253666047323, 0.9955508743372561, 0.9397702999597602, 0.07944491501841426, 0.6107327842040596, 0.07122112498721123, 0.09853031452479113, 0.04406710129927666, 0.029171179733323987, 0.042980940351759284, 0.01303393137020859, 0.010706443625528484, 0.14486879132869238, 0.8430053284353054, 0.005095887132165058, 0.0014559677520471594, 0.005823871008188638, 0.04508518227286434, 0.12961989903448495, 0.048607462137931864, 0.005635647784108042, 0.11905305943928239, 0.044380726299850834, 0.404357728509752, 0.20358777620090301, 0.3236861018436738, 0.06113149810748, 0.15928727077497049, 0.18681371370811262, 0.09325143779107119, 0.045658666948072635, 0.03757687567284646, 0.07919464698330601, 0.013400576986272452, 0.9937053168502538, 0.0338396488093959, 0.14381850743993255, 0.27917710267751616, 0.021149780505872434, 0.5202846004444619, 0.9977275121350524, 0.9661443089939366, 0.9970865123377314, 0.9965928573947719, 0.13425390265370443, 0.018601444343585554, 0.47271931386198934, 0.02507151194135444, 0.03154157953912333, 0.0012131376745816666, 0.000808758449721111, 0.3133938992669305, 0.0028306545740238885, 0.9960297923015453, 0.12439148291299013, 0.1341750826926635, 0.011181256891055293, 0.015374228225201026, 0.7156004410275387, 0.9958218680558377, 0.001092745013571142, 0.9408534566847533, 0.05572999569212825, 0.002185490027142284, 0.9899999535840084, 0.9186446846917348, 0.004751610438060697, 0.07444189686295093, 0.24398908666138186, 0.015322986118830746, 0.0842764236535691, 0.05304110579595258, 0.10785024845177024, 0.09075922547307441, 0.3453565332936468, 0.058934561995502864, 0.9915995927536463, 0.008837230330428074, 0.9897697970079443, 0.997186436643539, 0.4174020420174901, 0.0034715434022981077, 0.1750066291629105, 0.14539640602566192, 0.11660301663013056, 0.04316966324975412, 0.019236434617440103, 0.07388261193832091, 0.005840361253277993, 0.9983184422414921, 0.997402917962545, 0.9941310249621015, 0.9923153591591825, 0.11371851697629101, 0.8756325807174408, 0.4632726117438076, 0.014462777356116117, 0.16622049726919025, 0.150076675651241, 0.1186005710245033, 0.037127891369107706, 0.007535715656493368, 0.03651923741223709, 0.0061734901339734125, 0.47524736358363007, 0.03668948869481601, 0.14683966856254868, 0.14626767207955602, 0.11554328956452078, 0.03415636141299129, 0.01111307452671487, 0.02810954144992585, 0.006046819963065444, 0.9951080127120668, 0.9549970965470564, 0.003835329705008259, 0.042188626755090844, 0.04383001058293563, 0.6366129405980487, 0.0021555742909640475, 0.13723822985804435, 0.007185247636546825, 0.17244594327712381, 0.09378387355274631, 0.04710605520914198, 0.21925727515527904, 0.0025694211932259263, 0.16358648263538397, 0.09121445235952039, 0.29719638468313214, 0.029976580587635807, 0.05524255565435742, 0.01868816802047477, 0.03656380699658107, 0.06987749781568826, 0.002437587133105405, 0.0008125290443684683, 0.8629058451193133, 0.008937819488053151, 0.10199015561955328, 0.8943752108176212, 0.06721483511468254, 0.05139957979358077, 0.8797235772362862, 0.9943125387008103, 0.14485219793040624, 0.38747962946383674, 0.179125262619297, 0.0358250525238594, 0.020434506493753737, 0.0885926389127931, 0.08341934612956431, 0.04759429360570491, 0.012803899638491267, 0.9667632341279534, 0.030846142100580617, 0.002257034787847362, 0.9982338344835348, 0.006809259669803282, 0.031128044204815002, 0.2529153591641219, 0.5359860111516583, 0.04669206630722251, 0.0009727513814004688, 0.08365661880044033, 0.008754762432604219, 0.03210079558621547, 0.9913303754723921, 0.991385788229971, 0.007665354032705961, 0.21579783397689659, 0.3472572102633406, 0.15030774372484063, 0.020765150567725058, 0.04584306317643917, 0.08657470467466909, 0.00894498793686618, 0.10813851487961434, 0.01629265659929197, 0.9087864947443398, 0.08469798565627348, 0.004578269494933702, 0.0292554097262864, 0.021102262753386912, 0.004795968807587934, 0.13620551413549734, 0.7237116930650193, 0.08440905101354765, 0.11718865848044484, 0.8823251905696985, 0.9984777159412163, 0.9951140943471734, 0.034525601427373744, 0.673249227833788, 0.1908498523346493, 0.048431746446732614, 0.028291812280764595, 0.02349658986029602, 0.00047952224204685757, 0.9885560341172331, 0.4047367361778174, 0.4630079850248469, 0.05962639416905346, 0.00045171510734131405, 0.0018068604293652562, 0.07046755674524499, 0.9987849298346709, 0.0985505542188015, 0.7539647239427664, 0.01430572561240667, 0.05722290244962668, 0.019604142505890623, 0.0005298416893483952, 0.02755176784611655, 0.028081609535464944, 0.9817360283585378, 0.09980985764158676, 0.033269952547195586, 0.021387826637482878, 0.009505700727770168, 0.009505700727770168, 0.8246195381340621, 0.9925901703950104, 0.02916796493913956, 0.08681758976002717, 0.539435775109734, 0.027795354824356522, 0.17946877250788223, 0.09882792826437875, 0.03808993068522931, 0.02708717072763769, 0.09008766893686243, 0.13574020387108326, 0.09860947545791698, 0.13908805643292613, 0.01491316141184547, 0.45469924794483946, 0.03378287585132341, 0.006391354890790916, 0.090142809772478, 0.017261389105368126, 0.23939280042091352, 0.0029640769170834157, 0.15674736167399947, 0.11280928031488059, 0.13251167394019978, 0.24828503117216377, 0.06433718166567173, 0.015173863600394277, 0.7574792709316823, 0.019422545408504674, 0.13959954512362735, 0.0018208636320473132, 0.0018208636320473132, 0.9683454074258184, 0.02946284201092754, 0.1504914369078359, 0.33223313147975825, 0.29240437171180494, 0.03713265910673801, 0.04350526066961054, 0.12708438116728488, 0.0039216009617677105, 0.0003676500901657229, 0.01274520312574506, 0.9964092758121624, 0.4108918388902622, 0.12985871647452227, 0.13221621208374204, 0.1255366411909527, 0.08752202449228391, 0.025834222717699966, 0.012769767883273747, 0.05284719324000982, 0.022396208287587805, 0.03371563572819663, 0.930551546098227, 0.018543599650508148, 0.018543599650508148, 0.9990180787182684, 0.9919578312861063, 0.9911158173407427, 0.01869023594506298, 0.07242466428711904, 0.0023362794931328723, 0.8807773689110928, 0.0023362794931328723, 0.0023362794931328723, 0.01869023594506298, 0.0023362794931328723, 0.006805075891966388, 0.9867360043351262, 0.027905526498018488, 0.9697170458061425, 0.18172254021474912, 0.148682078357522, 0.016520230928613558, 0.17070905292900676, 0.48459344057266435, 0.13809128795885323, 0.24165975392799313, 0.011507607329904435, 0.09206085863923548, 0.5178423298456996, 0.04465707041679913, 0.9534284533986613, 0.9924566179424482, 0.9898261013099152, 0.9912297920486951, 0.9973202000860595, 0.04221474535010363, 0.4592249547080056, 0.3765823315358451, 0.021665768777566412, 0.002233584410058393, 0.036630784324957644, 0.010944563609286126, 0.02903659733075911, 0.021219051895554734, 0.0997964351610216, 0.873218807658939, 0.9186383122816554, 0.007401741101642703, 0.06168117584702252, 0.011513819491444205, 0.0008224156779603003, 0.5418923359584837, 0.11315892014551289, 0.08602661959682664, 0.09625506623224407, 0.06976877283947892, 0.016473182475988078, 0.016042511038707345, 0.010766785932018352, 0.04963488314660461, 0.18445128278695502, 0.24758561447913427, 0.263678679420278, 0.039613698316661484, 0.09903424579165371, 0.1646444336286243, 0.9921141959126227, 0.9913364461879951, 0.03113798914548132, 0.965277663509921, 0.0022241420818200942, 0.49310831721952475, 0.08576362656312135, 0.12597752733399312, 0.1213574837179221, 0.09910318911656588, 0.03370679708626469, 0.010736721079601688, 0.025507846443659766, 0.0046851146529170995, 0.012143765650577707, 0.00910782423793328, 0.9806090762841498, 0.016744875528620137, 0.07154628634955876, 0.021311659763698355, 0.003044522823385479, 0.8874784030168672, 0.0025827981777535422, 0.9969600966128673, 0.1694635313512193, 0.7207223704897706, 0.006698163294514597, 0.04219842875544196, 0.0026792653178058386, 0.005358530635611677, 0.052245673697213856, 0.0006698163294514597, 0.9773417824912813, 0.13009797354399497, 0.0762643293188936, 0.2458403086279629, 0.5033445735046977, 0.04486137018758447, 0.993437487607151, 0.12797028937209542, 0.39663518666180714, 0.03381033213524112, 0.00036355195844345296, 0.3722772054460958, 0.0010906558753303588, 0.029447708633919687, 0.03817295563656256, 0.07703826806495971, 0.16313986178462056, 0.6604478972453518, 0.039777929262299457, 0.015609060849763079, 0.026015101416271797, 0.0001678393639759471, 0.01795881194542634, 0.0928559920983831, 0.004615108951211883, 0.879639766100985, 0.022890940398010942, 0.14576332020714483, 0.023557708316306235, 0.42894660559274267, 0.008834140618614839, 0.39262847193843725, 0.9979947992013594, 0.005994533570416524, 0.9930943948323374, 0.9940501296711827, 0.024753296039582155, 0.07219711344878128, 0.08973069814348532, 0.008251098679860718, 0.7828229872517857, 0.022690521369616978, 0.986928217594683, 0.17372765546506375, 0.06055237783844545, 0.6631927096591644, 0.06920271752965194, 0.005766893127470995, 0.025230157432685606, 0.0028834465637354975, 0.06947307911936201, 0.09114867980460296, 0.03612600114206825, 0.3612600114206825, 0.34847696486271984, 0.05502267866253471, 0.03834913967388783, 0.939201458892665, 0.11325666193116186, 0.13990528826790583, 0.12467750178976642, 0.2046233807999983, 0.12467750178976642, 0.17131259787906836, 0.12182229182511528, 0.9665901126339652, 0.031433824801104564, 0.0015716912400552281, 0.9909232446808822, 0.024954819201875457, 0.006238704800468864, 0.9701185964729084, 0.9913937475380232, 0.01985630261852579, 0.07563243356944094, 0.6280392345073045, 0.006023822142698835, 0.14970313547225625, 0.012940062380612313, 0.10775948499716806, 0.0064239048269253505, 0.04239777185770731, 0.000642390482692535, 0.000642390482692535, 0.9481683524541817, 0.00128478096538507, 0.9938133631119195, 0.002427775538664653, 0.23630348576335955, 0.5939957484599517, 0.10844064072702116, 0.04855551077329306, 0.009711102154658612, 0.9850127994352885, 0.49793722305824867, 0.018561625390240012, 0.1460979546844698, 0.14786097645092627, 0.1170579923803846, 0.03309823882309823, 0.009413870941645025, 0.024017013497765752, 0.0059876210936258105, 0.016432207676961037, 0.17654089786273525, 0.015589530360193804, 0.6197891664822996, 0.12513758153993404, 0.036235124620991, 0.005477402558987012, 0.0008426773167672327, 0.00463472524221978, 0.011633543528587947, 0.39743431263943474, 0.015421208863477046, 0.22211951713885358, 0.32222210098949405, 0.030030775155192143, 0.0005410950478412998, 0.0010821900956825997, 0.03561782914511875, 0.01618992233869034, 0.9422534801117777, 0.38783746443553874, 0.08486681781374901, 0.12885741603830697, 0.12856544304124132, 0.12963601069714872, 0.022287272109344638, 0.07922200653714644, 0.03026786736247241, 0.008369892582548642, 0.4762150472366365, 0.06079912574246497, 0.13541759130759135, 0.14070057866960228, 0.11156952971297694, 0.03313059871091611, 0.012983613008331988, 0.023072029552737072, 0.006118714176340362, 0.4449660893336299, 0.007311948730809624, 0.16749463953133675, 0.15265818542056606, 0.13131749784576122, 0.0399606500404712, 0.010245230489099533, 0.03932298009301688, 0.006716790113185585, 0.9874689932059943, 0.005425653808824145, 0.01580441930518895, 0.010057357739665696, 0.1882162662708866, 0.4353399135883866, 0.3505707554969186, 0.9900127327709836, 0.9630404723771634, 0.9878421249582827, 0.016094814263545264, 0.9764187319884127, 0.5748555473721001, 0.024394239095126016, 0.12981977674971412, 0.08665257974225199, 0.07244028392161335, 0.05525825464591589, 0.005303095455462177, 0.04804604482648733, 0.003075795364168063, 0.04421327277099322, 0.0015790454561069008, 0.014211409104962106, 0.05131897732347427, 0.8463683644732988, 0.042634227314886315, 0.9968546524853179, 0.9970641543086876, 0.0902543317112595, 0.16132073463351107, 0.03411187340268076, 0.007106640292225158, 0.13289417346461044, 0.018477264759785412, 0.3972611923353863, 0.018477264759785412, 0.14071147778605814, 0.9858489163385047, 0.9950785021999835, 0.06295677911610918, 0.049896596214363126, 0.7933223921599076, 0.05257560809164437, 0.0006697529693203105, 0.00837191211650388, 0.032483019012035055, 0.9970506061027243, 0.05838757990006611, 0.005228738498513383, 0.9359441912338955, 0.4504581930327235, 0.016203532123479265, 0.24953439470158065, 0.0032407064246958526, 0.05833271564452535, 0.22360874330401384, 0.004665196593157839, 0.20293605180236596, 0.011662991482894595, 0.1994371543574976, 0.43386328316367895, 0.14578739353618245, 0.9973278482104995, 0.9913303289343542, 0.08676532347602152, 0.005658608052784012, 0.8865152616028286, 0.02074822952687471, 0.9865756645622321, 0.20974493970169977, 0.3286628296218599, 0.02668629813168948, 0.12219515460299919, 0.1493496334036657, 0.0004681806689770084, 0.08754978509870058, 0.07537708770529836, 0.9964872334113937, 0.34092246341299115, 0.10673292863702569, 0.11008704985120832, 0.2258042317405089, 0.1552478961993101, 0.02839024027718865, 0.0035937013009099557, 0.025275699149733356, 0.003953071431000952, 0.9892512649438898, 0.9967914384844688, 0.9840521396226098, 0.011442466739797789, 0.9873411882759087, 0.09286885430500402, 0.9061748814003423, 0.030349317816068536, 0.642720230524161, 0.0249647614293467, 0.07097824327951512, 0.07097824327951512, 0.013706143529837404, 0.09447448933066496, 0.03964991521131534, 0.011748123025574916, 0.009506977233934162, 0.9887256323291528, 0.26782244773078623, 0.03182048883930134, 0.6973990470613542, 0.016011946614816974, 0.9820660590421078, 0.9936426743521252, 0.9595887266007644, 0.05494794687609008, 0.9341150968935314, 0.3170473025368104, 0.22969753551136263, 0.4011618930057601, 0.016175882782490325, 0.03558694212147872, 0.2920828137376629, 0.0949038795425214, 0.12715277064920344, 0.14965425256424172, 0.17021595155556982, 0.03651641353884447, 0.09407947179994457, 0.02977566787895153, 0.005625370478759572, 0.9924891828567548, 0.9950764167821963, 0.9936932098739247, 0.015978236798217593, 0.9799985236240123, 0.9967670629411243, 0.047881848549019695, 0.933696046705884, 0.468395029269746, 0.00012582808039482768, 0.18169574809013117, 0.14677845578056647, 0.1163909743652156, 0.0400133295655552, 0.00163576504513276, 0.03944710320377848, 0.0055364355373724175, 0.08051279711070405, 0.6164515172718553, 0.002846412019065295, 0.08091942739914196, 0.14028744951107525, 0.06018128268880909, 0.0052861937496926905, 0.013418799518450675, 0.9968325585500731, 0.9896953354645522, 0.9970373847449069, 0.02390376599768505, 0.9750220341161007, 0.9967175703175747, 0.00031335171016559144, 0.07959133438206022, 0.0018801102609935485, 0.5637197265878989, 0.13286112511021075, 0.2014851496364753, 0.016920992348941937, 0.0031335171016559143, 0.003196140516849516, 0.017578772842672338, 0.9620382955717043, 0.01598070258424758, 0.8430100657206826, 0.03003089292643653, 0.058989253962643186, 0.05255406262126393, 0.006435191341379256, 0.00858025512183901, 0.22257641137244843, 0.22925745711010373, 0.1618464562964583, 0.09488586306063232, 0.09773844438682222, 0.06478362327636526, 0.08234951881132409, 0.03378056833645929, 0.012686480108581378, 0.0033463449018624305, 0.8031227764469834, 0.036809793920486736, 0.10150579535649372, 0.011154483006208102, 0.042387035423590784, 0.008112293021424417, 0.989699748613779, 0.15696414612018308, 0.5308725743201878, 0.11875099498460692, 0.02442739408033666, 0.030715634140621343, 0.034585320331565764, 0.05248261896468372, 0.03893871729637824, 0.01257648012056937, 0.9913288448337679, 0.9926474808565708, 0.9875627401455094, 0.999655893241866, 0.9965111008533634, 0.9842371257317246, 0.9944848790437848, 0.020247279930186324, 0.23145419998624758, 0.0003970054888271828, 0.1965177169694555, 0.5498526020256482, 0.0011910164664815485, 0.02492261986973626, 0.0706140896309194, 0.9034449702779395, 0.9693347303967301, 0.0270332394931359, 0.1416101903192214, 0.8575283747108406, 0.9926962271509848, 0.4480042357418449, 0.02967549424785725, 0.15276497710926512, 0.16130067034722406, 0.12045697933942055, 0.03733368631182041, 0.01021092275195088, 0.03406300011783614, 0.006062735383970836, 0.023979144539249382, 0.9651605677047876, 0.0059947861348123455, 0.021087790140783248, 0.9782391537530006, 0.9723093383587652, 0.005587984703211295, 0.016763954109633883, 0.9862373530834031, 0.0027200184010442814, 0.9955267347822071, 0.9969725533349314, 0.9953595050033228, 0.9963985731376364, 0.04199279500127864, 0.1667986063227054, 0.0002931434206022942, 0.22601357728436883, 0.44066784702039874, 0.022425471676075507, 0.08273973046499754, 0.005056724005389575, 0.013997598333759548, 0.9884648574518148, 0.9759522253278123, 0.9232874733353293, 0.12682364240539354, 0.8715752446157897, 0.0675331666920447, 0.24802003696635885, 0.0029881932164621547, 0.142835635746891, 0.510383401371736, 0.028089016234744257, 0.9907238082037794, 0.992613418791163, 0.3509370865597135, 0.2650695015504219, 0.18240195076507906, 0.07253410907617179, 0.07893417752406931, 0.0144001540077694, 0.009066763634521474, 0.021333561492991704, 0.005866729410572718, 0.9866486937126893, 0.3985152362480228, 0.09613718746241118, 0.14274038560000454, 0.15847981975361722, 0.10644923052857119, 0.038389746291915036, 0.021456286099062787, 0.03144268569997565, 0.00640432148319412, 0.4445697252086913, 0.06689720297157896, 0.14903533392450893, 0.14742980105319106, 0.10440617382033905, 0.03080761625543323, 0.015450345312392496, 0.033739458890013736, 0.007655366879182427, 0.002823686810830154, 0.6155637247609735, 0.3811977194620708, 0.45555918428437314, 0.5407450480123454, 0.9712608442752344, 0.9969734585880018, 0.9759207859093895, 0.010580598494898055, 0.0070537323299320375, 0.18692390674319898, 0.7900180209523882, 0.013482514839863995, 0.9808529546001056, 0.0016853143549829994, 0.0016853143549829994, 0.9570502874101853, 0.005685447251941695, 0.03600783259563073, 0.06413698702453376, 0.6822916288376781, 0.030297840496252143, 0.013378267232111336, 0.019280443952160456, 0.033445668080278344, 0.11725657750497583, 0.03383914652828161, 0.005902176720049119, 0.9974790397054288, 0.06361023976382979, 0.036436933456951044, 0.8991894087003511, 0.8904262414595803, 0.04730808381168344, 0.05133022858919499, 0.010917250110388486, 0.048228542957814154, 0.3122035046661539, 0.5993770060250878, 0.005982781278311123, 0.02710566211806264, 0.007081659472286635, 0.16733473679275865, 0.8238017811335809, 0.08723614284492882, 0.6276087572561921, 0.09165938389058718, 0.026785181887597865, 0.10296322211838078, 0.0022116205228291815, 0.03587739959256228, 0.023590618910177937, 0.0022116205228291815, 0.0009876990265433624, 0.16297033937965483, 0.7743560368099962, 0.026667873716670787, 0.03555716495556105, 0.008724894826466344, 0.9888214136661856, 0.002874530491062701, 0.015809917700844858, 0.8206784551984012, 0.03736889638381512, 0.12216754587016479, 0.992178492502345, 0.9948582413649865, 0.01749428651698855, 0.02067506588371374, 0.9605953687510077, 0.996101926322735, 0.04458574223377839, 0.022292871116889195, 0.04033948106865663, 0.8434136239223078, 0.04883200339890014, 0.9951346194698149, 0.031991627355715896, 0.10557237027386245, 0.006398325471143179, 0.0031991627355715895, 0.8381806367197564, 0.009597488206714768, 0.969447035165443, 0.024985748329006262, 0.013810374184429212, 0.05370701071722472, 0.8347603951477213, 0.013810374184429212, 0.08439673112706741, 0.022683408063553245, 0.04972900998548211, 0.6490944461262927, 0.2774355293926897, 0.9992748886049271, 0.9891812755096447, 0.13787104533949227, 0.24696625323427399, 0.2962962602823492, 0.09910271928760751, 0.07608204933183907, 0.012332501762018803, 0.06425549636005694, 0.06425549636005694, 0.0027827183463016787, 0.0074648692299085035, 0.992827607577831, 0.993938359144659, 0.23212799462597067, 0.38282128853859554, 0.07350347471794451, 0.02770343727971161, 0.0770781117862944, 0.07372688953471639, 0.07383859694310231, 0.056635656051668495, 0.00256927039287648, 0.49639387903388615, 0.024778669664170846, 0.14719514363418046, 0.1424363262814589, 0.1149500536407396, 0.03273738144372241, 0.010666314756100033, 0.023547941038466996, 0.007220274604129253, 0.08156242958035392, 0.0009062492175594879, 0.009968741393154368, 0.0009062492175594879, 0.9071554667770475, 0.08928753362427752, 0.12630919390751455, 0.7839881001156075, 0.9544156018125219, 0.0036186373528436853, 0.0009046593382109213, 0.002713978014632764, 0.03890035154306962, 0.9889152800641082, 0.9863192082197213, 0.9908200091102911], \"Term\": [\"0\", \"0\", \"0207\", \"0345\", \"0345\", \"0800\", \"0800\", \"0844\", \"1188\", \"1448\", \"15million\", \"17\", \"17\", \"17\", \"17\", \"17\", \"17\", \"17\", \"17\", \"17\", \"3million\", \"5000media\", \"503km\", \"555\", \"5g\", \"5g\", \"5p\", \"5p\", \"693\", \"7817\", \"830831\", \"988\", \"a3\", \"a46\", \"aardman\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"addit\", \"addit\", \"addit\", \"addit\", \"addit\", \"addit\", \"addit\", \"addit\", \"addit\", \"aerosol\", \"affect\", \"affect\", \"affect\", \"affect\", \"affect\", \"affect\", \"affect\", \"african\", \"african\", \"african\", \"african\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"agenc\", \"ago\", \"ago\", \"ago\", \"ahwb\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"alignmentcontactmedia\", \"allergen\", \"allergi\", \"allevi\", \"allevi\", \"allevi\", \"allevi\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"althea\", \"ambassador\", \"ambit\", \"ambit\", \"ambit\", \"ambit\", \"ambit\", \"ambit\", \"ambit\", \"ambiti\", \"ambiti\", \"ambiti\", \"ambiti\", \"ambiti\", \"ambiti\", \"ambiti\", \"amend\", \"amend\", \"amend\", \"amend\", \"and\", \"and\", \"and\", \"and\", \"and\", \"and\", \"angl\", \"angl\", \"angler\", \"anim\", \"anim\", \"anim\", \"anim\", \"anim\", \"apprentic\", \"apprenticeship\", \"apprenticeship\", \"apprenticeship\", \"arab\", \"astroscal\", \"autonom\", \"avers\", \"award\", \"award\", \"award\", \"award\", \"award\", \"award\", \"bafta\", \"bailiff\", \"balkan\", \"ballist\", \"bari\", \"bark\", \"barrier\", \"barrier\", \"barrier\", \"barrier\", \"barrier\", \"barrier\", \"bath\", \"bath\", \"bath\", \"battlefield\", \"beck\", \"bee\", \"beetl\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"bih\", \"bilater\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"binley\", \"biodivers\", \"biodivers\", \"biodivers\", \"biodivers\", \"biodivers\", \"biodivers\", \"bird\", \"bird\", \"bird\", \"blockag\", \"bonn\", \"borough\", \"borough\", \"borough\", \"bosnia\", \"bosnia\", \"brazilian\", \"brazilian\", \"bridg\", \"bridg\", \"bridg\", \"bridg\", \"bridg\", \"briefli\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"britishmad\", \"brook\", \"brook\", \"brook\", \"brook\", \"brook\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"build\", \"busi\", \"busi\", \"busi\", \"busi\", \"busi\", \"busi\", \"busi\", \"busi\", \"but\", \"but\", \"but\", \"but\", \"but\", \"butterfli\", \"byelaw\", \"byelaw\", \"caith\", \"calderdal\", \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"carolin\", \"catchment\", \"catchment\", \"catchment\", \"caught\", \"caught\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chemic\", \"chemic\", \"chemic\", \"children\", \"children\", \"children\", \"children\", \"children\", \"chisholm\", \"citi\", \"citi\", \"citi\", \"citi\", \"citi\", \"citi\", \"citi\", \"citi\", \"citiestreasuri\", \"cleaner\", \"cleaner\", \"cleaner\", \"cleaner\", \"cleveland\", \"cleveland\", \"climat\", \"climat\", \"climat\", \"climat\", \"clinic\", \"clinic\", \"clinic\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cma\", \"cma\", \"cma\", \"co2\", \"coars\", \"coars\", \"coast\", \"coast\", \"coast\", \"coast\", \"coast\", \"coastal\", \"coastal\", \"coastal\", \"coastal\", \"coastal\", \"coastal\", \"coastlin\", \"coastlin\", \"coastlin\", \"coastlin\", \"cofound\", \"cohen\", \"collaborationturkey\", \"commiss\", \"commiss\", \"commiss\", \"commiss\", \"commiss\", \"commiss\", \"commiss\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"commitmentsuk\", \"commonwealth\", \"commonwealth\", \"commonwealth\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"communicationsukexportfinancegovuk\", \"competit\", \"competit\", \"competit\", \"competit\", \"competit\", \"compromis\", \"compromis\", \"conserv\", \"conserv\", \"conserv\", \"conserv\", \"conserv\", \"conserv\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"consum\", \"consum\", \"consum\", \"consum\", \"consum\", \"consumerfriendli\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cooki\", \"cop26intern\", \"coronaviru\", \"coronaviru\", \"coronaviru\", \"coronaviru\", \"coronaviru\", \"coronaviru\", \"cotton\", \"council\", \"council\", \"council\", \"council\", \"council\", \"council\", \"council\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countrysid\", \"countrysid\", \"countrysid\", \"countrysid\", \"countrysid\", \"countrysideforest\", \"court\", \"court\", \"court\", \"court\", \"court\", \"coventri\", \"creat\", \"creat\", \"creat\", \"creat\", \"creat\", \"creat\", \"creat\", \"creat\", \"creation\", \"creation\", \"creation\", \"creation\", \"creation\", \"creation\", \"creation\", \"creation\", \"creator\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"crimestopp\", \"culvert\", \"cumbria\", \"cumbria\", \"cumbria\", \"curriculum\", \"cvmp\", \"dasa\", \"daytoday\", \"db\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"decad\", \"decad\", \"decad\", \"decad\", \"decad\", \"decad\", \"decommiss\", \"decommiss\", \"decommiss\", \"dedeoglu\", \"defenc\", \"defenc\", \"defenc\", \"defenc\", \"defenc\", \"dementia\", \"dementia\", \"depress\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"desmond\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"devic\", \"devic\", \"devic\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"divis\", \"divis\", \"divis\", \"draft\", \"draft\", \"draft\", \"draft\", \"draft\", \"drc\", \"droplet\", \"dstl\", \"easter\", \"easter\", \"educ\", \"educ\", \"educ\", \"educ\", \"educ\", \"educ\", \"educ\", \"eighttooth\", \"electricpow\", \"electrif\", \"electrif\", \"electrif\", \"ema\", \"embank\", \"embassi\", \"embassi\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"endnot\", \"enforc\", \"enforc\", \"enforc\", \"enforc\", \"england\", \"england\", \"england\", \"england\", \"england\", \"england\", \"england\", \"england\", \"englisht\\u00fcrk\\u00e7eth\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enquiriesjournalist\", \"enquiriesmemb\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"ensur\", \"entrepreneur\", \"entrepreneur\", \"entrepreneurship\", \"entrepreneurship\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"erg\", \"eros\", \"eros\", \"erosioni\", \"erosiontop\", \"eufor\", \"eur21\", \"eva\", \"eventswint\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exhal\", \"explanatori\", \"exponenti\", \"fallon\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"farm\", \"farm\", \"farm\", \"farm\", \"farm\", \"farm\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"fasten\", \"femal\", \"femal\", \"fever\", \"filey\", \"financ\", \"financ\", \"financ\", \"financ\", \"financ\", \"financ\", \"financepublished17\", \"fine\", \"fine\", \"fine\", \"fintech\", \"fintech\", \"fish\", \"fish\", \"fish\", \"fish\", \"fisheri\", \"fisheri\", \"flood\", \"flood\", \"flood\", \"flood\", \"floodhit\", \"floodingfromenviron\", \"floodingth\", \"floodlin\", \"floodsth\", \"flout\", \"flytip\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"forest\", \"forest\", \"forest\", \"forest\", \"forestri\", \"format\", \"format\", \"format\", \"format\", \"foss\", \"fossil\", \"founder\", \"founder\", \"fraud\", \"fraud\", \"freight\", \"freight\", \"freight\", \"fsb\", \"fund\", \"fund\", \"fund\", \"fund\", \"fund\", \"fund\", \"fund\", \"fund\", \"fusion\", \"futur\", \"futur\", \"futur\", \"futur\", \"futur\", \"futur\", \"futur\", \"futur\", \"futur\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gender\", \"gender\", \"gender\", \"genuin\", \"genuin\", \"genuin\", \"genuin\", \"getbizzi\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"govuk\", \"gp\", \"graduat\", \"grassland\", \"gravel\", \"greek\", \"green\", \"green\", \"green\", \"green\", \"green\", \"green\", \"green\", \"gromit\", \"grow\", \"grow\", \"grow\", \"grow\", \"grow\", \"grow\", \"grow\", \"grow\", \"guilti\", \"habitat\", \"habitat\", \"habitat\", \"habitat\", \"handwash\", \"hardwon\", \"harmoni\", \"harmoni\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"healthcar\", \"healthcar\", \"healthcar\", \"healthcar\", \"healthcar\", \"hectar\", \"hectar\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"heritag\", \"heritag\", \"heritag\", \"herzegovina\", \"highway\", \"highway\", \"hindhead\", \"hon\", \"hon\", \"hon\", \"hon\", \"hon\", \"hon\", \"hon\", \"honey\", \"honor\", \"hotlin\", \"hotlin\", \"hs2\", \"hub\", \"hub\", \"hub\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"ichikawa\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"ifc\", \"ifca\", \"illeg\", \"illeg\", \"illeg\", \"illeg\", \"illeg\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"im\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"inabl\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"indoor\", \"indoor\", \"infect\", \"infect\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"infrastructureroad\", \"inhomecoronaviru\", \"inhomeeduc\", \"inhomeenvironmentcommerci\", \"inhomeenvironmentriv\", \"inhomeenvironmentwast\", \"inhomeexport\", \"inhomehealth\", \"inhomeinternationalforeign\", \"inhometransportmaritim\", \"inhometransportroad\", \"innov\", \"innov\", \"innov\", \"innov\", \"innov\", \"innov\", \"innov\", \"innov\", \"innov\", \"inshor\", \"inshor\", \"inspect\", \"inspect\", \"inspect\", \"inspect\", \"inspect\", \"inspector\", \"inspector\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"inventor\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"invest\", \"ipo\", \"irregular\", \"isf\", \"ivd\", \"ivdr\", \"ive\", \"ive\", \"ive\", \"izmir\", \"i\\u0307zmir\", \"j\", \"jec\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"jonathan\", \"jonathan\", \"jonathan\", \"jonathan\", \"junction\", \"junip\", \"justic\", \"justic\", \"justic\", \"justic\", \"justic\", \"justic\", \"justic\", \"justic\", \"justic\", \"kimbl\", \"kingdom\", \"kingdom\", \"kingdom\", \"kingdom\", \"kosovo\", \"lab\", \"lab\", \"lab\", \"laboratori\", \"laboratori\", \"laboratori\", \"lake\", \"lake\", \"lake\", \"lake\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"landown\", \"landown\", \"landown\", \"landscap\", \"landscap\", \"landscap\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"lgbt\", \"lgbti\", \"librari\", \"librari\", \"librari\", \"librari\", \"librari\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"licenc\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"logist\", \"logist\", \"longdist\", \"longest\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"ltd\", \"ltd\", \"ltd\", \"ltd\", \"ltd\", \"ltd\", \"m\", \"m\", \"macedonia\", \"magistr\", \"mainten\", \"mainten\", \"mainten\", \"mainten\", \"mainten\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"maritim\", \"maritim\", \"maritim\", \"maritim\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"marpol\", \"mcp\", \"mdr\", \"meadow\", \"meadow\", \"med\", \"medal\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"media\", \"medic\", \"medic\", \"medic\", \"medic\", \"medicin\", \"medicin\", \"medicin\", \"medicin\", \"medicin\", \"medicin\", \"mentor\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mhra\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"michael\", \"middlesbrough\", \"middlesbrough\", \"mile\", \"mile\", \"mile\", \"mile\", \"mile\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"missil\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mmo\", \"mod\", \"moral\", \"mosaic\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"multiacademi\", \"munit\", \"murder\", \"music\", \"mytholmroyd\", \"n\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nationalist\", \"nationsit\", \"nativ\", \"nativ\", \"nato\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"nda\", \"nebati\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"net\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"newport\", \"nh\", \"nh\", \"nh\", \"nh\", \"nh\", \"nigerian\", \"ninefigur\", \"nnr\", \"noke\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"north\", \"novembersaturday\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"numerica\", \"ocean\", \"ocean\", \"ocean\", \"ocean\", \"octobersaturday\", \"offenc\", \"offenc\", \"offenc\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"officershar\", \"ofwat\", \"ofwat\", \"ohr\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"orbit\", \"osc\", \"osman\", \"outer\", \"oxid\", \"oxid\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"parent\", \"pari\", \"pari\", \"pari\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"partnership\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"patient\", \"patient\", \"peac\", \"peac\", \"peac\", \"peatland\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"permit\", \"permit\", \"permit\", \"pest\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"pierc\", \"pig\", \"pig\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"planet\", \"planet\", \"planet\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plastic\", \"plastic\", \"plead\", \"poland\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"pollin\", \"pollut\", \"pollut\", \"pollut\", \"pollut\", \"pollut\", \"pollut\", \"pork\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"preschool\", \"primari\", \"primari\", \"primari\", \"primari\", \"primari\", \"primari\", \"prize\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"programm\", \"programm\", \"programm\", \"programm\", \"programm\", \"programm\", \"programm\", \"programm\", \"programm\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"prosecut\", \"prosecut\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"psc\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"pump\", \"pump\", \"pump\", \"pump\", \"pupil\", \"q3\", \"quantum\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"queen\", \"radar\", \"radar\", \"raf\", \"raf\", \"rail\", \"rail\", \"rail\", \"rail\", \"rail\", \"railway\", \"railway\", \"railway\", \"railway\", \"railway\", \"rainfal\", \"rainfal\", \"rampl\", \"recyclingi\", \"recyclingwast\", \"redcar\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"referr\", \"referr\", \"regist\", \"regist\", \"regist\", \"regist\", \"regist\", \"regul\", \"regul\", \"regul\", \"regul\", \"regul\", \"regul\", \"regul\", \"regul\", \"regul\", \"regulatori\", \"regulatori\", \"regulatori\", \"regulatori\", \"regulatori\", \"regulatori\", \"reinspect\", \"reluct\", \"repair\", \"repair\", \"repair\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"republ\", \"republ\", \"republ\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reserv\", \"reservoir\", \"reservoir\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"respiratori\", \"restor\", \"restor\", \"restor\", \"restor\", \"restor\", \"rhetor\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"river\", \"river\", \"river\", \"river\", \"road\", \"road\", \"road\", \"road\", \"road\", \"rod\", \"romania\", \"romania\", \"roundabout\", \"rout\", \"rout\", \"rout\", \"rout\", \"rout\", \"rout\", \"rsh\", \"rt\", \"rt\", \"rt\", \"rt\", \"rt\", \"rt\", \"rt\", \"rural\", \"rural\", \"rural\", \"rural\", \"rural\", \"rural\", \"rural\", \"s\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"safeti\", \"salmon\", \"salmon\", \"salmon\", \"saltburn\", \"satellit\", \"satellit\", \"satellit\", \"scarborough\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"schumpeterian\", \"scienc\", \"scienc\", \"scienc\", \"scienc\", \"scienc\", \"scienc\", \"scrub\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secretari\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"sellafield\", \"sellafield\", \"sellafield\", \"servic\", \"servic\", \"servic\", \"servic\", \"servic\", \"servic\", \"servic\", \"servic\", \"servic\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"shift\", \"shift\", \"ship\", \"ship\", \"ship\", \"ship\", \"ship\", \"shouldnt\", \"si\", \"simul\", \"singleus\", \"singleus\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"slaveri\", \"sluic\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"soldier\", \"somalia\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spaceflight\", \"speci\", \"speci\", \"speci\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spruce\", \"sssi\", \"stabil\", \"stabil\", \"stabil\", \"stabil\", \"staith\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"startup\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statham\", \"stewardship\", \"stirrer\", \"stirrer\", \"stockton\", \"storm\", \"storm\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"straw\", \"straw\", \"stretch\", \"stretch\", \"stretch\", \"student\", \"student\", \"studio\", \"suiss\", \"sulphur\", \"sulphur\", \"supplier\", \"supplier\", \"supplier\", \"supplier\", \"supplier\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"supporti\", \"suppress\", \"surcharg\", \"swim\", \"swim\", \"swine\", \"symptom\", \"symptom\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tackl\", \"tackl\", \"tackl\", \"tackl\", \"tackl\", \"tackl\", \"tackl\", \"tackl\", \"talent\", \"teach\", \"teacher\", \"tech\", \"tech\", \"techbas\", \"technolog\", \"technolog\", \"technolog\", \"technolog\", \"technolog\", \"technolog\", \"technolog\", \"technolog\", \"thame\", \"thame\", \"thame\", \"thame\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"the\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"tidal\", \"tidal\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"topicforeign\", \"topicforest\", \"topicmilitari\", \"topicriv\", \"topicwast\", \"totem\", \"tracey\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"traffic\", \"traffic\", \"traffic\", \"traffick\", \"traffick\", \"trail\", \"trail\", \"transylvania\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"treasur\", \"treasur\", \"treasur\", \"tree\", \"tree\", \"trout\", \"trout\", \"trout\", \"truth\", \"tunnel\", \"tunnel\", \"turkey\", \"turkmenabad\", \"typographu\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"ukaea\", \"ukca\", \"ukt\\u00fcrkiy\", \"un\", \"un\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unlicens\", \"unoosa\", \"updat\", \"updat\", \"updat\", \"updat\", \"updat\", \"updat\", \"updat\", \"updat\", \"updat\", \"updates7\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"veterinari\", \"veterinari\", \"veterinari\", \"viru\", \"viru\", \"vitro\", \"vmd\", \"vol\", \"walker\", \"walker\", \"walker\", \"walker\", \"wall\", \"wall\", \"wall\", \"wall\", \"wallac\", \"wallac\", \"wallac\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warden\", \"warn\", \"warn\", \"warn\", \"wast\", \"wast\", \"wast\", \"wast\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"watson\", \"watson\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"we\", \"weather\", \"weather\", \"weather\", \"weather\", \"weather\", \"weir\", \"weir\", \"welfar\", \"welfar\", \"welfar\", \"welfar\", \"welfar\", \"who\", \"wigtown\", \"wild\", \"wild\", \"wild\", \"wildflow\", \"wildlif\", \"wildlif\", \"wildlif\", \"wildlif\", \"wildlif\", \"wilton\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"winner\", \"winner\", \"winter\", \"winter\", \"winter\", \"winter\", \"winter\", \"women\", \"women\", \"women\", \"women\", \"woodland\", \"woodlandi\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"wyre\", \"wyre\", \"y\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"you\", \"you\", \"you\", \"you\", \"you\", \"you\", \"you\", \"you\", \"you\", \"young\", \"young\", \"young\", \"young\", \"young\", \"youth\", \"youth\", \"youth\", \"zero\", \"zero\", \"zero\", \"zero\", \"zero\", \"zhang\", \"zinc\", \"\\u015fi\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 9, 4, 7, 2, 6, 1, 3, 8, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2396031401248621688645856133644\", ldavis_el2396031401248621688645856133644_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2396031401248621688645856133644\", ldavis_el2396031401248621688645856133644_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2396031401248621688645856133644\", ldavis_el2396031401248621688645856133644_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(vis_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
