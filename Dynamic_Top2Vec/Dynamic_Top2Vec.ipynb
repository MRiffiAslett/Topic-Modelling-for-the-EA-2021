{"cells":[{"cell_type":"markdown","metadata":{"id":"2nYcJkCgH6cJ"},"source":["# Top2Vec"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":73428,"status":"ok","timestamp":1688760578979,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"NEnbUAwBH6cO"},"outputs":[],"source":["%%capture\n","!pip install top2vec"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10054,"status":"ok","timestamp":1688760589008,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"JDvDvcACKHPK","outputId":"bc6b8a4e-0c3f-4ffe-edbe-f3c4368dac18"},"outputs":[],"source":["import sys\n","if 'google.colab' in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/yourrepository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133411,"status":"ok","timestamp":1688760722403,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"-JrsGz4tH6cU","outputId":"6928fd3b-4e1c-43eb-a7c1-4a2ebd314fa9"},"outputs":[],"source":["import os\n","import sys\n","import re\n","import nltk\n","nltk.download('punkt')\n","\n","parent_directory = os.path.abspath('..')\n","sys.path.append(parent_directory)\n","\n","from gensim.test.utils import common_texts\n","from gensim.corpora.dictionary import Dictionary\n","from top2vec import Top2Vec\n","from Preprocess import preprocess\n","from Plot import plot_df\n","\n","# Run the preprocessing\n","df= preprocess('yourrepository/Data/articles.json')\n","\n","# Create a dictionary from the tokenized documents\n","dictionary = Dictionary(df['content'])\n","\n","common_corpus = [','.join(text).replace(',',' ') for text in df['content']]"]},{"cell_type":"markdown","metadata":{"id":"EYe-RA0HH6cX"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1688406952040,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"uI19lFjw5ROb","outputId":"7afa703f-564a-4577-df1a-0ec20eecf30e"},"outputs":[{"name":"stdout","output_type":"stream","text":["min_count: 100\n","topic_merge_delta: 0.1\n","embedding_model: doc2vec\n","chunk_length: 50\n"]}],"source":["import os\n","import sys\n","import re\n","from gensim.test.utils import common_texts\n","from gensim.corpora.dictionary import Dictionary\n","from top2vec import Top2Vec\n","from Preprocess import preprocess\n","from Plot import plot_df\n","\n","# Run the preprocessing\n","df = preprocess('Data/articles.json')\n","\n","# Create a dictionary from the tokenized documents\n","dictionary = Dictionary(df['content'])\n","\n","common_corpus = [','.join(text).replace(',', ' ') for text in df['content']]\n","\n","# Define the hyperparameters to tune\n","min_count = [10, 50, 100]\n","topic_merge_delta = [0.05, 0.1, 0.2]\n","embedding_model = ['doc2vec', 'universal-sentence-encoder', 'distiluse-base-multilingual-cased']\n","chunk_length = [50, 100, 200]\n","\n","best_coherence = float('-inf')\n","best_params = None\n","\n","# Iterate over all combinations of hyperparameters\n","for count in min_count:\n","    for delta in topic_merge_delta:\n","        for model in embedding_model:\n","            for length in chunk_length:\n","                try:\n","                    # Create and train the Top2Vec model\n","                    top2vec_model = Top2Vec(common_corpus, min_count=count, topic_merge_delta=delta,\n","                                            embedding_model=model, chunk_length=length, verbose=False)\n","\n","                    # Evaluate the model and store the results\n","                    coherence = top2vec_model.get_topic_coherence()\n","\n","                    # Check if the current model has better coherence\n","                    if coherence > best_coherence:\n","                        best_coherence = coherence\n","                        best_params = {\n","                            'min_count': count,\n","                            'topic_merge_delta': delta,\n","                            'embedding_model': model,\n","                            'chunk_length': length\n","                        }\n","                except:\n","                    # Handle any errors during model training\n","                    print(\"An error occurred during model training.\")\n","\n","# Print the best parameters\n","print(\"min_count:\", best_params['min_count'])\n","print(\"topic_merge_delta:\", best_params['topic_merge_delta'])\n","print(\"embedding_model:\", best_params['embedding_model'])\n","print(\"chunk_length:\", best_params['chunk_length'])\n"]},{"cell_type":"markdown","metadata":{"id":"c37nXfhWH6ca"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"XnfSNOSuH6cb"},"outputs":[],"source":["min_count = 100\n","topic_merge_delta = 0.1\n","embedding_model = 'doc2vec'\n","chunk_length = 50\n","\n","model = Top2Vec(common_corpus,min_count, topic_merge_delta, embedding_model,chunk_length)\n","\n","model.save(\"Top2vec_Model\")"]},{"cell_type":"markdown","metadata":{"id":"w_CipY-VH6cb"},"source":["# Coherence Score"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Topic: 'wast,legitim,topicwast,crime,dump,anonym,impa'\tCoherence: 0.79\n","Topic: 'sewag,discharg,effluent,pollut,silag,leak,sew'\tCoherence: 0.74\n","Topic: 'comment,onshor,permit,variat,drill,stringent'\tCoherence: 0.77\n","Topic: 'packag,undertak,oblig,complianc,turnov,sancti'\tCoherence: 0.8\n","Topic: 'singleus,stirrer,plastic,straw,cotton,bud,bag'\tCoherence: 0.89\n","Topic: 'violat,yorki,locationsuk,genevai,peac,osc,vio'\tCoherence: 0.74\n","Topic: 'cma,mislead,consum,merger,unfair,urgenc,marke'\tCoherence: 0.62\n","Topic: 'prison,probat,hmp,rehabilit,offend,jail,recor'\tCoherence: 0.68\n","Topic: 'litter,tidi,pick,bin,rubbish,flytip,highway,b'\tCoherence: 0.66\n","Topic: 'boater,waterway,boat,lock,nene,registr,thame'\tCoherence: 0.72\n","Topic: 'rod,intelligencel,topicfish,angler,cheat,conc'\tCoherence: 0.87\n","Topic: 'cefa,aquat,aquacultur,shellfish,herpesviru,ca'\tCoherence: 0.82\n","Topic: 'sellafield,decommiss,nda,magnox,nuclear,ltdpu'\tCoherence: 0.79\n","Topic: 'rod,bailiff,angler,unlicens,coars,cheat,still'\tCoherence: 0.87\n","Topic: 'nato,troop,brigad,exercis,personnel,fallon,mu'\tCoherence: 0.92\n","Topic: 'ppp,la,plastic,emb,de,singleus,tamar,pour,beh'\tCoherence: 0.66\n","Topic: 'welfar,puppi,pet,anim,microchip,dog,cat,cctv'\tCoherence: 0.65\n","Topic: 'gdf,rwm,copeland,geolog,radioact,underground'\tCoherence: 0.67\n","Topic: 'mmo,marin,mpa,gear,inshor,byelaw,topicmarinei'\tCoherence: 0.7\n","Topic: 'mdp,veteran,constabl,forcesi,arm,topicdef,lgb'\tCoherence: 0.57\n","Topic: 'accid,bulletin,branch,monthli,seriou,railway'\tCoherence: 0.31\n","Topic: 'ofwat,sewerag,overflow,topicwat,sewag,wastewa'\tCoherence: 0.7\n","Topic: 'turk,tci,caico,governor,ordin,grand,premier,c'\tCoherence: 0.85\n","Topic: 'mhra,healthcar,patient,pharmaceut,clinic,regu'\tCoherence: 0.76\n","Topic: 'envag,floodawar,rain,flood,warn,supporti,floo'\tCoherence: 0.85\n","Topic: 'pest,ash,biosecur,plant,diseas,tree,forestri'\tCoherence: 0.61\n","Topic: 'ivori,eleph,poach,endang,traffick,african,ban'\tCoherence: 0.66\n","Topic: 'particul,emiss,nitrogen,dioxid,switchboard,fr'\tCoherence: 0.78\n","Topic: 'mine,coal,saltburn,iron,treatment,bed,abandon'\tCoherence: 0.78\n","Topic: 'employe,slc,workplac,career,apprenticeship,ap'\tCoherence: 0.69\n","Topic: 'viru,covid,coronaviru,infect,symptom,transmis'\tCoherence: 0.64\n","Topic: 'nh,patient,mental,care,dementia,health,hospit'\tCoherence: 0.77\n","Topic: 'ifca,inshor,mmo,vacanc,expens,appointe,seat,r'\tCoherence: 0.68\n","Topic: 'ndg,drought,abstract,dri,prolong,wise,leakag'\tCoherence: 0.86\n","Topic: 'beef,chees,dairi,lamb,food,topicfood,export,p'\tCoherence: 0.77\n","Topic: 'bind,principl,landmark,enshrin,parliament,gle'\tCoherence: 0.47\n","Topic: 'highway,enquiriesmemb,officershar,topicroad,r'\tCoherence: 0.74\n","Topic: 'topich,profil,speed,railway,map,phase,western'\tCoherence: 0.5\n","Topic: 'nonexecut,appointe,appoint,merit,remuner,trus'\tCoherence: 0.86\n","Topic: 'fco,diplomat,foreign,facebookfollow,majesti,i'\tCoherence: 0.68\n","Topic: 'seafood,fisherman,scallop,quota,prenti,catch'\tCoherence: 0.72\n","Topic: 'nonn,salmon,invas,mussel,byelaw,trout,catch,s'\tCoherence: 0.69\n","Topic: 'raf,aircraft,typhoon,navi,jet,typhoon,navi,jet'\tCoherence: 0.42\n","Topic: 'dio,salisburi,regiment,armi,plain,soldier,per'\tCoherence: 0.83\n","Topic: 'coastguard,maritim,vessel,ship,rescu,inshor,h'\tCoherence: 0.41\n","Topic: 'cairn,welsh,cardiff,wale,devolut,exit,brexit,'\tCoherence: 0.39\n","Topic: 'rfcc,committe,vacanc,wessex,merit,expens,cand'\tCoherence: 0.53\n","Topic: 'avers,pagesthi,format,reader,file,screen,assi'\tCoherence: 0.89\n","Topic: 'hous,architect,architectur,jenrick,heritag,af'\tCoherence: 0.43\n","Topic: 'bath,classif,bacteria,beach,topicwat,swim,wat'\tCoherence: 0.67\n","Topic: 'warden,flood,floodlin,cleveland,volunt,warn,p'\tCoherence: 0.6\n","Topic: 'fusion,ukaea,culham,atom,iter,jet,race,oxford'\tCoherence: 0.72\n","Topic: 'manur,nutrient,fertilis,slurri,farmer,ammonia'\tCoherence: 0.75\n","Topic: 'belt,territori,oversea,blue,ocean,mpa,da,mari'\tCoherence: 0.88\n","Topic: 'mytholmroyd,calderdal,hebden,siren,calder,flo'\tCoherence: 0.72\n","Topic: 'dasa,dstl,topicmilitari,logist,novel,technolo'\tCoherence: 0.78\n","Topic: 'flood,wall,allevi,embank,floodingth,mainten,t'\tCoherence: 0.8\n","Topic: 'bilater,foreign,investmentworld,asia,tie,face'\tCoherence: 0.66\n","Topic: 'floodlin,warn,alert,floodawar,flood,phone,env'\tCoherence: 0.69\n","Topic: 'migrat,spawn,weir,pa,eel,salmon,passag,trout'\tCoherence: 0.84\n","Topic: 'intellectu,ip,ipo,patent,properti,chines,chin'\tCoherence: 0.51\n","Topic: 'midday,feasibl,competit,autonom,prototyp,dead'\tCoherence: 0.57\n","Topic: 'school,teacher,pupil,classroom,educ,teach,dis'\tCoherence: 0.79\n","Topic: 'bog,natur,nnr,lowland,peat,peatland,grassland'\tCoherence: 0.87\n","Topic: 'fo,york,allevi,flood,embank,gate,wall,height'\tCoherence: 0.7\n","Topic: 'fintech,inward,firm,tech,dit,scaleup,investor'\tCoherence: 0.52\n","Topic: 'nfm,leed,slow,leaki,kirkstal,allevi,judith,te'\tCoherence: 0.77\n","Topic: 'esa,satellit,orbit,space,earth,observ,mar,mis'\tCoherence: 0.7\n","Topic: 'payment,rpa,bp,farmer,stewardship,countrysid'\tCoherence: 0.77\n","Topic: 'bid,templat,bidder,budget,embassi,submiss,dea'\tCoherence: 0.72\n","Topic: 'spaceflight,outer,space,orbit,satellit,aviat'\tCoherence: 0.6\n","Topic: 'pollin,bee,butterfli,insect,honey,flower,wild'\tCoherence: 0.8\n","Topic: 'birthday,honour,queen,majesti,celebr,jubile,i'\tCoherence: 0.54\n","Topic: 'woodland,forestri,tree,woodlandi,topicforest'\tCoherence: 0.68\n","Topic: 'intertid,otter,floodplain,saltmarsh,footpath'\tCoherence: 0.87\n","Topic: 'calverton,restock,roach,bream,chub,dace,barbe'\tCoherence: 0.9\n","Topic: 'ukho,hydrograph,geospati,seab,chart,data,mari'\tCoherence: 0.65\n","Topic: 'guatemala,guatemalan,whittingham,hondura,engl'\tCoherence: 0.63\n","Topic: 'ealert,woodlandi,topicforest,pageprint,woodla'\tCoherence: 0.79\n","Topic: 'fta,trade,negoti,chapter,zealand,tariff,inves'\tCoherence: 0.62\n","Topic: 'angl,rod,angler,buy,fisheriesi,fish,coars,tro'\tCoherence: 0.87\n","Topic: 'cde,marketplac,pitch,unman,novel,enterpris,se'\tCoherence: 0.8\n","Topic: 'shingl,sand,beach,gibraltar,rock,wave,overtop'\tCoherence: 0.68\n","Topic: 'chalk,stream,invertebr,habitat,ecolog,stour,r'\tCoherence: 0.59\n","Topic: 'vmd,antimicrobi,antibiot,veterinari,amr,resis'\tCoherence: 0.71\n","Topic: 'delhi,ukindia,india,indian,nerc,amr,research'\tCoherence: 0.52\n","Topic: 'actuari,gad,profess,client,analyst,servant,ge'\tCoherence: 0.35\n","Topic: 'heatwav,climat,adapt,resili,happen,shock,argu'\tCoherence: 0.62\n","Topic: 'deforest,indigen,revers,halt,forest,loss,rain'\tCoherence: 0.85\n","Topic: 'cop,sharma,alok,presidentdesign,pari,glasgow'\tCoherence: 0.84\n","Topic: 'cheven,scholarship,scholar,alumnu,master,acad'\tCoherence: 0.75\n","Topic: 'chile,embassi,englishespanol,america,congress'\tCoherence: 0.7\n"]}],"source":["topic_words = model.get_topics(num_topics=Num_topics, reduced=False)[0].tolist()\n","\n","from Plot import print_coherence\n","dic = dictionary\n","print_coherence(dic, topics_words[0], df['content'])"]},{"cell_type":"markdown","metadata":{"id":"V98qx-OuH6cc"},"source":["# Dynamic Topic modelling"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":13920,"status":"ok","timestamp":1688761640009,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"N2b3zeRoH6cc"},"outputs":[],"source":["import numpy as np\n","\n","df_distribution = df\n","\n","\n","num_docs = len(df_distribution)  # Get the number of documents in the DataFrame\n","\n","# Reset the index and create a new column for document IDs\n","df_distribution = df_distribution.reset_index()\n","df_distribution.rename(columns={'index': 'doc_id'}, inplace=True)\n","\n","# Call the get_documents_topics function\n","topic_distribution = model.get_documents_topics([i for i in range(num_docs)], num_topics=model.get_num_topics())\n","\n","topic_nums, topic_scores, topics_words, word_distribution = topic_distribution[0], topic_distribution[1], topic_distribution[2], topic_distribution[3]\n","\n","# Some extra preprocessing was required due to the function get_documents_topics from the Top2vec API.\n","for i in range(num_docs):\n","    # Retrieve the topic numbers and scores for the current document\n","    doc_topic_nums = topic_nums[i].tolist()\n","    doc_topic_scores = topic_scores[i].tolist()\n","    topics = topics_words[i].tolist()\n","    topic_hierarchy = word_distribution[i].tolist()\n","\n","    # Insert a column for each topic in the data\n","    for j, topic_num in enumerate(doc_topic_nums):\n","        topic_score = doc_topic_scores[j]\n","        topic_name =  topics[j]\n","        word_distri = topic_hierarchy[j]\n","\n","\n","        a = sorted(word_distri, reverse = True)[:4]\n","        Topic_tile = [topic_name[word_distri.index(i)] for i in a][:4]\n","\n","        # Ensure the column name is a string\n","        column_name = f'{Topic_tile}'\n","\n","        # Check if the column already exists\n","        if column_name not in df_distribution.columns:\n","            df_distribution[column_name] = np.nan\n","\n","        # Convert the topic score to numpy.float32\n","        topic_score = np.float32(topic_score)\n","\n","        # Insert the topic number and score into your data\n","        df_distribution.at[i, column_name] = topic_score"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17IsQLZjsCWRjJdG5Ml7GKFEYg_et2tYJ"},"executionInfo":{"elapsed":58602,"status":"ok","timestamp":1688771447868,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"kDrp0ab3H6cd","outputId":"f5e97423-3938-4f8a-9302-3d3841a165f8"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["topic_means = df_distribution.groupby('year-month').mean()\n","\n","plot_df(topic_means,'Top2vec', add_error_bars =False)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
