{"cells":[{"cell_type":"markdown","metadata":{"id":"2nYcJkCgH6cJ"},"source":["# Top2Vec"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11325,"status":"ok","timestamp":1688420586293,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"NEnbUAwBH6cO"},"outputs":[],"source":["%%capture\n","!pip install top2vec"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3657,"status":"ok","timestamp":1688420948952,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"JDvDvcACKHPK","outputId":"d14c81a7-420f-4378-f196-bdedefc2405e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/yourrepository\n"]}],"source":["import sys\n","if 'google.colab' in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/yourrepository"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162873,"status":"ok","timestamp":1688421111813,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"-JrsGz4tH6cU","outputId":"561fa44f-bc2c-4de6-dd62-f5f6804de21c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import os\n","import sys\n","import re\n","import nltk\n","nltk.download('punkt')\n","\n","\n","parent_directory = os.path.abspath('..')\n","sys.path.append(parent_directory)\n","\n","from gensim.test.utils import common_texts\n","from gensim.corpora.dictionary import Dictionary\n","from top2vec import Top2Vec\n","from Preprocess import preprocess\n","from Plot import plot_df\n","\n","# Run the preprocessing\n","df= preprocess('yourrepository/Data/articles.json')\n","\n","# Create a dictionary from the tokenized documents\n","dictionary = Dictionary(df['content'])\n","\n","common_corpus = [','.join(text).replace(',',' ') for text in df['content']]"]},{"cell_type":"markdown","metadata":{"id":"EYe-RA0HH6cX"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1688406952040,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"uI19lFjw5ROb","outputId":"7afa703f-564a-4577-df1a-0ec20eecf30e"},"outputs":[{"name":"stdout","output_type":"stream","text":["min_count: 100\n","topic_merge_delta: 0.1\n","embedding_model: doc2vec\n","chunk_length: 50\n"]}],"source":["import os\n","import sys\n","import re\n","from gensim.test.utils import common_texts\n","from gensim.corpora.dictionary import Dictionary\n","from top2vec import Top2Vec\n","from Preprocess import preprocess\n","from Plot import plot_df\n","\n","# Run the preprocessing\n","df = preprocess('Data/articles.json')\n","\n","# Create a dictionary from the tokenized documents\n","dictionary = Dictionary(df['content'])\n","\n","common_corpus = [','.join(text).replace(',', ' ') for text in df['content']]\n","\n","# Define the hyperparameters to tune\n","min_count = [10, 50, 100]\n","topic_merge_delta = [0.05, 0.1, 0.2]\n","embedding_model = ['doc2vec', 'universal-sentence-encoder', 'distiluse-base-multilingual-cased']\n","chunk_length = [50, 100, 200]\n","\n","best_coherence = float('-inf')\n","best_params = None\n","\n","# Iterate over all combinations of hyperparameters\n","for count in min_count:\n","    for delta in topic_merge_delta:\n","        for model in embedding_model:\n","            for length in chunk_length:\n","                try:\n","                    # Create and train the Top2Vec model\n","                    top2vec_model = Top2Vec(common_corpus, min_count=count, topic_merge_delta=delta,\n","                                            embedding_model=model, chunk_length=length, verbose=False)\n","\n","                    # Evaluate the model and store the results\n","                    coherence = top2vec_model.get_topic_coherence()\n","\n","                    # Check if the current model has better coherence\n","                    if coherence > best_coherence:\n","                        best_coherence = coherence\n","                        best_params = {\n","                            'min_count': count,\n","                            'topic_merge_delta': delta,\n","                            'embedding_model': model,\n","                            'chunk_length': length\n","                        }\n","                except:\n","                    # Handle any errors during model training\n","                    print(\"An error occurred during model training.\")\n","\n","# Print the best parameters\n","print(\"min_count:\", best_params['min_count'])\n","print(\"topic_merge_delta:\", best_params['topic_merge_delta'])\n","print(\"embedding_model:\", best_params['embedding_model'])\n","print(\"chunk_length:\", best_params['chunk_length'])\n"]},{"cell_type":"markdown","metadata":{"id":"c37nXfhWH6ca"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnfSNOSuH6cb"},"outputs":[],"source":["min_count = 100\n","topic_merge_delta = 0.1\n","embedding_model = 'doc2vec'\n","chunk_length = 50\n","\n","model = Top2Vec(common_corpus, min_count=min_count, topic_merge_delta=topic_merge_delta,\n","                            embedding_model=embedding_model, chunk_length=chunk_length, verbose=False)\n","\n","model.save(\"Top2vec_Model\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1100,"status":"ok","timestamp":1688425878813,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"JT40fCsTH6cb","outputId":"0a078013-81b8-4bbb-fdd4-61f5ea241302"},"outputs":[{"output_type":"stream","name":"stdout","text":["Topic 1: wast, legitim, crime, dump, anonym, blight, topicw\n","Topic 2: employe, employ, career, apprentic, workplac, incl\n","Topic 3: patient, nh, healthcar, clinic, cancer, health, ca\n","Topic 4: rain, rainfal, weekend, warn, flood, alert, floodl\n","Topic 5: nonexecut, appoint, board, truste, chair, chairman\n","Topic 6: bilater, foreign, relationship, asia, tie, trade, \n","Topic 7: embassi, guatemala, englishespanol, hondura, ameri\n","Topic 8: dropin, flood, resid, session, floodlin, allevi, t\n","Topic 9: decommiss, nda, sellafield, nuclear, dounreay, rad\n","Topic 10: beef, export, lamb, dairi, food, meat, topicfood, \n","Topic 11: avers, format, reader, file, assist, pageprint, re\n","Topic 12: cop, sharma, alok, glasgow, pari, climat, presid, \n","Topic 13: school, pupil, teacher, educ, child, disadvantag, \n","Topic 14: weir, spawn, migrat, upstream, pa, eel, passag, tr\n","Topic 15: embank, flood, allevi, wall, scheme, town, floodin\n","Topic 16: repair, wall, embank, flood, mainten, floodingth, \n","Topic 17: permit, variat, comment, ga, oil, shale, consult, \n","Topic 18: climat, adapt, happen, thing, shock, resili, think\n","Topic 19: natur, sssi, grassland, rare, wetland, speci, land\n","Topic 20: fintech, firm, investor, tech, startup, talent, en\n","Topic 21: sewag, discharg, tributari, sewer, pollut, waterco\n","Topic 22: emiss, cleaner, nitrogen, transport, dioxid, freig\n","Topic 23: rod, angler, angl, coars, fish, fisheri, buy, juni\n","Topic 24: dstl, capabl, logist, soldier, mod, synthet, simul\n","Topic 25: leed, allevi, slow, flood, catchment, floodingth, \n","Topic 26: feasibl, competit, deadlin, autonom, brief, concep\n","Topic 27: nato, troop, personnel, exercis, alli, forc, aircr\n","Topic 28: wto, locationsuk, un, human, peac, right, violenc,\n","Topic 29: payment, bp, rpa, stewardship, farmer, countrysid,\n","Topic 30: belt, mpa, ocean, marin, blue, squar, oversea, ter\n","Topic 31: rod, angler, fish, caught, byelaw, fisheri, junior\n","Topic 32: architect, architectur, heritag, built, cultur, ho\n","Topic 33: seafood, fisherman, mmo, fisheri, catch, aquacultu\n","Topic 34: floodlin, warn, alert, flood, phone, text, erosion\n","Topic 35: cma, consum, claim, firm, market, examin, choic, l\n","Topic 36: prison, probat, offend, jail, recordhomecrim, drug\n","Topic 37: restock, coars, angl, stock, fish, rod, fisheri, c\n","Topic 38: brexit, scottish, welsh, eu, scotland, exit, deal,\n","Topic 39: drought, dri, abstract, reservoir, groundwat, weat\n","Topic 40: highway, junction, road, traffic, motorway, cyclis\n","Topic 41: dio, armi, salisburi, plain, personnel, accommod, \n","Topic 42: dasa, novel, logist, dstl, competit, autonom, capa\n","Topic 43: orbit, satellit, space, outer, observ, earth, miss\n","Topic 44: bid, embassi, concept, submit, budget, propos, wor\n","Topic 45: boater, waterway, boat, lock, thame, registr, moor\n","Topic 46: peac, humanitarian, un, civilian, locationsuk, act\n","Topic 47: osc, russia, ukrain, russian, ukrainian, war, demo\n","Topic 48: singleus, plastic, bag, bottl, charg, litter, supe\n","Topic 49: woodland, tree, forestri, forest, creation, plant,\n","Topic 50: accid, maritim, rescu, safeti, seriou, vessel, inc\n","Topic 51: fertilis, nutrient, ammonia, slurri, farmer, soil,\n","Topic 52: eleph, ivori, endang, darwin, extinct, african, wi\n","Topic 53: halt, revers, deforest, loss, cop, forest, ambiti,\n","Topic 54: bind, legisl, principl, landmark, parliament, ambi\n","Topic 55: ofwat, overflow, sewerag, sewag, discharg, storm, \n","Topic 56: elect, osc, democraci, peac, polit, violenc, locat\n","Topic 57: ukho, hydrograph, geospati, seab, data, marin, mar\n","Topic 58: cefa, aquacultur, aquat, shellfish, inspector, not\n","Topic 59: trail, path, coast, walk, enjoy, coastlin, outdoor\n","Topic 60: nonn, crayfish, nativ, invas, speci, spread, signa\n","Topic 61: warden, flood, floodlin, tyne, resid, warn, floodi\n","Topic 62: mine, coal, abandon, treatment, bed, metal, treat,\n","Topic 63: bath, beach, swim, qualiti, water, sampl, standard\n","Topic 64: cheven, scholarship, scholar, master, degre, studi\n","Topic 65: profil, speed, railway, map, event, phase, questio\n","Topic 66: veterinari, medicin, authoris, anim, antibiot, not\n","Topic 67: sand, dredg, beach, cubic, flood, wall, coastal, m\n","Topic 68: fco, diplomat, majesti, deputi, head, ambassador, \n","Topic 69: hub, campu, reloc, workplac, darlington, civil, cl\n","Topic 70: packag, undertak, oblig, sanction, complianc, fail\n","Topic 71: zealand, trade, negoti, tariff, australia, free, d\n","Topic 72: fo, york, allevi, flood, embank, pump, floodingth,\n","Topic 73: ip, intellectu, ipo, properti, officepublish, crea\n","Topic 74: ealert, pageprint, correspond, woodland, forestri,\n","Topic 75: novel, academia, pitch, sensor, autonom, enterpris\n","Topic 76: fusion, ukaea, remot, race, oxfordshir, reactor, h\n","Topic 77: pest, ash, biosecur, tree, plant, diseas, forestri\n","Topic 78: siren, floodlin, calderdal, calder, warn, flood, r\n","Topic 79: la, plastic, de, singleus, influenc, behaviour, ma\n","Topic 80: committe, coastal, ifca, candid, expens, backgroun\n","Topic 81: welfar, pet, anim, dog, mandatori, owner, legisl, \n","Topic 82: hull, humber, tidal, holder, flood, allevi, victor\n","Topic 83: avian, influenza, bird, poultri, hn, hpai, wild, c\n","Topic 84: pollin, bee, insect, flower, crop, wild, speci, he\n","Topic 85: antimicrobi, amr, antibiot, resist, veterinari, in\n","Topic 86: peacekeep, sudan, un, civilian, troop, mandat, mis\n","Topic 87: cycl, cyclist, walk, junction, traffic, highway, r\n","Topic 88: litter, pick, rubbish, highway, bag, clean, blight\n","Topic 89: gdf, geolog, radioact, substanc, dispos, rock, dee\n","Topic 90: salmon, byelaw, wye, trout, stock, catch, spawn, s\n","Topic 91: ifca, inshor, expens, mmo, balanc, recreat, candid\n","Topic 92: governor, grand, cabinet, amend, approv, draft, as\n","Topic 93: aonb, landscap, beauti, outstand, park, hill, natu\n"]}],"source":["model = Top2Vec.load(\"Top2vec_Model\")\n","Num_topics = model.get_num_topics(reduced=False)\n","\n","for i, words in enumerate(model.get_topics(num_topics=Num_topics, reduced=False)[0][:]):\n","    print(f\"Topic {i+1}: {', '.join(words)[:50]}\")"]},{"cell_type":"markdown","metadata":{"id":"w_CipY-VH6cb"},"source":["# Coherence Score"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227851,"status":"ok","timestamp":1688426108716,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"Rw89YsOTH6cc","outputId":"19e006ea-d152-4384-9d77-5a1f1ee0a768"},"outputs":[{"output_type":"stream","name":"stdout","text":["Topic: wast,legitim,crime,dump,anonym,blight,topicwa\tCoherence: 0.85\n","Topic: employe,employ,career,apprentic,workplac,incl\tCoherence: 0.69\n","Topic: patient,nh,healthcar,clinic,cancer,health,car\tCoherence: 0.77\n","Topic: rain,rainfal,weekend,warn,flood,alert,floodli\tCoherence: 0.80\n","Topic: nonexecut,appoint,board,truste,chair,chairman\tCoherence: 0.77\n","Topic: bilater,foreign,relationship,asia,tie,trade,c\tCoherence: 0.71\n","Topic: embassi,guatemala,englishespanol,hondura,amer\tCoherence: 0.65\n","Topic: dropin,flood,resid,session,floodlin,allevi,to\tCoherence: 0.65\n","Topic: decommiss,nda,sellafield,nuclear,dounreay,rad\tCoherence: 0.80\n","Topic: beef,export,lamb,dairi,food,meat,topicfood,dr\tCoherence: 0.74\n","Topic: avers,format,reader,file,assist,pageprint,req\tCoherence: 0.89\n","Topic: cop,sharma,alok,glasgow,pari,climat,presid,eg\tCoherence: 0.83\n","Topic: school,pupil,teacher,educ,child,disadvantag,t\tCoherence: 0.84\n","Topic: weir,spawn,migrat,upstream,pa,eel,passag,trou\tCoherence: 0.84\n","Topic: embank,flood,allevi,wall,scheme,town,flooding\tCoherence: 0.77\n","Topic: repair,wall,embank,flood,mainten,floodingth,d\tCoherence: 0.70\n","Topic: permit,variat,comment,ga,oil,shale,consult,de\tCoherence: 0.67\n","Topic: climat,adapt,happen,thing,shock,resili,think,\tCoherence: 0.63\n","Topic: natur,sssi,grassland,rare,wetland,speci,lands\tCoherence: 0.86\n","Topic: fintech,firm,investor,tech,startup,talent,ent\tCoherence: 0.68\n","Topic: sewag,discharg,tributari,sewer,pollut,waterco\tCoherence: 0.81\n","Topic: emiss,cleaner,nitrogen,transport,dioxid,freig\tCoherence: 0.79\n","Topic: rod,angler,angl,coars,fish,fisheri,buy,junior\tCoherence: 0.92\n","Topic: dstl,capabl,logist,soldier,mod,synthet,simul,\tCoherence: 0.83\n","Topic: leed,allevi,slow,flood,catchment,floodingth,s\tCoherence: 0.69\n","Topic: feasibl,competit,deadlin,autonom,brief,concep\tCoherence: 0.60\n","Topic: nato,troop,personnel,exercis,alli,forc,aircra\tCoherence: 0.86\n","Topic: wto,locationsuk,un,human,peac,right,violenc,o\tCoherence: 0.78\n","Topic: payment,bp,rpa,stewardship,farmer,countrysid,\tCoherence: 0.82\n","Topic: belt,mpa,ocean,marin,blue,squar,oversea,terri\tCoherence: 0.82\n","Topic: rod,angler,fish,caught,byelaw,fisheri,junior,\tCoherence: 0.88\n","Topic: architect,architectur,heritag,built,cultur,ho\tCoherence: 0.51\n","Topic: seafood,fisherman,mmo,fisheri,catch,aquacultu\tCoherence: 0.68\n","Topic: floodlin,warn,alert,flood,phone,text,erosioni\tCoherence: 0.75\n","Topic: cma,consum,claim,firm,market,examin,choic,law\tCoherence: 0.55\n","Topic: prison,probat,offend,jail,recordhomecrim,drug\tCoherence: 0.66\n","Topic: restock,coars,angl,stock,fish,rod,fisheri,clu\tCoherence: 0.87\n","Topic: brexit,scottish,welsh,eu,scotland,exit,deal,w\tCoherence: 0.63\n","Topic: drought,dri,abstract,reservoir,groundwat,weat\tCoherence: 0.79\n","Topic: highway,junction,road,traffic,motorway,cyclis\tCoherence: 0.76\n","Topic: dio,armi,salisburi,plain,personnel,accommod,s\tCoherence: 0.84\n","Topic: dasa,novel,logist,dstl,competit,autonom,capab\tCoherence: 0.81\n","Topic: orbit,satellit,space,outer,observ,earth,missi\tCoherence: 0.57\n","Topic: bid,embassi,concept,submit,budget,propos,word\tCoherence: 0.61\n","Topic: boater,waterway,boat,lock,thame,registr,moor,\tCoherence: 0.69\n","Topic: peac,humanitarian,un,civilian,locationsuk,act\tCoherence: 0.78\n","Topic: osc,russia,ukrain,russian,ukrainian,war,democ\tCoherence: 0.79\n","Topic: singleus,plastic,bag,bottl,charg,litter,super\tCoherence: 0.82\n","Topic: woodland,tree,forestri,forest,creation,plant,\tCoherence: 0.75\n","Topic: accid,maritim,rescu,safeti,seriou,vessel,inci\tCoherence: 0.41\n","Topic: fertilis,nutrient,ammonia,slurri,farmer,soil,\tCoherence: 0.80\n","Topic: eleph,ivori,endang,darwin,extinct,african,wil\tCoherence: 0.70\n","Topic: halt,revers,deforest,loss,cop,forest,ambiti,g\tCoherence: 0.85\n","Topic: bind,legisl,principl,landmark,parliament,ambi\tCoherence: 0.65\n","Topic: ofwat,overflow,sewerag,sewag,discharg,storm,c\tCoherence: 0.77\n","Topic: elect,osc,democraci,peac,polit,violenc,locati\tCoherence: 0.76\n","Topic: ukho,hydrograph,geospati,seab,data,marin,mari\tCoherence: 0.72\n","Topic: cefa,aquacultur,aquat,shellfish,inspector,not\tCoherence: 0.74\n","Topic: trail,path,coast,walk,enjoy,coastlin,outdoor,\tCoherence: 0.77\n","Topic: nonn,crayfish,nativ,invas,speci,spread,signal\tCoherence: 0.57\n","Topic: warden,flood,floodlin,tyne,resid,warn,floodin\tCoherence: 0.55\n","Topic: mine,coal,abandon,treatment,bed,metal,treat,c\tCoherence: 0.64\n","Topic: bath,beach,swim,qualiti,water,sampl,standard,\tCoherence: 0.64\n","Topic: cheven,scholarship,scholar,master,degre,studi\tCoherence: 0.76\n","Topic: profil,speed,railway,map,event,phase,question\tCoherence: 0.52\n","Topic: veterinari,medicin,authoris,anim,antibiot,not\tCoherence: 0.52\n","Topic: sand,dredg,beach,cubic,flood,wall,coastal,met\tCoherence: 0.74\n","Topic: fco,diplomat,majesti,deputi,head,ambassador,o\tCoherence: 0.74\n","Topic: hub,campu,reloc,workplac,darlington,civil,cli\tCoherence: 0.45\n","Topic: packag,undertak,oblig,sanction,complianc,fail\tCoherence: 0.79\n","Topic: zealand,trade,negoti,tariff,australia,free,di\tCoherence: 0.68\n","Topic: fo,york,allevi,flood,embank,pump,floodingth,g\tCoherence: 0.74\n","Topic: ip,intellectu,ipo,properti,officepublish,crea\tCoherence: 0.48\n","Topic: ealert,pageprint,correspond,woodland,forestri\tCoherence: 0.71\n","Topic: novel,academia,pitch,sensor,autonom,enterpris\tCoherence: 0.81\n","Topic: fusion,ukaea,remot,race,oxfordshir,reactor,ha\tCoherence: 0.71\n","Topic: pest,ash,biosecur,tree,plant,diseas,forestri,\tCoherence: 0.74\n","Topic: siren,floodlin,calderdal,calder,warn,flood,re\tCoherence: 0.65\n","Topic: la,plastic,de,singleus,influenc,behaviour,mai\tCoherence: 0.58\n","Topic: committe,coastal,ifca,candid,expens,backgroun\tCoherence: 0.37\n","Topic: welfar,pet,anim,dog,mandatori,owner,legisl,la\tCoherence: 0.65\n","Topic: hull,humber,tidal,holder,flood,allevi,victori\tCoherence: 0.68\n","Topic: avian,influenza,bird,poultri,hn,hpai,wild,cap\tCoherence: 0.84\n","Topic: pollin,bee,insect,flower,crop,wild,speci,heal\tCoherence: 0.74\n","Topic: antimicrobi,amr,antibiot,resist,veterinari,in\tCoherence: 0.63\n","Topic: peacekeep,sudan,un,civilian,troop,mandat,miss\tCoherence: 0.69\n","Topic: cycl,cyclist,walk,junction,traffic,highway,ro\tCoherence: 0.82\n","Topic: litter,pick,rubbish,highway,bag,clean,blight,\tCoherence: 0.55\n","Topic: gdf,geolog,radioact,substanc,dispos,rock,deep\tCoherence: 0.56\n","Topic: salmon,byelaw,wye,trout,stock,catch,spawn,sev\tCoherence: 0.85\n","Topic: ifca,inshor,expens,mmo,balanc,recreat,candid,\tCoherence: 0.72\n","Topic: governor,grand,cabinet,amend,approv,draft,ass\tCoherence: 0.65\n","Topic: aonb,landscap,beauti,outstand,park,hill,natur\tCoherence: 0.75\n"]}],"source":["dictionary = Dictionary(df['content'])\n","\n","topic_words = model.get_topics(num_topics=Num_topics, reduced=False)[0].tolist()\n","\n","from Plot import print_coherence\n","dic = dictionary\n","print_coherence(dic, topic_words,df['content'])"]},{"cell_type":"markdown","metadata":{"id":"V98qx-OuH6cc"},"source":["# Dynamic Topic modelling"]},{"cell_type":"markdown","metadata":{"id":"A7JSWB30H6cc"},"source":["Some extra preprocessing was required due to the function get_documents_topics from the Top2vec API.\n","\n","'get_documents_topics'\n","\n","Returns:\n","topic_nums (array of int, shape(len(doc_ids), num_topics)) – The topic number(s) of the document corresponding to each doc_id.\n","\n","topic_score (array of float, shape(len(doc_ids), num_topics)) – Semantic similarity of document to topic(s). The cosine similarity of the document and topic vector.\n","\n","topics_words (array of shape(len(doc_ids), num_topics, 50)) – For each topic the top 50 words are returned, in order of semantic similarity to topic.\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":28561,"status":"ok","timestamp":1688426137270,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"N2b3zeRoH6cc"},"outputs":[],"source":["import numpy as np\n","\n","df_distribution = df\n","\n","\n","num_docs = len(df_distribution)  # Get the number of documents in the DataFrame\n","\n","# Reset the index and create a new column for document IDs\n","df_distribution = df_distribution.reset_index()\n","df_distribution.rename(columns={'index': 'doc_id'}, inplace=True)\n","\n","# Call the get_documents_topics function\n","topic_distribution = model.get_documents_topics([i for i in range(num_docs)], num_topics=model.get_num_topics())\n","\n","topic_nums, topic_scores, topics_words, word_distribution = topic_distribution[0], topic_distribution[1], topic_distribution[2], topic_distribution[3]\n","\n","# Insert topic columns in the data\n","for i in range(num_docs):\n","    # Retrieve the topic numbers and scores for the current document\n","    doc_topic_nums = topic_nums[i].tolist()\n","    doc_topic_scores = topic_scores[i].tolist()\n","    topics = topics_words[i].tolist()\n","    topic_hierarchy = word_distribution[i].tolist()\n","\n","    # Insert a column for each topic in the data\n","    for j, topic_num in enumerate(doc_topic_nums):\n","        topic_score = doc_topic_scores[j]\n","        topic_name =  topics[j]\n","        word_distri = topic_hierarchy[j]\n","\n","\n","        a = sorted(word_distri, reverse = True)[:4]\n","        Topic_tile = [topic_name[word_distri.index(i)] for i in a]\n","\n","        # Ensure the column name is a string\n","        column_name = f'{Topic_tile}'\n","\n","        # Check if the column already exists\n","        if column_name not in df_distribution.columns:\n","            df_distribution[column_name] = np.nan\n","\n","        # Convert the topic score to numpy.float32\n","        topic_score = np.float32(topic_score)\n","\n","        # Insert the topic number and score into your data\n","        df_distribution.at[i, column_name] = topic_score"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1e45Jqb8kb1QkU61PBmaEWQmmRRscVsGB"},"executionInfo":{"elapsed":69828,"status":"ok","timestamp":1688426207085,"user":{"displayName":"max riffi","userId":"15293106091454968129"},"user_tz":-60},"id":"kDrp0ab3H6cd","outputId":"77f78f68-3b3c-4616-ee41-1851150e848b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["  %cd /content/drive/MyDrive/yourrepository/Dynamic_Top2Vec\n","  topic_means = df_distribution.groupby('year-month').mean()\n","\n","plot_df(topic_means,'Top2vec', add_error_bars =False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python [conda env:Python3] *","language":"python","name":"conda-env-Python3-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":0}